{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [09:23:04] Enabling RDKit 2019.09.2 jupyter extensions\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from SMILESX import main, inference, utils\n",
    "%load_ext autoreload\n",
    "%aimport SMILESX\n",
    "%autoreload 1\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Read data file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data_dir = \"./validation_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "extension = '.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'FreeSolv' # FreeSolv, ESOL, Lipophilicity\n",
    "prop_tag = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_name == 'FreeSolv':\n",
    "    data_filename = 'FreeSolv_SAMPL'\n",
    "    prop_tag = 'expt'\n",
    "elif data_name == 'ESOL':\n",
    "    data_filename = 'ESOL_delaney-processed'\n",
    "    prop_tag = 'measured log solubility in mols per litre'\n",
    "elif data_name == 'Lipophilicity':\n",
    "    data_filename = 'Lipophilicity'\n",
    "    prop_tag = 'exp'\n",
    "else:\n",
    "    data_filename = data_name\n",
    "    prop_tag = prop_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol_data = pd.read_csv(validation_data_dir+data_filename+extension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>iupac</th>\n",
       "      <th>smiles</th>\n",
       "      <th>expt</th>\n",
       "      <th>calc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4-methoxy-N,N-dimethyl-benzamide</td>\n",
       "      <td>COc1ccc(C(=O)N(C)C)cc1</td>\n",
       "      <td>-11.01</td>\n",
       "      <td>-9.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>methanesulfonyl chloride</td>\n",
       "      <td>CS(=O)(=O)Cl</td>\n",
       "      <td>-4.87</td>\n",
       "      <td>-6.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3-methylbut-1-ene</td>\n",
       "      <td>C=CC(C)C</td>\n",
       "      <td>1.83</td>\n",
       "      <td>2.452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                             iupac                  smiles  \\\n",
       "0           0  4-methoxy-N,N-dimethyl-benzamide  COc1ccc(C(=O)N(C)C)cc1   \n",
       "1           1          methanesulfonyl chloride            CS(=O)(=O)Cl   \n",
       "2           2                 3-methylbut-1-ene                C=CC(C)C   \n",
       "\n",
       "    expt   calc  \n",
       "0 -11.01 -9.625  \n",
       "1  -4.87 -6.219  \n",
       "2   1.83  2.452  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Observation**\n",
    "* The column containing the SMILES must be named 'smiles' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Extract relevant data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol_data = sol_data[['smiles',prop_tag]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>expt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COc1ccc(C(=O)N(C)C)cc1</td>\n",
       "      <td>-11.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CS(=O)(=O)Cl</td>\n",
       "      <td>-4.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C=CC(C)C</td>\n",
       "      <td>1.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CCc1cnccn1</td>\n",
       "      <td>-5.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CCCCCCCO</td>\n",
       "      <td>-4.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   smiles   expt\n",
       "0  COc1ccc(C(=O)N(C)C)cc1 -11.01\n",
       "1            CS(=O)(=O)Cl  -4.87\n",
       "2                C=CC(C)C   1.83\n",
       "3              CCc1cnccn1  -5.45\n",
       "4                CCCCCCCO  -4.21"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(642, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **SMILES check from RDKit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol_data, bad_smiles_list = utils.check_smiles(sol_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(642, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(642,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol_data.iloc[:,1].values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters optimization with GPyOpt (Bayesian optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dhyp_range = [int(2**itn) for itn in range(1,11)] # \n",
    "\n",
    "if data_name != 'Lipophilicity':\n",
    "    bounds = [\n",
    "        {'name': 'lstmunits', 'type': 'discrete', 'domain': dhyp_range}, \n",
    "        {'name': 'denseunits', 'type': 'discrete', 'domain': dhyp_range}, \n",
    "        {'name': 'embedding', 'type': 'discrete', 'domain': dhyp_range}\n",
    "    ]\n",
    "else:\n",
    "    bounds = [\n",
    "        {'name': 'lstmunits', 'type': 'discrete', 'domain': dhyp_range}, \n",
    "        {'name': 'denseunits', 'type': 'discrete', 'domain': dhyp_range}, \n",
    "        {'name': 'embedding', 'type': 'discrete', 'domain': dhyp_range}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs detected and configured.\n",
      "1 GPU device(s) will be used.\n",
      "\n",
      "***Data augmentation to True***\n",
      "\n",
      "***SMILES_X starts...***\n",
      "\n",
      "\n",
      "******\n",
      "***Fold #0 initiated...***\n",
      "******\n",
      "***Splitting and standardization of the dataset.***\n",
      "\n",
      "Scaler: RobustScaler(copy=True, quantile_range=(5.0, 95.0), with_centering=True,\n",
      "             with_scaling=True)\n",
      "Train/valid/test splits: 0.67/0.17/0.17\n",
      "\n",
      "\n",
      "Enumerated SMILES:\n",
      "\tTraining set: 3538\n",
      "\tValidation set: 892\n",
      "\tTest set: 925\n",
      "\n",
      "***Tokenization of SMILES.***\n",
      "\n",
      "Examples of tokenized SMILES from a training set:\n",
      "[[' ', 'C', 'S', '(', '=', 'O', ')', '(', '=', 'O', ')', 'Cl', ' '], [' ', 'S', '(', '=', 'O', ')', '(', '=', 'O', ')', '(', 'Cl', ')', 'C', ' '], [' ', 'O', '=', 'S', '(', '=', 'O', ')', '(', 'Cl', ')', 'C', ' '], [' ', 'O', '=', 'S', '(', 'Cl', ')', '(', 'C', ')', '=', 'O', ' '], [' ', 'Cl', 'S', '(', 'C', ')', '(', '=', 'O', ')', '=', 'O', ' ']]\n",
      "\n",
      "Number of tokens only present in a training set: 31\n",
      "\n",
      "Number of tokens only present in a validation set: 27\n",
      "Is the validation set a subset of the training set: False\n",
      "What are the tokens by which they differ: {'[S+2]'}\n",
      "\n",
      "Number of tokens only present in a test set: 25\n",
      "Is the test set a subset of the training set: True\n",
      "What are the tokens by which they differ: set()\n",
      "Is the test set a subset of the validation set: True\n",
      "What are the tokens by which they differ: set()\n",
      "\n",
      "Full vocabulary: ['S', 'C', '[C@@H]', '-', 'O', '5', '3', 'n', 's', 'Br', '[C@H]', '=', '[C@@]', '4', '(', '1', '[nH]', 'P', '[C@]', '#', ' ', 'I', 'Cl', '[N+]', '/', 'c', 'F', ')', '2', 'N', '[O-]', '[S+2]']\n",
      "Of size: 32\n",
      "\n",
      "Maximum length of tokenized SMILES: 50 tokens (termination spaces included)\n",
      "\n",
      "***Bayesian Optimization of the SMILESX's architecture.***\n",
      "\n",
      "Random initialization:\n",
      "\n",
      "Model: [64, 16, 256]\n",
      "Train MSE mean: 0.1489, MSE std: 0.0507\n",
      "Model: [64, 256, 16]\n",
      "Train MSE mean: 0.1249, MSE std: 0.0270\n",
      "Model: [2, 2, 8]\n",
      "Train MSE mean: 0.1289, MSE std: 0.0429\n",
      "Model: [16, 64, 256]\n",
      "Train MSE mean: 0.2601, MSE std: 0.2540\n",
      "Model: [2, 2, 2]\n",
      "Train MSE mean: 0.1329, MSE std: 0.0812\n",
      "Optimization:\n",
      "\n",
      "Model: [2, 2, 64]\n",
      "Train MSE mean: 0.1769, MSE std: 0.1950\n",
      "Model: [1024, 512, 8]\n",
      "Train MSE mean: 0.1004, MSE std: 0.0007\n",
      "Model: [2, 512, 1024]\n",
      "Train MSE mean: 0.1454, MSE std: 0.0504\n",
      "Model: [64, 1024, 128]\n",
      "Train MSE mean: 0.1618, MSE std: 0.0638\n",
      "Model: [1024, 16, 1024]\n",
      "Train MSE mean: 0.1314, MSE std: 0.0456\n",
      "\n",
      "The architecture for this datatset is:\n",
      "\tLSTM units: 1024\n",
      "\tDense units: 512\n",
      "\tEmbedding dimensions 8\n",
      "***Training of the best model.***\n",
      "\n",
      "Best model summary:\n",
      "\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 51)]              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 51, 8)             272       \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 51, 2048)          8462336   \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 51, 512)           1049088   \n",
      "_________________________________________________________________\n",
      "attention_m (AttentionM)     (None, 512)               563       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 9,512,772\n",
      "Trainable params: 9,512,772\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 56 steps, validate for 14 steps\n",
      "Epoch 1/400\n",
      "56/56 [==============================] - 4s 78ms/step - loss: 0.1226 - mean_absolute_error: 0.2570 - mean_squared_error: 0.1229 - val_loss: 0.0823 - val_mean_absolute_error: 0.2149 - val_mean_squared_error: 0.0824\n",
      "Epoch 2/400\n",
      "56/56 [==============================] - 2s 33ms/step - loss: 0.0742 - mean_absolute_error: 0.2182 - mean_squared_error: 0.0747 - val_loss: 0.0771 - val_mean_absolute_error: 0.2100 - val_mean_squared_error: 0.0772\n",
      "Epoch 3/400\n",
      "56/56 [==============================] - 2s 33ms/step - loss: 0.0582 - mean_absolute_error: 0.1861 - mean_squared_error: 0.0586 - val_loss: 0.0590 - val_mean_absolute_error: 0.1883 - val_mean_squared_error: 0.0592\n",
      "Epoch 4/400\n",
      "56/56 [==============================] - 2s 32ms/step - loss: 0.0499 - mean_absolute_error: 0.1725 - mean_squared_error: 0.0504 - val_loss: 0.0542 - val_mean_absolute_error: 0.1737 - val_mean_squared_error: 0.0544\n",
      "Epoch 5/400\n",
      "56/56 [==============================] - 2s 35ms/step - loss: 0.0439 - mean_absolute_error: 0.1589 - mean_squared_error: 0.0441 - val_loss: 0.0452 - val_mean_absolute_error: 0.1565 - val_mean_squared_error: 0.0453\n",
      "Epoch 6/400\n",
      "56/56 [==============================] - 2s 32ms/step - loss: 0.0409 - mean_absolute_error: 0.1497 - mean_squared_error: 0.0412 - val_loss: 0.0411 - val_mean_absolute_error: 0.1538 - val_mean_squared_error: 0.0412\n",
      "Epoch 7/400\n",
      "56/56 [==============================] - 2s 32ms/step - loss: 0.0402 - mean_absolute_error: 0.1481 - mean_squared_error: 0.0401 - val_loss: 0.0401 - val_mean_absolute_error: 0.1489 - val_mean_squared_error: 0.0402\n",
      "Epoch 8/400\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 0.0341 - mean_absolute_error: 0.1419 - mean_squared_error: 0.0345 - val_loss: 0.0462 - val_mean_absolute_error: 0.1586 - val_mean_squared_error: 0.0464\n",
      "Epoch 9/400\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 0.0323 - mean_absolute_error: 0.1340 - mean_squared_error: 0.0326 - val_loss: 0.0417 - val_mean_absolute_error: 0.1509 - val_mean_squared_error: 0.0419\n",
      "Epoch 10/400\n",
      "56/56 [==============================] - 2s 32ms/step - loss: 0.0331 - mean_absolute_error: 0.1363 - mean_squared_error: 0.0334 - val_loss: 0.0369 - val_mean_absolute_error: 0.1416 - val_mean_squared_error: 0.0371\n",
      "Epoch 11/400\n",
      "56/56 [==============================] - 2s 32ms/step - loss: 0.0272 - mean_absolute_error: 0.1254 - mean_squared_error: 0.0274 - val_loss: 0.0314 - val_mean_absolute_error: 0.1316 - val_mean_squared_error: 0.0315\n",
      "Epoch 12/400\n",
      "56/56 [==============================] - 2s 33ms/step - loss: 0.0219 - mean_absolute_error: 0.1135 - mean_squared_error: 0.0221 - val_loss: 0.0260 - val_mean_absolute_error: 0.1199 - val_mean_squared_error: 0.0260\n",
      "Epoch 13/400\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 0.0220 - mean_absolute_error: 0.1160 - mean_squared_error: 0.0222 - val_loss: 0.0271 - val_mean_absolute_error: 0.1246 - val_mean_squared_error: 0.0272\n",
      "Epoch 14/400\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 0.0784 - mean_absolute_error: 0.1381 - mean_squared_error: 0.0789 - val_loss: 0.0412 - val_mean_absolute_error: 0.1529 - val_mean_squared_error: 0.0413\n",
      "Epoch 15/400\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 0.0272 - mean_absolute_error: 0.1232 - mean_squared_error: 0.0274 - val_loss: 0.0296 - val_mean_absolute_error: 0.1294 - val_mean_squared_error: 0.0297\n",
      "Epoch 16/400\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 0.0209 - mean_absolute_error: 0.1124 - mean_squared_error: 0.0211 - val_loss: 0.0265 - val_mean_absolute_error: 0.1214 - val_mean_squared_error: 0.0266\n",
      "Epoch 17/400\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 0.0193 - mean_absolute_error: 0.1067 - mean_squared_error: 0.0193 - val_loss: 0.0270 - val_mean_absolute_error: 0.1219 - val_mean_squared_error: 0.0271\n",
      "Epoch 18/400\n",
      "56/56 [==============================] - 2s 32ms/step - loss: 0.0188 - mean_absolute_error: 0.1056 - mean_squared_error: 0.0190 - val_loss: 0.0252 - val_mean_absolute_error: 0.1165 - val_mean_squared_error: 0.0253\n",
      "Epoch 19/400\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 0.0167 - mean_absolute_error: 0.0990 - mean_squared_error: 0.0168 - val_loss: 0.0256 - val_mean_absolute_error: 0.1188 - val_mean_squared_error: 0.0256\n",
      "Epoch 20/400\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 0.0167 - mean_absolute_error: 0.0986 - mean_squared_error: 0.0168 - val_loss: 0.0311 - val_mean_absolute_error: 0.1242 - val_mean_squared_error: 0.0312\n",
      "Epoch 21/400\n",
      "56/56 [==============================] - 2s 34ms/step - loss: 0.0160 - mean_absolute_error: 0.0968 - mean_squared_error: 0.0160 - val_loss: 0.0242 - val_mean_absolute_error: 0.1097 - val_mean_squared_error: 0.0243\n",
      "Epoch 22/400\n",
      "56/56 [==============================] - 2s 32ms/step - loss: 0.0144 - mean_absolute_error: 0.0939 - mean_squared_error: 0.0146 - val_loss: 0.0230 - val_mean_absolute_error: 0.1096 - val_mean_squared_error: 0.0231\n",
      "Epoch 23/400\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 0.0132 - mean_absolute_error: 0.0901 - mean_squared_error: 0.0133 - val_loss: 0.0237 - val_mean_absolute_error: 0.1082 - val_mean_squared_error: 0.0237\n",
      "Epoch 24/400\n",
      "56/56 [==============================] - 2s 28ms/step - loss: 0.0142 - mean_absolute_error: 0.0933 - mean_squared_error: 0.0143 - val_loss: 0.0240 - val_mean_absolute_error: 0.1086 - val_mean_squared_error: 0.0241\n",
      "Epoch 25/400\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 0.0123 - mean_absolute_error: 0.0863 - mean_squared_error: 0.0124 - val_loss: 0.0254 - val_mean_absolute_error: 0.1132 - val_mean_squared_error: 0.0255\n",
      "Epoch 26/400\n",
      "56/56 [==============================] - 2s 32ms/step - loss: 0.0133 - mean_absolute_error: 0.0887 - mean_squared_error: 0.0134 - val_loss: 0.0226 - val_mean_absolute_error: 0.1059 - val_mean_squared_error: 0.0227\n",
      "Epoch 27/400\n",
      "56/56 [==============================] - 2s 33ms/step - loss: 0.0116 - mean_absolute_error: 0.0839 - mean_squared_error: 0.0117 - val_loss: 0.0225 - val_mean_absolute_error: 0.1043 - val_mean_squared_error: 0.0226\n",
      "Epoch 28/400\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 0.0125 - mean_absolute_error: 0.0869 - mean_squared_error: 0.0126 - val_loss: 0.0237 - val_mean_absolute_error: 0.1133 - val_mean_squared_error: 0.0237\n",
      "Epoch 29/400\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 0.0128 - mean_absolute_error: 0.0886 - mean_squared_error: 0.0129 - val_loss: 0.0265 - val_mean_absolute_error: 0.1279 - val_mean_squared_error: 0.0266\n",
      "Epoch 30/400\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 0.0112 - mean_absolute_error: 0.0824 - mean_squared_error: 0.0113 - val_loss: 0.0229 - val_mean_absolute_error: 0.1063 - val_mean_squared_error: 0.0230\n",
      "Epoch 31/400\n",
      "56/56 [==============================] - 2s 28ms/step - loss: 0.0121 - mean_absolute_error: 0.0845 - mean_squared_error: 0.0122 - val_loss: 0.0226 - val_mean_absolute_error: 0.1028 - val_mean_squared_error: 0.0227\n",
      "Epoch 32/400\n",
      "56/56 [==============================] - 2s 32ms/step - loss: 0.0110 - mean_absolute_error: 0.0812 - mean_squared_error: 0.0111 - val_loss: 0.0223 - val_mean_absolute_error: 0.1014 - val_mean_squared_error: 0.0224\n",
      "Epoch 33/400\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 0.0122 - mean_absolute_error: 0.0849 - mean_squared_error: 0.0122 - val_loss: 0.0246 - val_mean_absolute_error: 0.1058 - val_mean_squared_error: 0.0247\n",
      "Epoch 34/400\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 0.0112 - mean_absolute_error: 0.0815 - mean_squared_error: 0.0113 - val_loss: 0.0261 - val_mean_absolute_error: 0.1088 - val_mean_squared_error: 0.0262\n",
      "Epoch 35/400\n",
      "56/56 [==============================] - 2s 28ms/step - loss: 0.0109 - mean_absolute_error: 0.0812 - mean_squared_error: 0.0110 - val_loss: 0.0250 - val_mean_absolute_error: 0.1059 - val_mean_squared_error: 0.0251\n",
      "Epoch 36/400\n",
      "56/56 [==============================] - 2s 28ms/step - loss: 0.0101 - mean_absolute_error: 0.0785 - mean_squared_error: 0.0102 - val_loss: 0.0227 - val_mean_absolute_error: 0.0999 - val_mean_squared_error: 0.0228\n",
      "Epoch 37/400\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 0.0113 - mean_absolute_error: 0.0816 - mean_squared_error: 0.0112 - val_loss: 0.0224 - val_mean_absolute_error: 0.1025 - val_mean_squared_error: 0.0224\n",
      "Epoch 38/400\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 0.0122 - mean_absolute_error: 0.0864 - mean_squared_error: 0.0123 - val_loss: 0.0223 - val_mean_absolute_error: 0.1094 - val_mean_squared_error: 0.0224\n",
      "Epoch 39/400\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 0.0114 - mean_absolute_error: 0.0833 - mean_squared_error: 0.0114 - val_loss: 0.0266 - val_mean_absolute_error: 0.1137 - val_mean_squared_error: 0.0267\n",
      "Epoch 40/400\n",
      "56/56 [==============================] - 2s 28ms/step - loss: 0.0112 - mean_absolute_error: 0.0814 - mean_squared_error: 0.0112 - val_loss: 0.0234 - val_mean_absolute_error: 0.0997 - val_mean_squared_error: 0.0235\n",
      "Epoch 41/400\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 0.0095 - mean_absolute_error: 0.0749 - mean_squared_error: 0.0096 - val_loss: 0.0240 - val_mean_absolute_error: 0.1018 - val_mean_squared_error: 0.0241\n",
      "Epoch 42/400\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 0.0104 - mean_absolute_error: 0.0789 - mean_squared_error: 0.0105 - val_loss: 0.0230 - val_mean_absolute_error: 0.1010 - val_mean_squared_error: 0.0231\n",
      "Epoch 43/400\n",
      "56/56 [==============================] - 2s 28ms/step - loss: 0.0098 - mean_absolute_error: 0.0771 - mean_squared_error: 0.0098 - val_loss: 0.0227 - val_mean_absolute_error: 0.0992 - val_mean_squared_error: 0.0228\n",
      "Epoch 44/400\n",
      "56/56 [==============================] - 2s 28ms/step - loss: 0.0091 - mean_absolute_error: 0.0736 - mean_squared_error: 0.0092 - val_loss: 0.0250 - val_mean_absolute_error: 0.1060 - val_mean_squared_error: 0.0251\n",
      "Epoch 45/400\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 0.0086 - mean_absolute_error: 0.0721 - mean_squared_error: 0.0087 - val_loss: 0.0241 - val_mean_absolute_error: 0.1018 - val_mean_squared_error: 0.0242\n",
      "Epoch 46/400\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 0.0089 - mean_absolute_error: 0.0730 - mean_squared_error: 0.0090 - val_loss: 0.0244 - val_mean_absolute_error: 0.0999 - val_mean_squared_error: 0.0244\n",
      "Epoch 47/400\n",
      "56/56 [==============================] - 2s 28ms/step - loss: 0.0088 - mean_absolute_error: 0.0722 - mean_squared_error: 0.0088 - val_loss: 0.0228 - val_mean_absolute_error: 0.1001 - val_mean_squared_error: 0.0229\n",
      "Epoch 48/400\n",
      "56/56 [==============================] - 2s 28ms/step - loss: 0.1057 - mean_absolute_error: 0.1795 - mean_squared_error: 0.1067 - val_loss: 0.1392 - val_mean_absolute_error: 0.2748 - val_mean_squared_error: 0.1394\n",
      "Epoch 49/400\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 0.9779 - mean_absolute_error: 0.7568 - mean_squared_error: 0.9854 - val_loss: 0.1286 - val_mean_absolute_error: 0.3046 - val_mean_squared_error: 0.1287\n",
      "Epoch 50/400\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 0.1347 - mean_absolute_error: 0.2781 - mean_squared_error: 0.1356 - val_loss: 0.1236 - val_mean_absolute_error: 0.2499 - val_mean_squared_error: 0.1238\n",
      "Epoch 51/400\n",
      "56/56 [==============================] - 2s 28ms/step - loss: 0.1097 - mean_absolute_error: 0.2451 - mean_squared_error: 0.1102 - val_loss: 0.1037 - val_mean_absolute_error: 0.2498 - val_mean_squared_error: 0.1039\n",
      "Epoch 52/400\n",
      "56/56 [==============================] - 2s 28ms/step - loss: 0.1051 - mean_absolute_error: 0.2391 - mean_squared_error: 0.1056 - val_loss: 0.1054 - val_mean_absolute_error: 0.2337 - val_mean_squared_error: 0.1056\n",
      "Epoch 53/400\n",
      "56/56 [==============================] - 2s 28ms/step - loss: 0.1043 - mean_absolute_error: 0.2366 - mean_squared_error: 0.1048 - val_loss: 0.1024 - val_mean_absolute_error: 0.2412 - val_mean_squared_error: 0.1026\n",
      "Epoch 54/400\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 0.1047 - mean_absolute_error: 0.2381 - mean_squared_error: 0.1050 - val_loss: 0.1017 - val_mean_absolute_error: 0.2386 - val_mean_squared_error: 0.1019\n",
      "Epoch 55/400\n",
      "56/56 [==============================] - 2s 28ms/step - loss: 0.1048 - mean_absolute_error: 0.2384 - mean_squared_error: 0.1052 - val_loss: 0.1031 - val_mean_absolute_error: 0.2362 - val_mean_squared_error: 0.1033\n",
      "Epoch 56/400\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 0.1038 - mean_absolute_error: 0.2381 - mean_squared_error: 0.1042 - val_loss: 0.1093 - val_mean_absolute_error: 0.2353 - val_mean_squared_error: 0.1095\n",
      "Epoch 57/400\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 0.1039 - mean_absolute_error: 0.2330 - mean_squared_error: 0.1044 - val_loss: 0.1023 - val_mean_absolute_error: 0.2435 - val_mean_squared_error: 0.1024\n",
      "Best val_loss @ Epoch #32\n",
      "\n",
      "***Predictions from the best model.***\n",
      "\n",
      "For the training set:\n",
      "MAE: 0.8303 RMSE: 1.0854 R^2: 0.9173\n",
      "\n",
      "For the validation set:\n",
      "MAE: 1.0512 RMSE: 1.6203 R^2: 0.8192\n",
      "\n",
      "For the test set:\n",
      "MAE: 1.0462 RMSE: 1.3230 R^2: 0.8950\n",
      "\n",
      "******\n",
      "***Fold #1 initiated...***\n",
      "******\n",
      "***Splitting and standardization of the dataset.***\n",
      "\n",
      "Scaler: RobustScaler(copy=True, quantile_range=(5.0, 95.0), with_centering=True,\n",
      "             with_scaling=True)\n",
      "Train/valid/test splits: 0.67/0.17/0.17\n",
      "\n",
      "\n",
      "Enumerated SMILES:\n",
      "\tTraining set: 3620\n",
      "\tValidation set: 880\n",
      "\tTest set: 855\n",
      "\n",
      "***Tokenization of SMILES.***\n",
      "\n",
      "Examples of tokenized SMILES from a training set:\n",
      "[[' ', 'C', 'O', 'c', '1', 'c', 'c', 'c', '(', 'C', '(', '=', 'O', ')', 'N', '(', 'C', ')', 'C', ')', 'c', 'c', '1', ' '], [' ', 'O', '(', 'c', '1', 'c', 'c', 'c', '(', 'C', '(', '=', 'O', ')', 'N', '(', 'C', ')', 'C', ')', 'c', 'c', '1', ')', 'C', ' '], [' ', 'c', '1', '(', 'O', 'C', ')', 'c', 'c', 'c', '(', 'C', '(', '=', 'O', ')', 'N', '(', 'C', ')', 'C', ')', 'c', 'c', '1', ' '], [' ', 'c', '1', 'c', 'c', '(', 'C', '(', '=', 'O', ')', 'N', '(', 'C', ')', 'C', ')', 'c', 'c', 'c', '1', 'O', 'C', ' '], [' ', 'c', '1', 'c', '(', 'C', '(', '=', 'O', ')', 'N', '(', 'C', ')', 'C', ')', 'c', 'c', 'c', '(', 'O', 'C', ')', 'c', '1', ' ']]\n",
      "\n",
      "Number of tokens only present in a training set: 32\n",
      "\n",
      "Number of tokens only present in a validation set: 27\n",
      "Is the validation set a subset of the training set: True\n",
      "What are the tokens by which they differ: set()\n",
      "\n",
      "Number of tokens only present in a test set: 28\n",
      "Is the test set a subset of the training set: True\n",
      "What are the tokens by which they differ: set()\n",
      "Is the test set a subset of the validation set: False\n",
      "What are the tokens by which they differ: {'s', '/', '4'}\n",
      "\n",
      "Full vocabulary: ['S', 'C', '[C@@H]', '-', 'O', '5', '3', 'n', 's', 'Br', '[C@H]', '=', '[C@@]', '4', '(', '1', '[nH]', 'P', '[C@]', '#', ' ', 'I', 'Cl', '[N+]', '/', 'c', 'F', ')', '2', 'N', '[O-]', '[S+2]']\n",
      "Of size: 32\n",
      "\n",
      "Maximum length of tokenized SMILES: 50 tokens (termination spaces included)\n",
      "\n",
      "***Bayesian Optimization of the SMILESX's architecture.***\n",
      "\n",
      "Random initialization:\n",
      "\n",
      "Model: [16, 4, 64]\n",
      "Train MSE mean: 0.1536, MSE std: 0.0283\n",
      "Model: [2, 8, 32]\n",
      "Train MSE mean: 0.1976, MSE std: 0.1044\n",
      "Model: [256, 8, 32]\n",
      "Train MSE mean: 0.1214, MSE std: 0.0070\n",
      "Model: [16, 4, 4]\n",
      "Train MSE mean: 0.1312, MSE std: 0.0246\n",
      "Model: [1024, 32, 2]\n",
      "Train MSE mean: 0.1159, MSE std: 0.0004\n",
      "Optimization:\n",
      "\n",
      "Model: [64, 256, 2]\n",
      "Train MSE mean: 0.1178, MSE std: 0.0030\n",
      "Model: [512, 256, 2]\n",
      "Train MSE mean: 0.1159, MSE std: 0.0006\n",
      "Model: [64, 1024, 64]\n",
      "Train MSE mean: 0.1640, MSE std: 0.0686\n",
      "Model: [128, 16, 32]\n",
      "Train MSE mean: 0.1352, MSE std: 0.0163\n",
      "Model: [512, 512, 1024]\n",
      "Train MSE mean: 0.1755, MSE std: 0.0753\n",
      "\n",
      "The architecture for this datatset is:\n",
      "\tLSTM units: 1024\n",
      "\tDense units: 32\n",
      "\tEmbedding dimensions 2\n",
      "***Training of the best model.***\n",
      "\n",
      "Best model summary:\n",
      "\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 51)]              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 51, 2)             68        \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 51, 2048)          8413184   \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 51, 32)            65568     \n",
      "_________________________________________________________________\n",
      "attention_m (AttentionM)     (None, 32)                83        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 8,478,936\n",
      "Trainable params: 8,478,936\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 57 steps, validate for 14 steps\n",
      "Epoch 1/400\n",
      "57/57 [==============================] - 4s 67ms/step - loss: 0.1191 - mean_absolute_error: 0.2609 - mean_squared_error: 0.1194 - val_loss: 0.1190 - val_mean_absolute_error: 0.2291 - val_mean_squared_error: 0.1199\n",
      "Epoch 2/400\n",
      "57/57 [==============================] - 2s 30ms/step - loss: 0.1058 - mean_absolute_error: 0.2447 - mean_squared_error: 0.1062 - val_loss: 0.1124 - val_mean_absolute_error: 0.2249 - val_mean_squared_error: 0.1134\n",
      "Epoch 3/400\n",
      "57/57 [==============================] - 2s 32ms/step - loss: 0.1046 - mean_absolute_error: 0.2443 - mean_squared_error: 0.1051 - val_loss: 0.1118 - val_mean_absolute_error: 0.2235 - val_mean_squared_error: 0.1127\n",
      "Epoch 4/400\n",
      "57/57 [==============================] - 2s 30ms/step - loss: 0.0965 - mean_absolute_error: 0.2340 - mean_squared_error: 0.0969 - val_loss: 0.0988 - val_mean_absolute_error: 0.2160 - val_mean_squared_error: 0.0998\n",
      "Epoch 5/400\n",
      "57/57 [==============================] - 2s 30ms/step - loss: 0.0904 - mean_absolute_error: 0.2260 - mean_squared_error: 0.0908 - val_loss: 0.0888 - val_mean_absolute_error: 0.2080 - val_mean_squared_error: 0.0900\n",
      "Epoch 6/400\n",
      "57/57 [==============================] - 2s 32ms/step - loss: 0.0813 - mean_absolute_error: 0.2098 - mean_squared_error: 0.0815 - val_loss: 0.0857 - val_mean_absolute_error: 0.2094 - val_mean_squared_error: 0.0865\n",
      "Epoch 7/400\n",
      "57/57 [==============================] - 2s 30ms/step - loss: 0.0711 - mean_absolute_error: 0.2045 - mean_squared_error: 0.0714 - val_loss: 0.0713 - val_mean_absolute_error: 0.1818 - val_mean_squared_error: 0.0720\n",
      "Epoch 8/400\n",
      "57/57 [==============================] - 2s 32ms/step - loss: 0.0611 - mean_absolute_error: 0.1916 - mean_squared_error: 0.0614 - val_loss: 0.0690 - val_mean_absolute_error: 0.1708 - val_mean_squared_error: 0.0697\n",
      "Epoch 9/400\n",
      "57/57 [==============================] - 2s 29ms/step - loss: 0.0549 - mean_absolute_error: 0.1816 - mean_squared_error: 0.0550 - val_loss: 0.0590 - val_mean_absolute_error: 0.1656 - val_mean_squared_error: 0.0596\n",
      "Epoch 10/400\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 0.0505 - mean_absolute_error: 0.1753 - mean_squared_error: 0.0507 - val_loss: 6.5268 - val_mean_absolute_error: 0.9248 - val_mean_squared_error: 6.6449\n",
      "Epoch 11/400\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 0.1677 - mean_absolute_error: 0.2024 - mean_squared_error: 0.1639 - val_loss: 0.0622 - val_mean_absolute_error: 0.1575 - val_mean_squared_error: 0.0628\n",
      "Epoch 12/400\n",
      "57/57 [==============================] - 2s 30ms/step - loss: 0.0486 - mean_absolute_error: 0.1683 - mean_squared_error: 0.0488 - val_loss: 0.0523 - val_mean_absolute_error: 0.1564 - val_mean_squared_error: 0.0528\n",
      "Epoch 13/400\n",
      "57/57 [==============================] - 2s 30ms/step - loss: 0.0435 - mean_absolute_error: 0.1610 - mean_squared_error: 0.0435 - val_loss: 0.0488 - val_mean_absolute_error: 0.1685 - val_mean_squared_error: 0.0493\n",
      "Epoch 14/400\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 0.0401 - mean_absolute_error: 0.1579 - mean_squared_error: 0.0403 - val_loss: 0.0489 - val_mean_absolute_error: 0.1579 - val_mean_squared_error: 0.0493\n",
      "Epoch 15/400\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 2.1197 - mean_absolute_error: 0.6342 - mean_squared_error: 2.1356 - val_loss: 9.5340 - val_mean_absolute_error: 3.0691 - val_mean_squared_error: 9.5348\n",
      "Epoch 16/400\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 1.0233 - mean_absolute_error: 0.7255 - mean_squared_error: 1.0270 - val_loss: 0.1326 - val_mean_absolute_error: 0.2434 - val_mean_squared_error: 0.1332\n",
      "Epoch 17/400\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 0.1173 - mean_absolute_error: 0.2555 - mean_squared_error: 0.1174 - val_loss: 0.1476 - val_mean_absolute_error: 0.2614 - val_mean_squared_error: 0.1482\n",
      "Epoch 18/400\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 0.1346 - mean_absolute_error: 0.2798 - mean_squared_error: 0.1347 - val_loss: 0.1922 - val_mean_absolute_error: 0.3740 - val_mean_squared_error: 0.1930\n",
      "Epoch 19/400\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 0.1284 - mean_absolute_error: 0.2720 - mean_squared_error: 0.1288 - val_loss: 0.1169 - val_mean_absolute_error: 0.2217 - val_mean_squared_error: 0.1176\n",
      "Epoch 20/400\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 0.1407 - mean_absolute_error: 0.2831 - mean_squared_error: 0.1410 - val_loss: 0.1190 - val_mean_absolute_error: 0.2419 - val_mean_squared_error: 0.1197\n",
      "Epoch 21/400\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 0.1330 - mean_absolute_error: 0.2809 - mean_squared_error: 0.1326 - val_loss: 0.1187 - val_mean_absolute_error: 0.2392 - val_mean_squared_error: 0.1194\n",
      "Epoch 22/400\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 0.1339 - mean_absolute_error: 0.2756 - mean_squared_error: 0.1343 - val_loss: 0.1297 - val_mean_absolute_error: 0.2699 - val_mean_squared_error: 0.1303\n",
      "Epoch 23/400\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 0.1309 - mean_absolute_error: 0.2788 - mean_squared_error: 0.1304 - val_loss: 0.1359 - val_mean_absolute_error: 0.2422 - val_mean_squared_error: 0.1366\n",
      "Epoch 24/400\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 0.1246 - mean_absolute_error: 0.2636 - mean_squared_error: 0.1249 - val_loss: 0.1624 - val_mean_absolute_error: 0.3307 - val_mean_squared_error: 0.1631\n",
      "Epoch 25/400\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 0.1276 - mean_absolute_error: 0.2701 - mean_squared_error: 0.1280 - val_loss: 0.1140 - val_mean_absolute_error: 0.2211 - val_mean_squared_error: 0.1147\n",
      "Epoch 26/400\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 0.1198 - mean_absolute_error: 0.2593 - mean_squared_error: 0.1202 - val_loss: 0.1881 - val_mean_absolute_error: 0.3695 - val_mean_squared_error: 0.1888\n",
      "Epoch 27/400\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 0.1522 - mean_absolute_error: 0.3064 - mean_squared_error: 0.1521 - val_loss: 0.1307 - val_mean_absolute_error: 0.2343 - val_mean_squared_error: 0.1313\n",
      "Epoch 28/400\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 0.1210 - mean_absolute_error: 0.2631 - mean_squared_error: 0.1214 - val_loss: 0.1242 - val_mean_absolute_error: 0.2590 - val_mean_squared_error: 0.1249\n",
      "Epoch 29/400\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 0.1186 - mean_absolute_error: 0.2536 - mean_squared_error: 0.1189 - val_loss: 0.1156 - val_mean_absolute_error: 0.2364 - val_mean_squared_error: 0.1163\n",
      "Epoch 30/400\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 0.1183 - mean_absolute_error: 0.2579 - mean_squared_error: 0.1185 - val_loss: 0.1132 - val_mean_absolute_error: 0.2281 - val_mean_squared_error: 0.1138\n",
      "Epoch 31/400\n",
      "57/57 [==============================] - 2s 26ms/step - loss: 0.1470 - mean_absolute_error: 0.3072 - mean_squared_error: 0.1457 - val_loss: 0.1428 - val_mean_absolute_error: 0.2982 - val_mean_squared_error: 0.1435\n",
      "Epoch 32/400\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 0.1318 - mean_absolute_error: 0.2669 - mean_squared_error: 0.1319 - val_loss: 0.1403 - val_mean_absolute_error: 0.2926 - val_mean_squared_error: 0.1410\n",
      "Epoch 33/400\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 0.1288 - mean_absolute_error: 0.2719 - mean_squared_error: 0.1292 - val_loss: 0.1331 - val_mean_absolute_error: 0.2380 - val_mean_squared_error: 0.1338\n",
      "Epoch 34/400\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 0.1168 - mean_absolute_error: 0.2580 - mean_squared_error: 0.1169 - val_loss: 0.1121 - val_mean_absolute_error: 0.2188 - val_mean_squared_error: 0.1128\n",
      "Epoch 35/400\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 0.1232 - mean_absolute_error: 0.2661 - mean_squared_error: 0.1235 - val_loss: 0.1191 - val_mean_absolute_error: 0.2220 - val_mean_squared_error: 0.1197\n",
      "Epoch 36/400\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 0.1285 - mean_absolute_error: 0.2787 - mean_squared_error: 0.1289 - val_loss: 0.1166 - val_mean_absolute_error: 0.2423 - val_mean_squared_error: 0.1173\n",
      "Epoch 37/400\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 0.1186 - mean_absolute_error: 0.2589 - mean_squared_error: 0.1189 - val_loss: 0.2228 - val_mean_absolute_error: 0.3651 - val_mean_squared_error: 0.2234\n",
      "Epoch 38/400\n",
      "57/57 [==============================] - 2s 27ms/step - loss: 0.1345 - mean_absolute_error: 0.2866 - mean_squared_error: 0.1344 - val_loss: 0.1148 - val_mean_absolute_error: 0.2161 - val_mean_squared_error: 0.1154\n",
      "Best val_loss @ Epoch #13\n",
      "\n",
      "***Predictions from the best model.***\n",
      "\n",
      "For the training set:\n",
      "MAE: 1.7979 RMSE: 2.2176 R^2: 0.6782\n",
      "\n",
      "For the validation set:\n",
      "MAE: 1.8308 RMSE: 2.3742 R^2: 0.6399\n",
      "\n",
      "For the test set:\n",
      "MAE: 1.6894 RMSE: 2.0679 R^2: 0.6287\n",
      "\n",
      "******\n",
      "***Fold #2 initiated...***\n",
      "******\n",
      "***Splitting and standardization of the dataset.***\n",
      "\n",
      "Scaler: RobustScaler(copy=True, quantile_range=(5.0, 95.0), with_centering=True,\n",
      "             with_scaling=True)\n",
      "Train/valid/test splits: 0.67/0.17/0.17\n",
      "\n",
      "\n",
      "Enumerated SMILES:\n",
      "\tTraining set: 3552\n",
      "\tValidation set: 814\n",
      "\tTest set: 989\n",
      "\n",
      "***Tokenization of SMILES.***\n",
      "\n",
      "Examples of tokenized SMILES from a training set:\n",
      "[[' ', 'C', 'O', 'c', '1', 'c', 'c', 'c', '(', 'C', '(', '=', 'O', ')', 'N', '(', 'C', ')', 'C', ')', 'c', 'c', '1', ' '], [' ', 'O', '(', 'c', '1', 'c', 'c', 'c', '(', 'C', '(', '=', 'O', ')', 'N', '(', 'C', ')', 'C', ')', 'c', 'c', '1', ')', 'C', ' '], [' ', 'c', '1', '(', 'O', 'C', ')', 'c', 'c', 'c', '(', 'C', '(', '=', 'O', ')', 'N', '(', 'C', ')', 'C', ')', 'c', 'c', '1', ' '], [' ', 'c', '1', 'c', 'c', '(', 'C', '(', '=', 'O', ')', 'N', '(', 'C', ')', 'C', ')', 'c', 'c', 'c', '1', 'O', 'C', ' '], [' ', 'c', '1', 'c', '(', 'C', '(', '=', 'O', ')', 'N', '(', 'C', ')', 'C', ')', 'c', 'c', 'c', '(', 'O', 'C', ')', 'c', '1', ' ']]\n",
      "\n",
      "Number of tokens only present in a training set: 31\n",
      "\n",
      "Number of tokens only present in a validation set: 28\n",
      "Is the validation set a subset of the training set: True\n",
      "What are the tokens by which they differ: set()\n",
      "\n",
      "Number of tokens only present in a test set: 29\n",
      "Is the test set a subset of the training set: False\n",
      "What are the tokens by which they differ: {'5'}\n",
      "Is the test set a subset of the validation set: False\n",
      "What are the tokens by which they differ: {'5', '4'}\n",
      "\n",
      "Full vocabulary: ['S', 'C', '[C@@H]', '-', 'O', '5', '3', 'n', 's', 'Br', '[C@H]', '=', '[C@@]', '4', '(', '1', '[nH]', 'P', '[C@]', '#', ' ', 'I', 'Cl', '[N+]', '/', 'c', 'F', ')', '2', 'N', '[O-]', '[S+2]']\n",
      "Of size: 32\n",
      "\n",
      "Maximum length of tokenized SMILES: 50 tokens (termination spaces included)\n",
      "\n",
      "***Bayesian Optimization of the SMILESX's architecture.***\n",
      "\n",
      "Random initialization:\n",
      "\n",
      "Model: [16, 128, 1024]\n",
      "Train MSE mean: 0.2583, MSE std: 0.2128\n",
      "Model: [512, 16, 8]\n",
      "Train MSE mean: 0.1093, MSE std: 0.0014\n",
      "Model: [128, 256, 512]\n",
      "Train MSE mean: 0.1756, MSE std: 0.0851\n",
      "Model: [128, 8, 4]\n",
      "Train MSE mean: 0.1088, MSE std: 0.0029\n",
      "Model: [4, 64, 8]\n",
      "Train MSE mean: 0.1859, MSE std: 0.0661\n",
      "Optimization:\n",
      "\n",
      "Model: [32, 8, 2]\n",
      "Train MSE mean: 0.1095, MSE std: 0.0024\n",
      "Model: [256, 256, 128]\n",
      "Train MSE mean: 0.1309, MSE std: 0.0312\n",
      "Model: [4, 1024, 64]\n",
      "Train MSE mean: 0.2253, MSE std: 0.1122\n",
      "Model: [1024, 16, 8]\n",
      "Train MSE mean: 0.1087, MSE std: 0.0007\n",
      "Model: [512, 4, 256]\n",
      "Train MSE mean: 0.1509, MSE std: 0.0510\n",
      "\n",
      "The architecture for this datatset is:\n",
      "\tLSTM units: 1024\n",
      "\tDense units: 16\n",
      "\tEmbedding dimensions 8\n",
      "***Training of the best model.***\n",
      "\n",
      "Best model summary:\n",
      "\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 51)]              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 51, 8)             272       \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 51, 2048)          8462336   \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 51, 16)            32784     \n",
      "_________________________________________________________________\n",
      "attention_m (AttentionM)     (None, 16)                67        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 8,495,476\n",
      "Trainable params: 8,495,476\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 56 steps, validate for 13 steps\n",
      "Epoch 1/400\n",
      "56/56 [==============================] - 5s 90ms/step - loss: 0.1296 - mean_absolute_error: 0.2598 - mean_squared_error: 0.1302 - val_loss: 0.1242 - val_mean_absolute_error: 0.2842 - val_mean_squared_error: 0.1248\n",
      "Epoch 2/400\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 0.0899 - mean_absolute_error: 0.2234 - mean_squared_error: 0.0902 - val_loss: 0.0940 - val_mean_absolute_error: 0.2463 - val_mean_squared_error: 0.0953\n",
      "Epoch 3/400\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 0.0796 - mean_absolute_error: 0.2104 - mean_squared_error: 0.0799 - val_loss: 0.1018 - val_mean_absolute_error: 0.2697 - val_mean_squared_error: 0.1026\n",
      "Epoch 4/400\n",
      "56/56 [==============================] - 2s 32ms/step - loss: 0.0666 - mean_absolute_error: 0.1928 - mean_squared_error: 0.0670 - val_loss: 0.0667 - val_mean_absolute_error: 0.2030 - val_mean_squared_error: 0.0677\n",
      "Epoch 5/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.5039 - mean_absolute_error: 0.2330 - mean_squared_error: 0.5081 - val_loss: 0.1001 - val_mean_absolute_error: 0.2408 - val_mean_squared_error: 0.1013\n",
      "Epoch 6/400\n",
      "56/56 [==============================] - 2s 27ms/step - loss: 0.0914 - mean_absolute_error: 0.2228 - mean_squared_error: 0.0919 - val_loss: 0.0852 - val_mean_absolute_error: 0.2252 - val_mean_squared_error: 0.0864\n",
      "Epoch 7/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.1068 - mean_absolute_error: 0.2287 - mean_squared_error: 0.1074 - val_loss: 0.0764 - val_mean_absolute_error: 0.2185 - val_mean_squared_error: 0.0775\n",
      "Epoch 8/400\n",
      "56/56 [==============================] - 2s 27ms/step - loss: 0.0649 - mean_absolute_error: 0.1959 - mean_squared_error: 0.0652 - val_loss: 0.0694 - val_mean_absolute_error: 0.2189 - val_mean_squared_error: 0.0700\n",
      "Epoch 9/400\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 0.0557 - mean_absolute_error: 0.1814 - mean_squared_error: 0.0560 - val_loss: 0.0490 - val_mean_absolute_error: 0.1804 - val_mean_squared_error: 0.0497\n",
      "Epoch 10/400\n",
      "56/56 [==============================] - 2s 29ms/step - loss: 0.0521 - mean_absolute_error: 0.1755 - mean_squared_error: 0.0524 - val_loss: 0.0459 - val_mean_absolute_error: 0.1685 - val_mean_squared_error: 0.0465\n",
      "Epoch 11/400\n",
      "56/56 [==============================] - 2s 31ms/step - loss: 0.0517 - mean_absolute_error: 0.1746 - mean_squared_error: 0.0520 - val_loss: 0.0457 - val_mean_absolute_error: 0.1693 - val_mean_squared_error: 0.0463\n",
      "Epoch 12/400\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 0.0468 - mean_absolute_error: 0.1667 - mean_squared_error: 0.0471 - val_loss: 0.0361 - val_mean_absolute_error: 0.1513 - val_mean_squared_error: 0.0365\n",
      "Epoch 13/400\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 0.0436 - mean_absolute_error: 0.1620 - mean_squared_error: 0.0439 - val_loss: 0.0300 - val_mean_absolute_error: 0.1365 - val_mean_squared_error: 0.0302\n",
      "Epoch 14/400\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 0.0388 - mean_absolute_error: 0.1550 - mean_squared_error: 0.0391 - val_loss: 0.0325 - val_mean_absolute_error: 0.1485 - val_mean_squared_error: 0.0328\n",
      "Epoch 15/400\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 0.0390 - mean_absolute_error: 0.1526 - mean_squared_error: 0.0392 - val_loss: 0.0302 - val_mean_absolute_error: 0.1395 - val_mean_squared_error: 0.0306\n",
      "Epoch 16/400\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 0.0449 - mean_absolute_error: 0.1675 - mean_squared_error: 0.0451 - val_loss: 0.0285 - val_mean_absolute_error: 0.1364 - val_mean_squared_error: 0.0288\n",
      "Epoch 17/400\n",
      "56/56 [==============================] - 2s 27ms/step - loss: 0.0388 - mean_absolute_error: 0.1533 - mean_squared_error: 0.0391 - val_loss: 0.0331 - val_mean_absolute_error: 0.1530 - val_mean_squared_error: 0.0333\n",
      "Epoch 18/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0320 - mean_absolute_error: 0.1398 - mean_squared_error: 0.0323 - val_loss: 0.0327 - val_mean_absolute_error: 0.1506 - val_mean_squared_error: 0.0329\n",
      "Epoch 19/400\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 0.0318 - mean_absolute_error: 0.1399 - mean_squared_error: 0.0319 - val_loss: 0.0232 - val_mean_absolute_error: 0.1223 - val_mean_squared_error: 0.0234\n",
      "Epoch 20/400\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 0.0285 - mean_absolute_error: 0.1324 - mean_squared_error: 0.0287 - val_loss: 0.0222 - val_mean_absolute_error: 0.1202 - val_mean_squared_error: 0.0224\n",
      "Epoch 21/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0286 - mean_absolute_error: 0.1314 - mean_squared_error: 0.0287 - val_loss: 0.0257 - val_mean_absolute_error: 0.1284 - val_mean_squared_error: 0.0260\n",
      "Epoch 22/400\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 0.0288 - mean_absolute_error: 0.1344 - mean_squared_error: 0.0290 - val_loss: 0.0206 - val_mean_absolute_error: 0.1170 - val_mean_squared_error: 0.0208\n",
      "Epoch 23/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0257 - mean_absolute_error: 0.1271 - mean_squared_error: 0.0258 - val_loss: 0.0274 - val_mean_absolute_error: 0.1373 - val_mean_squared_error: 0.0276\n",
      "Epoch 24/400\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 0.0262 - mean_absolute_error: 0.1271 - mean_squared_error: 0.0263 - val_loss: 0.0210 - val_mean_absolute_error: 0.1200 - val_mean_squared_error: 0.0210\n",
      "Epoch 25/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0254 - mean_absolute_error: 0.1239 - mean_squared_error: 0.0256 - val_loss: 0.0217 - val_mean_absolute_error: 0.1202 - val_mean_squared_error: 0.0219\n",
      "Epoch 26/400\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 0.0258 - mean_absolute_error: 0.1280 - mean_squared_error: 0.0260 - val_loss: 0.0198 - val_mean_absolute_error: 0.1163 - val_mean_squared_error: 0.0200\n",
      "Epoch 27/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0277 - mean_absolute_error: 0.1300 - mean_squared_error: 0.0278 - val_loss: 0.0200 - val_mean_absolute_error: 0.1172 - val_mean_squared_error: 0.0201\n",
      "Epoch 28/400\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 0.0243 - mean_absolute_error: 0.1229 - mean_squared_error: 0.0243 - val_loss: 0.0181 - val_mean_absolute_error: 0.1121 - val_mean_squared_error: 0.0181\n",
      "Epoch 29/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0248 - mean_absolute_error: 0.1247 - mean_squared_error: 0.0249 - val_loss: 0.0191 - val_mean_absolute_error: 0.1138 - val_mean_squared_error: 0.0192\n",
      "Epoch 30/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0245 - mean_absolute_error: 0.1224 - mean_squared_error: 0.0247 - val_loss: 0.0183 - val_mean_absolute_error: 0.1115 - val_mean_squared_error: 0.0184\n",
      "Epoch 31/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0230 - mean_absolute_error: 0.1197 - mean_squared_error: 0.0231 - val_loss: 0.0195 - val_mean_absolute_error: 0.1153 - val_mean_squared_error: 0.0197\n",
      "Epoch 32/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0221 - mean_absolute_error: 0.1190 - mean_squared_error: 0.0222 - val_loss: 0.0199 - val_mean_absolute_error: 0.1174 - val_mean_squared_error: 0.0201\n",
      "Epoch 33/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0218 - mean_absolute_error: 0.1161 - mean_squared_error: 0.0219 - val_loss: 0.0194 - val_mean_absolute_error: 0.1152 - val_mean_squared_error: 0.0195\n",
      "Epoch 34/400\n",
      "56/56 [==============================] - 2s 27ms/step - loss: 0.0221 - mean_absolute_error: 0.1186 - mean_squared_error: 0.0222 - val_loss: 0.0218 - val_mean_absolute_error: 0.1190 - val_mean_squared_error: 0.0220\n",
      "Epoch 35/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0205 - mean_absolute_error: 0.1148 - mean_squared_error: 0.0206 - val_loss: 0.0249 - val_mean_absolute_error: 0.1279 - val_mean_squared_error: 0.0251\n",
      "Epoch 36/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0242 - mean_absolute_error: 0.1214 - mean_squared_error: 0.0243 - val_loss: 0.0242 - val_mean_absolute_error: 0.1276 - val_mean_squared_error: 0.0245\n",
      "Epoch 37/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0221 - mean_absolute_error: 0.1203 - mean_squared_error: 0.0223 - val_loss: 0.0195 - val_mean_absolute_error: 0.1150 - val_mean_squared_error: 0.0196\n",
      "Epoch 38/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0205 - mean_absolute_error: 0.1128 - mean_squared_error: 0.0205 - val_loss: 0.0222 - val_mean_absolute_error: 0.1242 - val_mean_squared_error: 0.0224\n",
      "Epoch 39/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0197 - mean_absolute_error: 0.1128 - mean_squared_error: 0.0198 - val_loss: 0.0194 - val_mean_absolute_error: 0.1134 - val_mean_squared_error: 0.0194\n",
      "Epoch 40/400\n",
      "56/56 [==============================] - 2s 27ms/step - loss: 0.0203 - mean_absolute_error: 0.1133 - mean_squared_error: 0.0204 - val_loss: 0.0215 - val_mean_absolute_error: 0.1200 - val_mean_squared_error: 0.0216\n",
      "Epoch 41/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0184 - mean_absolute_error: 0.1095 - mean_squared_error: 0.0184 - val_loss: 0.0193 - val_mean_absolute_error: 0.1108 - val_mean_squared_error: 0.0193\n",
      "Epoch 42/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0194 - mean_absolute_error: 0.1118 - mean_squared_error: 0.0195 - val_loss: 0.0188 - val_mean_absolute_error: 0.1119 - val_mean_squared_error: 0.0189\n",
      "Epoch 43/400\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 0.0185 - mean_absolute_error: 0.1075 - mean_squared_error: 0.0186 - val_loss: 0.0184 - val_mean_absolute_error: 0.1092 - val_mean_squared_error: 0.0184\n",
      "Epoch 44/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0190 - mean_absolute_error: 0.1103 - mean_squared_error: 0.0190 - val_loss: 0.0208 - val_mean_absolute_error: 0.1164 - val_mean_squared_error: 0.0210\n",
      "Epoch 45/400\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 0.0190 - mean_absolute_error: 0.1109 - mean_squared_error: 0.0191 - val_loss: 0.0220 - val_mean_absolute_error: 0.1194 - val_mean_squared_error: 0.0222\n",
      "Epoch 46/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0178 - mean_absolute_error: 0.1059 - mean_squared_error: 0.0179 - val_loss: 0.0183 - val_mean_absolute_error: 0.1088 - val_mean_squared_error: 0.0184\n",
      "Epoch 47/400\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 0.0180 - mean_absolute_error: 0.1078 - mean_squared_error: 0.0181 - val_loss: 0.0179 - val_mean_absolute_error: 0.1084 - val_mean_squared_error: 0.0179\n",
      "Epoch 48/400\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 0.0173 - mean_absolute_error: 0.1043 - mean_squared_error: 0.0173 - val_loss: 0.0156 - val_mean_absolute_error: 0.1013 - val_mean_squared_error: 0.0157\n",
      "Epoch 49/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0154 - mean_absolute_error: 0.0984 - mean_squared_error: 0.0155 - val_loss: 0.0217 - val_mean_absolute_error: 0.1212 - val_mean_squared_error: 0.0219\n",
      "Epoch 50/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0155 - mean_absolute_error: 0.0997 - mean_squared_error: 0.0156 - val_loss: 0.0186 - val_mean_absolute_error: 0.1089 - val_mean_squared_error: 0.0188\n",
      "Epoch 51/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0155 - mean_absolute_error: 0.0989 - mean_squared_error: 0.0156 - val_loss: 0.0195 - val_mean_absolute_error: 0.1147 - val_mean_squared_error: 0.0197\n",
      "Epoch 52/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0171 - mean_absolute_error: 0.1045 - mean_squared_error: 0.0172 - val_loss: 0.0242 - val_mean_absolute_error: 0.1273 - val_mean_squared_error: 0.0244\n",
      "Epoch 53/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0155 - mean_absolute_error: 0.1004 - mean_squared_error: 0.0156 - val_loss: 0.0187 - val_mean_absolute_error: 0.1136 - val_mean_squared_error: 0.0188\n",
      "Epoch 54/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0159 - mean_absolute_error: 0.1009 - mean_squared_error: 0.0160 - val_loss: 0.0157 - val_mean_absolute_error: 0.0986 - val_mean_squared_error: 0.0158\n",
      "Epoch 55/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0158 - mean_absolute_error: 0.0993 - mean_squared_error: 0.0159 - val_loss: 0.0187 - val_mean_absolute_error: 0.1074 - val_mean_squared_error: 0.0189\n",
      "Epoch 56/400\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 0.0169 - mean_absolute_error: 0.1013 - mean_squared_error: 0.0169 - val_loss: 0.0141 - val_mean_absolute_error: 0.0964 - val_mean_squared_error: 0.0143\n",
      "Epoch 57/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0167 - mean_absolute_error: 0.1021 - mean_squared_error: 0.0168 - val_loss: 0.0146 - val_mean_absolute_error: 0.0972 - val_mean_squared_error: 0.0147\n",
      "Epoch 58/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0156 - mean_absolute_error: 0.0990 - mean_squared_error: 0.0156 - val_loss: 0.0152 - val_mean_absolute_error: 0.0989 - val_mean_squared_error: 0.0153\n",
      "Epoch 59/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0151 - mean_absolute_error: 0.0975 - mean_squared_error: 0.0152 - val_loss: 0.0180 - val_mean_absolute_error: 0.1071 - val_mean_squared_error: 0.0182\n",
      "Epoch 60/400\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 0.0144 - mean_absolute_error: 0.0949 - mean_squared_error: 0.0145 - val_loss: 0.0159 - val_mean_absolute_error: 0.1017 - val_mean_squared_error: 0.0160\n",
      "Epoch 61/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0131 - mean_absolute_error: 0.0915 - mean_squared_error: 0.0131 - val_loss: 0.0148 - val_mean_absolute_error: 0.0984 - val_mean_squared_error: 0.0150\n",
      "Epoch 62/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0135 - mean_absolute_error: 0.0928 - mean_squared_error: 0.0136 - val_loss: 0.0152 - val_mean_absolute_error: 0.0992 - val_mean_squared_error: 0.0154\n",
      "Epoch 63/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0121 - mean_absolute_error: 0.0884 - mean_squared_error: 0.0121 - val_loss: 0.0155 - val_mean_absolute_error: 0.0966 - val_mean_squared_error: 0.0156\n",
      "Epoch 64/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0133 - mean_absolute_error: 0.0903 - mean_squared_error: 0.0134 - val_loss: 0.0144 - val_mean_absolute_error: 0.0950 - val_mean_squared_error: 0.0145\n",
      "Epoch 65/400\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 0.0124 - mean_absolute_error: 0.0881 - mean_squared_error: 0.0125 - val_loss: 0.0130 - val_mean_absolute_error: 0.0897 - val_mean_squared_error: 0.0131\n",
      "Epoch 66/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0125 - mean_absolute_error: 0.0879 - mean_squared_error: 0.0126 - val_loss: 0.0163 - val_mean_absolute_error: 0.0994 - val_mean_squared_error: 0.0165\n",
      "Epoch 67/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0124 - mean_absolute_error: 0.0887 - mean_squared_error: 0.0125 - val_loss: 0.0147 - val_mean_absolute_error: 0.0962 - val_mean_squared_error: 0.0147\n",
      "Epoch 68/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0118 - mean_absolute_error: 0.0860 - mean_squared_error: 0.0118 - val_loss: 0.0145 - val_mean_absolute_error: 0.0944 - val_mean_squared_error: 0.0146\n",
      "Epoch 69/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0120 - mean_absolute_error: 0.0862 - mean_squared_error: 0.0121 - val_loss: 0.0170 - val_mean_absolute_error: 0.0991 - val_mean_squared_error: 0.0171\n",
      "Epoch 70/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0136 - mean_absolute_error: 0.0908 - mean_squared_error: 0.0137 - val_loss: 0.0164 - val_mean_absolute_error: 0.1002 - val_mean_squared_error: 0.0167\n",
      "Epoch 71/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0105 - mean_absolute_error: 0.0813 - mean_squared_error: 0.0105 - val_loss: 0.0134 - val_mean_absolute_error: 0.0916 - val_mean_squared_error: 0.0135\n",
      "Epoch 72/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0101 - mean_absolute_error: 0.0779 - mean_squared_error: 0.0102 - val_loss: 0.0133 - val_mean_absolute_error: 0.0880 - val_mean_squared_error: 0.0134\n",
      "Epoch 73/400\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 0.0111 - mean_absolute_error: 0.0828 - mean_squared_error: 0.0111 - val_loss: 0.0222 - val_mean_absolute_error: 0.1197 - val_mean_squared_error: 0.0223\n",
      "Epoch 74/400\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 0.0109 - mean_absolute_error: 0.0803 - mean_squared_error: 0.0109 - val_loss: 0.0129 - val_mean_absolute_error: 0.0872 - val_mean_squared_error: 0.0130\n",
      "Epoch 75/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0100 - mean_absolute_error: 0.0766 - mean_squared_error: 0.0100 - val_loss: 0.0148 - val_mean_absolute_error: 0.0945 - val_mean_squared_error: 0.0150\n",
      "Epoch 76/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0110 - mean_absolute_error: 0.0822 - mean_squared_error: 0.0110 - val_loss: 0.0136 - val_mean_absolute_error: 0.0877 - val_mean_squared_error: 0.0138\n",
      "Epoch 77/400\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 0.0090 - mean_absolute_error: 0.0746 - mean_squared_error: 0.0090 - val_loss: 0.0122 - val_mean_absolute_error: 0.0859 - val_mean_squared_error: 0.0123\n",
      "Epoch 78/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0106 - mean_absolute_error: 0.0797 - mean_squared_error: 0.0106 - val_loss: 0.0152 - val_mean_absolute_error: 0.0971 - val_mean_squared_error: 0.0154\n",
      "Epoch 79/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0110 - mean_absolute_error: 0.0821 - mean_squared_error: 0.0110 - val_loss: 0.0142 - val_mean_absolute_error: 0.0864 - val_mean_squared_error: 0.0143\n",
      "Epoch 80/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0092 - mean_absolute_error: 0.0740 - mean_squared_error: 0.0091 - val_loss: 0.0129 - val_mean_absolute_error: 0.0848 - val_mean_squared_error: 0.0130\n",
      "Epoch 81/400\n",
      "56/56 [==============================] - 2s 27ms/step - loss: 0.0096 - mean_absolute_error: 0.0757 - mean_squared_error: 0.0096 - val_loss: 0.0142 - val_mean_absolute_error: 0.0904 - val_mean_squared_error: 0.0144\n",
      "Epoch 82/400\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 0.0082 - mean_absolute_error: 0.0716 - mean_squared_error: 0.0082 - val_loss: 0.0152 - val_mean_absolute_error: 0.0998 - val_mean_squared_error: 0.0153\n",
      "Epoch 83/400\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 0.0077 - mean_absolute_error: 0.0681 - mean_squared_error: 0.0078 - val_loss: 0.0107 - val_mean_absolute_error: 0.0778 - val_mean_squared_error: 0.0109\n",
      "Epoch 84/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0109 - mean_absolute_error: 0.0778 - mean_squared_error: 0.0110 - val_loss: 0.0124 - val_mean_absolute_error: 0.0824 - val_mean_squared_error: 0.0126\n",
      "Epoch 85/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0100 - mean_absolute_error: 0.0755 - mean_squared_error: 0.0101 - val_loss: 0.0123 - val_mean_absolute_error: 0.0856 - val_mean_squared_error: 0.0124\n",
      "Epoch 86/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0085 - mean_absolute_error: 0.0713 - mean_squared_error: 0.0086 - val_loss: 0.0158 - val_mean_absolute_error: 0.1031 - val_mean_squared_error: 0.0159\n",
      "Epoch 87/400\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 0.0095 - mean_absolute_error: 0.0759 - mean_squared_error: 0.0096 - val_loss: 0.0105 - val_mean_absolute_error: 0.0761 - val_mean_squared_error: 0.0107\n",
      "Epoch 88/400\n",
      "56/56 [==============================] - 2s 27ms/step - loss: 0.0078 - mean_absolute_error: 0.0687 - mean_squared_error: 0.0079 - val_loss: 0.0116 - val_mean_absolute_error: 0.0793 - val_mean_squared_error: 0.0117\n",
      "Epoch 89/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0072 - mean_absolute_error: 0.0655 - mean_squared_error: 0.0072 - val_loss: 0.0131 - val_mean_absolute_error: 0.0879 - val_mean_squared_error: 0.0133\n",
      "Epoch 90/400\n",
      "56/56 [==============================] - 2s 27ms/step - loss: 0.0066 - mean_absolute_error: 0.0619 - mean_squared_error: 0.0066 - val_loss: 0.0126 - val_mean_absolute_error: 0.0838 - val_mean_squared_error: 0.0128\n",
      "Epoch 91/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0067 - mean_absolute_error: 0.0628 - mean_squared_error: 0.0067 - val_loss: 0.0149 - val_mean_absolute_error: 0.0878 - val_mean_squared_error: 0.0151\n",
      "Epoch 92/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0069 - mean_absolute_error: 0.0651 - mean_squared_error: 0.0070 - val_loss: 0.0112 - val_mean_absolute_error: 0.0785 - val_mean_squared_error: 0.0113\n",
      "Epoch 93/400\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 0.0096 - mean_absolute_error: 0.0727 - mean_squared_error: 0.0096 - val_loss: 0.0185 - val_mean_absolute_error: 0.1092 - val_mean_squared_error: 0.0187\n",
      "Epoch 94/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0111 - mean_absolute_error: 0.0783 - mean_squared_error: 0.0111 - val_loss: 0.0126 - val_mean_absolute_error: 0.0854 - val_mean_squared_error: 0.0128\n",
      "Epoch 95/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0080 - mean_absolute_error: 0.0685 - mean_squared_error: 0.0081 - val_loss: 0.0125 - val_mean_absolute_error: 0.0847 - val_mean_squared_error: 0.0126\n",
      "Epoch 96/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0081 - mean_absolute_error: 0.0694 - mean_squared_error: 0.0082 - val_loss: 0.0182 - val_mean_absolute_error: 0.1023 - val_mean_squared_error: 0.0185\n",
      "Epoch 97/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0077 - mean_absolute_error: 0.0675 - mean_squared_error: 0.0077 - val_loss: 0.0111 - val_mean_absolute_error: 0.0766 - val_mean_squared_error: 0.0112\n",
      "Epoch 98/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0064 - mean_absolute_error: 0.0605 - mean_squared_error: 0.0065 - val_loss: 0.0117 - val_mean_absolute_error: 0.0804 - val_mean_squared_error: 0.0119\n",
      "Epoch 99/400\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 0.0058 - mean_absolute_error: 0.0583 - mean_squared_error: 0.0059 - val_loss: 0.0132 - val_mean_absolute_error: 0.0881 - val_mean_squared_error: 0.0134\n",
      "Epoch 100/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0061 - mean_absolute_error: 0.0590 - mean_squared_error: 0.0061 - val_loss: 0.0118 - val_mean_absolute_error: 0.0781 - val_mean_squared_error: 0.0120\n",
      "Epoch 101/400\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 0.0059 - mean_absolute_error: 0.0587 - mean_squared_error: 0.0059 - val_loss: 0.0116 - val_mean_absolute_error: 0.0782 - val_mean_squared_error: 0.0117\n",
      "Epoch 102/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0049 - mean_absolute_error: 0.0532 - mean_squared_error: 0.0049 - val_loss: 0.0106 - val_mean_absolute_error: 0.0729 - val_mean_squared_error: 0.0107\n",
      "Epoch 103/400\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 0.0055 - mean_absolute_error: 0.0556 - mean_squared_error: 0.0055 - val_loss: 0.0110 - val_mean_absolute_error: 0.0757 - val_mean_squared_error: 0.0112\n",
      "Epoch 104/400\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 0.0064 - mean_absolute_error: 0.0592 - mean_squared_error: 0.0064 - val_loss: 0.0099 - val_mean_absolute_error: 0.0736 - val_mean_squared_error: 0.0101\n",
      "Epoch 105/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0067 - mean_absolute_error: 0.0614 - mean_squared_error: 0.0067 - val_loss: 0.0110 - val_mean_absolute_error: 0.0782 - val_mean_squared_error: 0.0112\n",
      "Epoch 106/400\n",
      "56/56 [==============================] - 2s 27ms/step - loss: 0.0070 - mean_absolute_error: 0.0631 - mean_squared_error: 0.0070 - val_loss: 0.0108 - val_mean_absolute_error: 0.0743 - val_mean_squared_error: 0.0110\n",
      "Epoch 107/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0062 - mean_absolute_error: 0.0587 - mean_squared_error: 0.0062 - val_loss: 0.0115 - val_mean_absolute_error: 0.0781 - val_mean_squared_error: 0.0117\n",
      "Epoch 108/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0067 - mean_absolute_error: 0.0626 - mean_squared_error: 0.0067 - val_loss: 0.0101 - val_mean_absolute_error: 0.0725 - val_mean_squared_error: 0.0103\n",
      "Epoch 109/400\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 0.0056 - mean_absolute_error: 0.0566 - mean_squared_error: 0.0056 - val_loss: 0.0116 - val_mean_absolute_error: 0.0793 - val_mean_squared_error: 0.0117\n",
      "Epoch 110/400\n",
      "56/56 [==============================] - 2s 27ms/step - loss: 0.0064 - mean_absolute_error: 0.0572 - mean_squared_error: 0.0064 - val_loss: 0.0166 - val_mean_absolute_error: 0.0950 - val_mean_squared_error: 0.0168\n",
      "Epoch 111/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0116 - mean_absolute_error: 0.0803 - mean_squared_error: 0.0116 - val_loss: 0.0132 - val_mean_absolute_error: 0.0880 - val_mean_squared_error: 0.0133\n",
      "Epoch 112/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0075 - mean_absolute_error: 0.0655 - mean_squared_error: 0.0074 - val_loss: 0.0107 - val_mean_absolute_error: 0.0771 - val_mean_squared_error: 0.0108\n",
      "Epoch 113/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0065 - mean_absolute_error: 0.0620 - mean_squared_error: 0.0066 - val_loss: 0.0140 - val_mean_absolute_error: 0.0856 - val_mean_squared_error: 0.0142\n",
      "Epoch 114/400\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 0.0050 - mean_absolute_error: 0.0541 - mean_squared_error: 0.0051 - val_loss: 0.0115 - val_mean_absolute_error: 0.0764 - val_mean_squared_error: 0.0117\n",
      "Epoch 115/400\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 0.0046 - mean_absolute_error: 0.0517 - mean_squared_error: 0.0047 - val_loss: 0.0116 - val_mean_absolute_error: 0.0770 - val_mean_squared_error: 0.0118\n",
      "Epoch 116/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0048 - mean_absolute_error: 0.0526 - mean_squared_error: 0.0048 - val_loss: 0.0109 - val_mean_absolute_error: 0.0733 - val_mean_squared_error: 0.0111\n",
      "Epoch 117/400\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 0.0039 - mean_absolute_error: 0.0471 - mean_squared_error: 0.0039 - val_loss: 0.0122 - val_mean_absolute_error: 0.0817 - val_mean_squared_error: 0.0124\n",
      "Epoch 118/400\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 0.0040 - mean_absolute_error: 0.0473 - mean_squared_error: 0.0040 - val_loss: 0.0096 - val_mean_absolute_error: 0.0685 - val_mean_squared_error: 0.0098\n",
      "Epoch 119/400\n",
      "56/56 [==============================] - 2s 27ms/step - loss: 0.0040 - mean_absolute_error: 0.0487 - mean_squared_error: 0.0040 - val_loss: 0.0105 - val_mean_absolute_error: 0.0761 - val_mean_squared_error: 0.0107\n",
      "Epoch 120/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0037 - mean_absolute_error: 0.0452 - mean_squared_error: 0.0037 - val_loss: 0.0099 - val_mean_absolute_error: 0.0715 - val_mean_squared_error: 0.0101\n",
      "Epoch 121/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0033 - mean_absolute_error: 0.0432 - mean_squared_error: 0.0033 - val_loss: 0.0118 - val_mean_absolute_error: 0.0777 - val_mean_squared_error: 0.0120\n",
      "Epoch 122/400\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 0.0039 - mean_absolute_error: 0.0476 - mean_squared_error: 0.0039 - val_loss: 0.0095 - val_mean_absolute_error: 0.0698 - val_mean_squared_error: 0.0096\n",
      "Epoch 123/400\n",
      "56/56 [==============================] - 2s 27ms/step - loss: 0.0037 - mean_absolute_error: 0.0459 - mean_squared_error: 0.0037 - val_loss: 0.0124 - val_mean_absolute_error: 0.0771 - val_mean_squared_error: 0.0126\n",
      "Epoch 124/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0039 - mean_absolute_error: 0.0483 - mean_squared_error: 0.0039 - val_loss: 0.0125 - val_mean_absolute_error: 0.0825 - val_mean_squared_error: 0.0127\n",
      "Epoch 125/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0034 - mean_absolute_error: 0.0446 - mean_squared_error: 0.0034 - val_loss: 0.0112 - val_mean_absolute_error: 0.0749 - val_mean_squared_error: 0.0114\n",
      "Epoch 126/400\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 0.0038 - mean_absolute_error: 0.0466 - mean_squared_error: 0.0038 - val_loss: 0.0104 - val_mean_absolute_error: 0.0747 - val_mean_squared_error: 0.0106\n",
      "Epoch 127/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0033 - mean_absolute_error: 0.0432 - mean_squared_error: 0.0034 - val_loss: 0.0112 - val_mean_absolute_error: 0.0755 - val_mean_squared_error: 0.0113\n",
      "Epoch 128/400\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 0.0040 - mean_absolute_error: 0.0487 - mean_squared_error: 0.0040 - val_loss: 0.0094 - val_mean_absolute_error: 0.0686 - val_mean_squared_error: 0.0096\n",
      "Epoch 129/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0029 - mean_absolute_error: 0.0406 - mean_squared_error: 0.0029 - val_loss: 0.0103 - val_mean_absolute_error: 0.0733 - val_mean_squared_error: 0.0104\n",
      "Epoch 130/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0027 - mean_absolute_error: 0.0399 - mean_squared_error: 0.0027 - val_loss: 0.0103 - val_mean_absolute_error: 0.0690 - val_mean_squared_error: 0.0105\n",
      "Epoch 131/400\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 0.0024 - mean_absolute_error: 0.0371 - mean_squared_error: 0.0024 - val_loss: 0.0088 - val_mean_absolute_error: 0.0660 - val_mean_squared_error: 0.0090\n",
      "Epoch 132/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0024 - mean_absolute_error: 0.0372 - mean_squared_error: 0.0024 - val_loss: 0.0103 - val_mean_absolute_error: 0.0696 - val_mean_squared_error: 0.0105\n",
      "Epoch 133/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0025 - mean_absolute_error: 0.0374 - mean_squared_error: 0.0025 - val_loss: 0.0098 - val_mean_absolute_error: 0.0695 - val_mean_squared_error: 0.0100\n",
      "Epoch 134/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0025 - mean_absolute_error: 0.0381 - mean_squared_error: 0.0025 - val_loss: 0.0100 - val_mean_absolute_error: 0.0706 - val_mean_squared_error: 0.0101\n",
      "Epoch 135/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0031 - mean_absolute_error: 0.0431 - mean_squared_error: 0.0031 - val_loss: 0.0100 - val_mean_absolute_error: 0.0730 - val_mean_squared_error: 0.0102\n",
      "Epoch 136/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0042 - mean_absolute_error: 0.0486 - mean_squared_error: 0.0042 - val_loss: 0.0118 - val_mean_absolute_error: 0.0762 - val_mean_squared_error: 0.0120\n",
      "Epoch 137/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0035 - mean_absolute_error: 0.0445 - mean_squared_error: 0.0035 - val_loss: 0.0103 - val_mean_absolute_error: 0.0704 - val_mean_squared_error: 0.0105\n",
      "Epoch 138/400\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 0.0026 - mean_absolute_error: 0.0380 - mean_squared_error: 0.0026 - val_loss: 0.0121 - val_mean_absolute_error: 0.0824 - val_mean_squared_error: 0.0123\n",
      "Epoch 139/400\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 0.0025 - mean_absolute_error: 0.0380 - mean_squared_error: 0.0025 - val_loss: 0.0101 - val_mean_absolute_error: 0.0701 - val_mean_squared_error: 0.0103\n",
      "Epoch 140/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0025 - mean_absolute_error: 0.0377 - mean_squared_error: 0.0025 - val_loss: 0.0098 - val_mean_absolute_error: 0.0675 - val_mean_squared_error: 0.0100\n",
      "Epoch 141/400\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 0.0031 - mean_absolute_error: 0.0432 - mean_squared_error: 0.0031 - val_loss: 0.0107 - val_mean_absolute_error: 0.0742 - val_mean_squared_error: 0.0109\n",
      "Epoch 142/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0026 - mean_absolute_error: 0.0392 - mean_squared_error: 0.0026 - val_loss: 0.0100 - val_mean_absolute_error: 0.0697 - val_mean_squared_error: 0.0102\n",
      "Epoch 143/400\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 0.0027 - mean_absolute_error: 0.0396 - mean_squared_error: 0.0027 - val_loss: 0.0102 - val_mean_absolute_error: 0.0689 - val_mean_squared_error: 0.0104\n",
      "Epoch 144/400\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 0.0025 - mean_absolute_error: 0.0381 - mean_squared_error: 0.0025 - val_loss: 0.0105 - val_mean_absolute_error: 0.0710 - val_mean_squared_error: 0.0107\n",
      "Epoch 145/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0034 - mean_absolute_error: 0.0436 - mean_squared_error: 0.0034 - val_loss: 0.0094 - val_mean_absolute_error: 0.0705 - val_mean_squared_error: 0.0096\n",
      "Epoch 146/400\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 0.0029 - mean_absolute_error: 0.0403 - mean_squared_error: 0.0029 - val_loss: 0.0087 - val_mean_absolute_error: 0.0657 - val_mean_squared_error: 0.0088\n",
      "Epoch 147/400\n",
      "56/56 [==============================] - 2s 27ms/step - loss: 0.0026 - mean_absolute_error: 0.0391 - mean_squared_error: 0.0026 - val_loss: 0.0094 - val_mean_absolute_error: 0.0653 - val_mean_squared_error: 0.0096\n",
      "Epoch 148/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0022 - mean_absolute_error: 0.0361 - mean_squared_error: 0.0022 - val_loss: 0.0092 - val_mean_absolute_error: 0.0671 - val_mean_squared_error: 0.0094\n",
      "Epoch 149/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0023 - mean_absolute_error: 0.0366 - mean_squared_error: 0.0023 - val_loss: 0.0102 - val_mean_absolute_error: 0.0728 - val_mean_squared_error: 0.0104\n",
      "Epoch 150/400\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 0.0024 - mean_absolute_error: 0.0370 - mean_squared_error: 0.0024 - val_loss: 0.0096 - val_mean_absolute_error: 0.0690 - val_mean_squared_error: 0.0097\n",
      "Epoch 151/400\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 0.0025 - mean_absolute_error: 0.0384 - mean_squared_error: 0.0025 - val_loss: 0.0102 - val_mean_absolute_error: 0.0715 - val_mean_squared_error: 0.0103\n",
      "Epoch 152/400\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 0.0028 - mean_absolute_error: 0.0406 - mean_squared_error: 0.0028 - val_loss: 0.0090 - val_mean_absolute_error: 0.0668 - val_mean_squared_error: 0.0092\n",
      "Epoch 153/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0026 - mean_absolute_error: 0.0387 - mean_squared_error: 0.0026 - val_loss: 0.0096 - val_mean_absolute_error: 0.0694 - val_mean_squared_error: 0.0098\n",
      "Epoch 154/400\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 0.0030 - mean_absolute_error: 0.0416 - mean_squared_error: 0.0030 - val_loss: 0.0099 - val_mean_absolute_error: 0.0775 - val_mean_squared_error: 0.0100\n",
      "Epoch 155/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0026 - mean_absolute_error: 0.0393 - mean_squared_error: 0.0026 - val_loss: 0.0093 - val_mean_absolute_error: 0.0683 - val_mean_squared_error: 0.0095\n",
      "Epoch 156/400\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 0.0021 - mean_absolute_error: 0.0358 - mean_squared_error: 0.0022 - val_loss: 0.0107 - val_mean_absolute_error: 0.0732 - val_mean_squared_error: 0.0109\n",
      "Epoch 157/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0017 - mean_absolute_error: 0.0321 - mean_squared_error: 0.0017 - val_loss: 0.0100 - val_mean_absolute_error: 0.0711 - val_mean_squared_error: 0.0102\n",
      "Epoch 158/400\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 0.0018 - mean_absolute_error: 0.0327 - mean_squared_error: 0.0018 - val_loss: 0.0082 - val_mean_absolute_error: 0.0641 - val_mean_squared_error: 0.0083\n",
      "Epoch 159/400\n",
      "56/56 [==============================] - 2s 27ms/step - loss: 0.0024 - mean_absolute_error: 0.0373 - mean_squared_error: 0.0024 - val_loss: 0.0091 - val_mean_absolute_error: 0.0686 - val_mean_squared_error: 0.0093\n",
      "Epoch 160/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0026 - mean_absolute_error: 0.0394 - mean_squared_error: 0.0027 - val_loss: 0.0098 - val_mean_absolute_error: 0.0687 - val_mean_squared_error: 0.0100\n",
      "Epoch 161/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0024 - mean_absolute_error: 0.0360 - mean_squared_error: 0.0024 - val_loss: 0.0114 - val_mean_absolute_error: 0.0779 - val_mean_squared_error: 0.0116\n",
      "Epoch 162/400\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 0.0028 - mean_absolute_error: 0.0402 - mean_squared_error: 0.0028 - val_loss: 0.0118 - val_mean_absolute_error: 0.0748 - val_mean_squared_error: 0.0120\n",
      "Epoch 163/400\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 0.0037 - mean_absolute_error: 0.0455 - mean_squared_error: 0.0037 - val_loss: 0.0096 - val_mean_absolute_error: 0.0660 - val_mean_squared_error: 0.0097\n",
      "Epoch 164/400\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 0.0026 - mean_absolute_error: 0.0393 - mean_squared_error: 0.0026 - val_loss: 0.0096 - val_mean_absolute_error: 0.0690 - val_mean_squared_error: 0.0098\n",
      "Epoch 165/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0019 - mean_absolute_error: 0.0330 - mean_squared_error: 0.0019 - val_loss: 0.0087 - val_mean_absolute_error: 0.0628 - val_mean_squared_error: 0.0089\n",
      "Epoch 166/400\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 0.0019 - mean_absolute_error: 0.0331 - mean_squared_error: 0.0019 - val_loss: 0.0098 - val_mean_absolute_error: 0.0668 - val_mean_squared_error: 0.0100\n",
      "Epoch 167/400\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 0.0020 - mean_absolute_error: 0.0344 - mean_squared_error: 0.0020 - val_loss: 0.0104 - val_mean_absolute_error: 0.0691 - val_mean_squared_error: 0.0106\n",
      "Epoch 168/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0020 - mean_absolute_error: 0.0344 - mean_squared_error: 0.0021 - val_loss: 0.0095 - val_mean_absolute_error: 0.0659 - val_mean_squared_error: 0.0097\n",
      "Epoch 169/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0022 - mean_absolute_error: 0.0357 - mean_squared_error: 0.0022 - val_loss: 0.0085 - val_mean_absolute_error: 0.0621 - val_mean_squared_error: 0.0087\n",
      "Epoch 170/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0016 - mean_absolute_error: 0.0305 - mean_squared_error: 0.0016 - val_loss: 0.0104 - val_mean_absolute_error: 0.0732 - val_mean_squared_error: 0.0106\n",
      "Epoch 171/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0018 - mean_absolute_error: 0.0329 - mean_squared_error: 0.0018 - val_loss: 0.0095 - val_mean_absolute_error: 0.0687 - val_mean_squared_error: 0.0097\n",
      "Epoch 172/400\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 0.0019 - mean_absolute_error: 0.0334 - mean_squared_error: 0.0019 - val_loss: 0.0094 - val_mean_absolute_error: 0.0695 - val_mean_squared_error: 0.0095\n",
      "Epoch 173/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0021 - mean_absolute_error: 0.0338 - mean_squared_error: 0.0021 - val_loss: 0.0092 - val_mean_absolute_error: 0.0672 - val_mean_squared_error: 0.0093\n",
      "Epoch 174/400\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 0.0020 - mean_absolute_error: 0.0347 - mean_squared_error: 0.0020 - val_loss: 0.0093 - val_mean_absolute_error: 0.0668 - val_mean_squared_error: 0.0095\n",
      "Epoch 175/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0028 - mean_absolute_error: 0.0410 - mean_squared_error: 0.0028 - val_loss: 0.0112 - val_mean_absolute_error: 0.0732 - val_mean_squared_error: 0.0113\n",
      "Epoch 176/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0025 - mean_absolute_error: 0.0376 - mean_squared_error: 0.0025 - val_loss: 0.0102 - val_mean_absolute_error: 0.0694 - val_mean_squared_error: 0.0103\n",
      "Epoch 177/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0024 - mean_absolute_error: 0.0363 - mean_squared_error: 0.0024 - val_loss: 0.0095 - val_mean_absolute_error: 0.0674 - val_mean_squared_error: 0.0096\n",
      "Epoch 178/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0017 - mean_absolute_error: 0.0313 - mean_squared_error: 0.0017 - val_loss: 0.0096 - val_mean_absolute_error: 0.0671 - val_mean_squared_error: 0.0098\n",
      "Epoch 179/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0022 - mean_absolute_error: 0.0353 - mean_squared_error: 0.0022 - val_loss: 0.0083 - val_mean_absolute_error: 0.0629 - val_mean_squared_error: 0.0084\n",
      "Epoch 180/400\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 0.0015 - mean_absolute_error: 0.0292 - mean_squared_error: 0.0015 - val_loss: 0.0091 - val_mean_absolute_error: 0.0655 - val_mean_squared_error: 0.0092\n",
      "Epoch 181/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0013 - mean_absolute_error: 0.0275 - mean_squared_error: 0.0013 - val_loss: 0.0094 - val_mean_absolute_error: 0.0674 - val_mean_squared_error: 0.0095\n",
      "Epoch 182/400\n",
      "56/56 [==============================] - 2s 30ms/step - loss: 0.0016 - mean_absolute_error: 0.0311 - mean_squared_error: 0.0016 - val_loss: 0.0082 - val_mean_absolute_error: 0.0622 - val_mean_squared_error: 0.0083\n",
      "Epoch 183/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0016 - mean_absolute_error: 0.0302 - mean_squared_error: 0.0016 - val_loss: 0.0105 - val_mean_absolute_error: 0.0748 - val_mean_squared_error: 0.0107\n",
      "Epoch 184/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0016 - mean_absolute_error: 0.0304 - mean_squared_error: 0.0016 - val_loss: 0.0101 - val_mean_absolute_error: 0.0725 - val_mean_squared_error: 0.0103\n",
      "Epoch 185/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0016 - mean_absolute_error: 0.0310 - mean_squared_error: 0.0016 - val_loss: 0.0096 - val_mean_absolute_error: 0.0697 - val_mean_squared_error: 0.0098\n",
      "Epoch 186/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0016 - mean_absolute_error: 0.0303 - mean_squared_error: 0.0016 - val_loss: 0.0087 - val_mean_absolute_error: 0.0650 - val_mean_squared_error: 0.0089\n",
      "Epoch 187/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0014 - mean_absolute_error: 0.0280 - mean_squared_error: 0.0014 - val_loss: 0.0085 - val_mean_absolute_error: 0.0632 - val_mean_squared_error: 0.0087\n",
      "Epoch 188/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0012 - mean_absolute_error: 0.0266 - mean_squared_error: 0.0012 - val_loss: 0.0093 - val_mean_absolute_error: 0.0666 - val_mean_squared_error: 0.0095\n",
      "Epoch 189/400\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 0.0020 - mean_absolute_error: 0.0348 - mean_squared_error: 0.0020 - val_loss: 0.0099 - val_mean_absolute_error: 0.0707 - val_mean_squared_error: 0.0101\n",
      "Epoch 190/400\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 0.0019 - mean_absolute_error: 0.0327 - mean_squared_error: 0.0019 - val_loss: 0.0101 - val_mean_absolute_error: 0.0729 - val_mean_squared_error: 0.0102\n",
      "Epoch 191/400\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 0.0017 - mean_absolute_error: 0.0314 - mean_squared_error: 0.0017 - val_loss: 0.0101 - val_mean_absolute_error: 0.0679 - val_mean_squared_error: 0.0103\n",
      "Epoch 192/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0018 - mean_absolute_error: 0.0330 - mean_squared_error: 0.0018 - val_loss: 0.0091 - val_mean_absolute_error: 0.0642 - val_mean_squared_error: 0.0092\n",
      "Epoch 193/400\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 0.0012 - mean_absolute_error: 0.0264 - mean_squared_error: 0.0012 - val_loss: 0.0085 - val_mean_absolute_error: 0.0630 - val_mean_squared_error: 0.0086\n",
      "Epoch 194/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0018 - mean_absolute_error: 0.0330 - mean_squared_error: 0.0018 - val_loss: 0.0119 - val_mean_absolute_error: 0.0790 - val_mean_squared_error: 0.0121\n",
      "Epoch 195/400\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 0.0020 - mean_absolute_error: 0.0337 - mean_squared_error: 0.0020 - val_loss: 0.0083 - val_mean_absolute_error: 0.0616 - val_mean_squared_error: 0.0084\n",
      "Epoch 196/400\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 0.0014 - mean_absolute_error: 0.0294 - mean_squared_error: 0.0014 - val_loss: 0.0096 - val_mean_absolute_error: 0.0663 - val_mean_squared_error: 0.0098\n",
      "Epoch 197/400\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 0.0013 - mean_absolute_error: 0.0271 - mean_squared_error: 0.0013 - val_loss: 0.0086 - val_mean_absolute_error: 0.0654 - val_mean_squared_error: 0.0087\n",
      "Epoch 198/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0019 - mean_absolute_error: 0.0346 - mean_squared_error: 0.0019 - val_loss: 0.0101 - val_mean_absolute_error: 0.0736 - val_mean_squared_error: 0.0102\n",
      "Epoch 199/400\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 0.0021 - mean_absolute_error: 0.0350 - mean_squared_error: 0.0021 - val_loss: 0.0094 - val_mean_absolute_error: 0.0683 - val_mean_squared_error: 0.0095\n",
      "Epoch 200/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0021 - mean_absolute_error: 0.0344 - mean_squared_error: 0.0021 - val_loss: 0.0122 - val_mean_absolute_error: 0.0770 - val_mean_squared_error: 0.0124\n",
      "Epoch 201/400\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 0.0019 - mean_absolute_error: 0.0335 - mean_squared_error: 0.0019 - val_loss: 0.0093 - val_mean_absolute_error: 0.0670 - val_mean_squared_error: 0.0095\n",
      "Epoch 202/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0014 - mean_absolute_error: 0.0280 - mean_squared_error: 0.0014 - val_loss: 0.0083 - val_mean_absolute_error: 0.0611 - val_mean_squared_error: 0.0084\n",
      "Epoch 203/400\n",
      "56/56 [==============================] - 1s 27ms/step - loss: 0.0011 - mean_absolute_error: 0.0259 - mean_squared_error: 0.0011 - val_loss: 0.0086 - val_mean_absolute_error: 0.0638 - val_mean_squared_error: 0.0088\n",
      "Epoch 204/400\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 8.7702e-04 - mean_absolute_error: 0.0227 - mean_squared_error: 8.8098e-04 - val_loss: 0.0084 - val_mean_absolute_error: 0.0609 - val_mean_squared_error: 0.0085\n",
      "Epoch 205/400\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 9.5779e-04 - mean_absolute_error: 0.0241 - mean_squared_error: 9.5908e-04 - val_loss: 0.0090 - val_mean_absolute_error: 0.0653 - val_mean_squared_error: 0.0092\n",
      "Epoch 206/400\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 8.7830e-04 - mean_absolute_error: 0.0227 - mean_squared_error: 8.8042e-04 - val_loss: 0.0090 - val_mean_absolute_error: 0.0660 - val_mean_squared_error: 0.0091\n",
      "Epoch 207/400\n",
      "56/56 [==============================] - 1s 26ms/step - loss: 0.0018 - mean_absolute_error: 0.0329 - mean_squared_error: 0.0018 - val_loss: 0.0092 - val_mean_absolute_error: 0.0656 - val_mean_squared_error: 0.0094\n",
      "Best val_loss @ Epoch #182\n",
      "\n",
      "***Predictions from the best model.***\n",
      "\n",
      "For the training set:\n",
      "MAE: 0.2444 RMSE: 0.3407 R^2: 0.9921\n",
      "\n",
      "For the validation set:\n",
      "MAE: 0.6481 RMSE: 0.9360 R^2: 0.9474\n",
      "\n",
      "For the test set:\n",
      "MAE: 0.7433 RMSE: 1.1271 R^2: 0.8941\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main.Main(data=sol_data, \n",
    "          data_name=data_name, \n",
    "          data_units='', \n",
    "          bayopt_bounds=bounds, \n",
    "          k_fold_number = 3, \n",
    "          augmentation = True, \n",
    "          outdir = \"./data/\", \n",
    "          bayopt_n_rounds = 5, \n",
    "          bayopt_on = True, \n",
    "          lstmunits_ref = 128, \n",
    "          denseunits_ref = 16, \n",
    "          embedding_ref = 32, \n",
    "          seed_ref = None, \n",
    "          n_gpus = 1,\n",
    "          gpus_list = None, \n",
    "          gpus_debug = False,\n",
    "          batchsize_pergpu = 64,  \n",
    "          patience = 25, \n",
    "          n_epochs = 400, \n",
    "          lr_schedule = 'decay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***SMILES_X for inference starts...***\n",
      "\n",
      "\n",
      "***Checking the SMILES list for inference***\n",
      "\n",
      "***Data augmentation.***\n",
      "\n",
      "Enumerated SMILES: 5\n",
      "\n",
      "***Tokenization of SMILES.***\n",
      "\n",
      "Full vocabulary: ['pad', 'unk', 'Cl', '[N+]', '\\\\', ')', '2', '-', 'c', '1', 'P', 'n', '=', ' ', '[C@@]', 'S', '3', 'Br', '#', '/', '[O-]', '[C@@H]', '[C@H]', '[nH]', '5', '4', 'C', 's', '(', 'N', 'F', '[S+2]', 'I', '[C@]', 'O']\n",
      "Of size: 35\n",
      "\n",
      "Maximum length of tokenized SMILES: 51 tokens\n",
      "\n",
      "***Inference of SMILES property done.***\n"
     ]
    }
   ],
   "source": [
    "pred_from_ens = inference.Inference(data_name=data_name, \n",
    "                                    smiles_list = ['CC','CCC','C=O','ABC','DEF'], \n",
    "                                    data_units = '',\n",
    "                                    k_fold_number = 3,\n",
    "                                    augmentation = True, \n",
    "                                    outdir = \"./data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMILES</th>\n",
       "      <th>ens_pred_mean</th>\n",
       "      <th>ens_pred_sd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CC</td>\n",
       "      <td>0.406713</td>\n",
       "      <td>0.0213377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CCC</td>\n",
       "      <td>0.43053</td>\n",
       "      <td>0.020964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C=O</td>\n",
       "      <td>0.00962523</td>\n",
       "      <td>0.0223681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SMILES ens_pred_mean ens_pred_sd\n",
       "0     CC      0.406713   0.0213377\n",
       "1    CCC       0.43053    0.020964\n",
       "2    C=O    0.00962523   0.0223681"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_from_ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
