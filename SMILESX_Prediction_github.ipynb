{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [15:56:47] Enabling RDKit 2019.09.2 jupyter extensions\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from SMILESX import main, inference, utils\n",
    "%load_ext autoreload\n",
    "%aimport SMILESX\n",
    "%autoreload 1\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Read data file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data_dir = \"./validation_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "extension = '.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'FreeSolv' # FreeSolv, ESOL, Lipophilicity\n",
    "prop_tag = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_name == 'FreeSolv':\n",
    "    data_filename = 'FreeSolv_SAMPL'\n",
    "    prop_tag = 'expt'\n",
    "elif data_name == 'ESOL':\n",
    "    data_filename = 'ESOL_delaney-processed'\n",
    "    prop_tag = 'measured log solubility in mols per litre'\n",
    "elif data_name == 'Lipophilicity':\n",
    "    data_filename = 'Lipophilicity'\n",
    "    prop_tag = 'exp'\n",
    "else:\n",
    "    data_filename = data_name\n",
    "    prop_tag = prop_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol_data = pd.read_csv(validation_data_dir+data_filename+extension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>iupac</th>\n",
       "      <th>smiles</th>\n",
       "      <th>expt</th>\n",
       "      <th>calc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4-methoxy-N,N-dimethyl-benzamide</td>\n",
       "      <td>COc1ccc(C(=O)N(C)C)cc1</td>\n",
       "      <td>-11.01</td>\n",
       "      <td>-9.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>methanesulfonyl chloride</td>\n",
       "      <td>CS(=O)(=O)Cl</td>\n",
       "      <td>-4.87</td>\n",
       "      <td>-6.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3-methylbut-1-ene</td>\n",
       "      <td>C=CC(C)C</td>\n",
       "      <td>1.83</td>\n",
       "      <td>2.452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                             iupac                  smiles  \\\n",
       "0           0  4-methoxy-N,N-dimethyl-benzamide  COc1ccc(C(=O)N(C)C)cc1   \n",
       "1           1          methanesulfonyl chloride            CS(=O)(=O)Cl   \n",
       "2           2                 3-methylbut-1-ene                C=CC(C)C   \n",
       "\n",
       "    expt   calc  \n",
       "0 -11.01 -9.625  \n",
       "1  -4.87 -6.219  \n",
       "2   1.83  2.452  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Observation**\n",
    "* The column containing the SMILES must be named 'smiles' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Extract relevant data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol_data = sol_data[['smiles',prop_tag]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>expt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COc1ccc(C(=O)N(C)C)cc1</td>\n",
       "      <td>-11.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CS(=O)(=O)Cl</td>\n",
       "      <td>-4.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C=CC(C)C</td>\n",
       "      <td>1.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CCc1cnccn1</td>\n",
       "      <td>-5.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CCCCCCCO</td>\n",
       "      <td>-4.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   smiles   expt\n",
       "0  COc1ccc(C(=O)N(C)C)cc1 -11.01\n",
       "1            CS(=O)(=O)Cl  -4.87\n",
       "2                C=CC(C)C   1.83\n",
       "3              CCc1cnccn1  -5.45\n",
       "4                CCCCCCCO  -4.21"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(642, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **SMILES check from RDKit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol_data, bad_smiles_list = utils.check_smiles(sol_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(642, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(642,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol_data.iloc[:,1].values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters optimization with GPyOpt (Bayesian optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dhyp_range = [int(2**itn) for itn in range(3,11)] # \n",
    "\n",
    "if data_name != 'Lipophilicity':\n",
    "    bounds = [\n",
    "        {'name': 'lstmunits', 'type': 'discrete', 'domain': dhyp_range}, \n",
    "        {'name': 'denseunits', 'type': 'discrete', 'domain': dhyp_range}, \n",
    "        {'name': 'embedding', 'type': 'discrete', 'domain': dhyp_range}\n",
    "    ]\n",
    "else:\n",
    "    bounds = [\n",
    "        {'name': 'lstmunits', 'type': 'discrete', 'domain': dhyp_range}, \n",
    "        {'name': 'denseunits', 'type': 'discrete', 'domain': dhyp_range}, \n",
    "        {'name': 'embedding', 'type': 'discrete', 'domain': dhyp_range}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs detected and configured.\n",
      "1 GPU device(s) will be used.\n",
      "\n",
      "***Data augmentation to True***\n",
      "\n",
      "***SMILES_X starts...***\n",
      "\n",
      "\n",
      "******\n",
      "***Fold #0 initiated...***\n",
      "******\n",
      "***Splitting and standardization of the dataset.***\n",
      "\n",
      "Scaler: RobustScaler(copy=True, quantile_range=(5.0, 95.0), with_centering=True,\n",
      "             with_scaling=True)\n",
      "Train/valid/test splits: 0.50/0.25/0.25\n",
      "\n",
      "\n",
      "Enumerated SMILES:\n",
      "\tTraining set: 2661\n",
      "\tValidation set: 1377\n",
      "\tTest set: 1317\n",
      "\n",
      "***Tokenization of SMILES.***\n",
      "\n",
      "Examples of tokenized SMILES from a training set:\n",
      "[[' ', 'C', 'S', '(', '=', 'O', ')', '(', '=', 'O', ')', 'Cl', ' '], [' ', 'S', '(', '=', 'O', ')', '(', '=', 'O', ')', '(', 'Cl', ')', 'C', ' '], [' ', 'O', '=', 'S', '(', '=', 'O', ')', '(', 'Cl', ')', 'C', ' '], [' ', 'O', '=', 'S', '(', 'Cl', ')', '(', 'C', ')', '=', 'O', ' '], [' ', 'Cl', 'S', '(', 'C', ')', '(', '=', 'O', ')', '=', 'O', ' ']]\n",
      "\n",
      "Number of tokens only present in a training set: 30\n",
      "\n",
      "Number of tokens only present in a validation set: 30\n",
      "Is the validation set a subset of the training set: False\n",
      "What are the tokens by which they differ: {'[S+2]', 's'}\n",
      "\n",
      "Number of tokens only present in a test set: 26\n",
      "Is the test set a subset of the training set: False\n",
      "What are the tokens by which they differ: {'s'}\n",
      "Is the test set a subset of the validation set: True\n",
      "What are the tokens by which they differ: set()\n",
      "\n",
      "Full vocabulary: ['S', 'C', '[C@@H]', '-', 'O', '5', '3', 'n', 's', 'Br', '[C@H]', '=', '[C@@]', '4', '(', '1', '[nH]', 'P', '[C@]', '#', ' ', 'I', 'Cl', '[N+]', '/', 'c', 'F', ')', '2', 'N', '[O-]', '[S+2]']\n",
      "Of size: 32\n",
      "\n",
      "Maximum length of tokenized SMILES: 50 tokens (termination spaces included)\n",
      "\n",
      "***Bayesian Optimization of the SMILESX's architecture.***\n",
      "\n",
      "Random initialization:\n",
      "\n",
      "Model: [64, 16, 512]\n",
      "Train MSE mean: 0.1775, MSE std: 0.1137\n",
      "Model: [16, 8, 1024]\n",
      "Train MSE mean: 0.1813, MSE std: 0.0777\n",
      "Model: [512, 16, 16]\n",
      "Train MSE mean: 0.1074, MSE std: 0.0016\n",
      "Optimization:\n",
      "\n",
      "Model: [128, 64, 64]\n",
      "Train MSE mean: 0.1209, MSE std: 0.0160\n",
      "Model: [32, 128, 1024]\n",
      "Train MSE mean: 0.2890, MSE std: 0.2013\n",
      "Model: [32, 512, 64]\n",
      "Train MSE mean: 0.1445, MSE std: 0.0539\n",
      "\n",
      "The architecture for this datatset is:\n",
      "\tLSTM units: 512\n",
      "\tDense units: 16\n",
      "\tEmbedding dimensions 16\n",
      "***Training of the best model.***\n",
      "\n",
      "Best model summary:\n",
      "\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 51)]              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 51, 16)            544       \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 51, 1024)          2166784   \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 51, 16)            16400     \n",
      "_________________________________________________________________\n",
      "attention_m (AttentionM)     (None, 16)                67        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 2,183,812\n",
      "Trainable params: 2,183,812\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 42 steps, validate for 22 steps\n",
      "Epoch 1/10\n",
      "42/42 [==============================] - 3s 73ms/step - loss: 0.0980 - mean_absolute_error: 0.2300 - mean_squared_error: 0.0987 - val_loss: 0.0608 - val_mean_absolute_error: 0.1929 - val_mean_squared_error: 0.0615\n",
      "Epoch 2/10\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.0719 - mean_absolute_error: 0.1965 - mean_squared_error: 0.0723 - val_loss: 0.0458 - val_mean_absolute_error: 0.1670 - val_mean_squared_error: 0.0462\n",
      "Epoch 3/10\n",
      "42/42 [==============================] - 1s 19ms/step - loss: 0.0501 - mean_absolute_error: 0.1740 - mean_squared_error: 0.0505 - val_loss: 0.0438 - val_mean_absolute_error: 0.1634 - val_mean_squared_error: 0.0442\n",
      "Epoch 4/10\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.0458 - mean_absolute_error: 0.1603 - mean_squared_error: 0.0459 - val_loss: 0.0342 - val_mean_absolute_error: 0.1433 - val_mean_squared_error: 0.0342\n",
      "Epoch 5/10\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0391 - mean_absolute_error: 0.1509 - mean_squared_error: 0.0393 - val_loss: 0.0355 - val_mean_absolute_error: 0.1459 - val_mean_squared_error: 0.0351\n",
      "Epoch 6/10\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.0283 - mean_absolute_error: 0.1310 - mean_squared_error: 0.0286 - val_loss: 0.0318 - val_mean_absolute_error: 0.1400 - val_mean_squared_error: 0.0316\n",
      "Epoch 7/10\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.0289 - mean_absolute_error: 0.1321 - mean_squared_error: 0.0291 - val_loss: 0.0296 - val_mean_absolute_error: 0.1360 - val_mean_squared_error: 0.0294\n",
      "Epoch 8/10\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0280 - mean_absolute_error: 0.1266 - mean_squared_error: 0.0282 - val_loss: 0.0345 - val_mean_absolute_error: 0.1447 - val_mean_squared_error: 0.0349\n",
      "Epoch 9/10\n",
      "42/42 [==============================] - 1s 18ms/step - loss: 0.0239 - mean_absolute_error: 0.1234 - mean_squared_error: 0.0240 - val_loss: 0.0269 - val_mean_absolute_error: 0.1285 - val_mean_squared_error: 0.0266\n",
      "Epoch 10/10\n",
      "42/42 [==============================] - 1s 16ms/step - loss: 0.0263 - mean_absolute_error: 0.1253 - mean_squared_error: 0.0265 - val_loss: 0.4383 - val_mean_absolute_error: 0.2923 - val_mean_squared_error: 0.4475\n",
      "Best val_loss @ Epoch #9\n",
      "\n",
      "***Predictions from the best model.***\n",
      "\n",
      "For the training set:\n",
      "MAE: 1.3903 RMSE: 1.7495 R^2: 0.8027\n",
      "\n",
      "For the validation set:\n",
      "MAE: 1.4840 RMSE: 1.8914 R^2: 0.7326\n",
      "\n",
      "For the test set:\n",
      "MAE: 1.3850 RMSE: 1.8053 R^2: 0.7780\n",
      "\n",
      "******\n",
      "***Fold #1 initiated...***\n",
      "******\n",
      "***Splitting and standardization of the dataset.***\n",
      "\n",
      "Scaler: RobustScaler(copy=True, quantile_range=(5.0, 95.0), with_centering=True,\n",
      "             with_scaling=True)\n",
      "Train/valid/test splits: 0.50/0.25/0.25\n",
      "\n",
      "\n",
      "Enumerated SMILES:\n",
      "\tTraining set: 2694\n",
      "\tValidation set: 1216\n",
      "\tTest set: 1445\n",
      "\n",
      "***Tokenization of SMILES.***\n",
      "\n",
      "Examples of tokenized SMILES from a training set:\n",
      "[[' ', 'C', 'O', 'c', '1', 'c', 'c', 'c', '(', 'C', '(', '=', 'O', ')', 'N', '(', 'C', ')', 'C', ')', 'c', 'c', '1', ' '], [' ', 'O', '(', 'c', '1', 'c', 'c', 'c', '(', 'C', '(', '=', 'O', ')', 'N', '(', 'C', ')', 'C', ')', 'c', 'c', '1', ')', 'C', ' '], [' ', 'c', '1', '(', 'O', 'C', ')', 'c', 'c', 'c', '(', 'C', '(', '=', 'O', ')', 'N', '(', 'C', ')', 'C', ')', 'c', 'c', '1', ' '], [' ', 'c', '1', 'c', 'c', '(', 'C', '(', '=', 'O', ')', 'N', '(', 'C', ')', 'C', ')', 'c', 'c', 'c', '1', 'O', 'C', ' '], [' ', 'c', '1', 'c', '(', 'C', '(', '=', 'O', ')', 'N', '(', 'C', ')', 'C', ')', 'c', 'c', 'c', '(', 'O', 'C', ')', 'c', '1', ' ']]\n",
      "\n",
      "Number of tokens only present in a training set: 30\n",
      "\n",
      "Number of tokens only present in a validation set: 28\n",
      "Is the validation set a subset of the training set: True\n",
      "What are the tokens by which they differ: set()\n",
      "\n",
      "Number of tokens only present in a test set: 30\n",
      "Is the test set a subset of the training set: False\n",
      "What are the tokens by which they differ: {'4', '5'}\n",
      "Is the test set a subset of the validation set: False\n",
      "What are the tokens by which they differ: {'4', '5'}\n",
      "\n",
      "Full vocabulary: ['S', 'C', '[C@@H]', '-', 'O', '5', '3', 'n', 's', 'Br', '[C@H]', '=', '[C@@]', '4', '(', '1', '[nH]', 'P', '[C@]', '#', ' ', 'I', 'Cl', '[N+]', '/', 'c', 'F', ')', '2', 'N', '[O-]', '[S+2]']\n",
      "Of size: 32\n",
      "\n",
      "Maximum length of tokenized SMILES: 50 tokens (termination spaces included)\n",
      "\n",
      "***Bayesian Optimization of the SMILESX's architecture.***\n",
      "\n",
      "Random initialization:\n",
      "\n",
      "Model: [256, 64, 8]\n",
      "Train MSE mean: 0.1075, MSE std: 0.0010\n",
      "Model: [8, 64, 128]\n",
      "Train MSE mean: 0.1464, MSE std: 0.0407\n",
      "Model: [32, 32, 16]\n",
      "Train MSE mean: 0.1253, MSE std: 0.0165\n",
      "Optimization:\n",
      "\n",
      "Model: [32, 8, 32]\n",
      "Train MSE mean: 0.1179, MSE std: 0.0140\n",
      "Model: [512, 128, 32]\n",
      "Train MSE mean: 0.1090, MSE std: 0.0025\n",
      "Model: [16, 128, 16]\n",
      "Train MSE mean: 0.1714, MSE std: 0.0764\n",
      "\n",
      "The architecture for this datatset is:\n",
      "\tLSTM units: 256\n",
      "\tDense units: 64\n",
      "\tEmbedding dimensions 8\n",
      "***Training of the best model.***\n",
      "\n",
      "Best model summary:\n",
      "\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 51)]              0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 51, 8)             272       \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 51, 512)           542720    \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 51, 64)            32832     \n",
      "_________________________________________________________________\n",
      "attention_m (AttentionM)     (None, 64)                115       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 576,004\n",
      "Trainable params: 576,004\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 43 steps, validate for 19 steps\n",
      "Epoch 1/10\n",
      "43/43 [==============================] - 3s 67ms/step - loss: 0.1033 - mean_absolute_error: 0.2402 - mean_squared_error: 0.1031 - val_loss: 0.1329 - val_mean_absolute_error: 0.2669 - val_mean_squared_error: 0.1329\n",
      "Epoch 2/10\n",
      "43/43 [==============================] - 0s 11ms/step - loss: 0.0932 - mean_absolute_error: 0.2254 - mean_squared_error: 0.0941 - val_loss: 0.1237 - val_mean_absolute_error: 0.2456 - val_mean_squared_error: 0.1237\n",
      "Epoch 3/10\n",
      "43/43 [==============================] - 0s 11ms/step - loss: 0.0875 - mean_absolute_error: 0.2175 - mean_squared_error: 0.0890 - val_loss: 0.1173 - val_mean_absolute_error: 0.2449 - val_mean_squared_error: 0.1173\n",
      "Epoch 4/10\n",
      "43/43 [==============================] - 0s 12ms/step - loss: 0.0874 - mean_absolute_error: 0.2170 - mean_squared_error: 0.0888 - val_loss: 0.1125 - val_mean_absolute_error: 0.2512 - val_mean_squared_error: 0.1125\n",
      "Epoch 5/10\n",
      "43/43 [==============================] - 0s 12ms/step - loss: 0.0844 - mean_absolute_error: 0.2204 - mean_squared_error: 0.0856 - val_loss: 0.1006 - val_mean_absolute_error: 0.2215 - val_mean_squared_error: 0.1006\n",
      "Epoch 6/10\n",
      "43/43 [==============================] - 0s 11ms/step - loss: 0.0982 - mean_absolute_error: 0.1992 - mean_squared_error: 0.0993 - val_loss: 0.0952 - val_mean_absolute_error: 0.2312 - val_mean_squared_error: 0.0952\n",
      "Epoch 7/10\n",
      "43/43 [==============================] - 0s 12ms/step - loss: 0.0757 - mean_absolute_error: 0.2005 - mean_squared_error: 0.0761 - val_loss: 0.0836 - val_mean_absolute_error: 0.2184 - val_mean_squared_error: 0.0836\n",
      "Epoch 8/10\n",
      "43/43 [==============================] - 0s 12ms/step - loss: 0.0563 - mean_absolute_error: 0.1760 - mean_squared_error: 0.0570 - val_loss: 0.0741 - val_mean_absolute_error: 0.2048 - val_mean_squared_error: 0.0741\n",
      "Epoch 9/10\n",
      "43/43 [==============================] - 0s 11ms/step - loss: 0.0522 - mean_absolute_error: 0.1813 - mean_squared_error: 0.0529 - val_loss: 0.0501 - val_mean_absolute_error: 0.1795 - val_mean_squared_error: 0.0501\n",
      "Epoch 10/10\n",
      "43/43 [==============================] - 0s 11ms/step - loss: 0.0457 - mean_absolute_error: 0.1738 - mean_squared_error: 0.0460 - val_loss: 0.0507 - val_mean_absolute_error: 0.1702 - val_mean_squared_error: 0.0507\n",
      "Best val_loss @ Epoch #9\n",
      "\n",
      "***Predictions from the best model.***\n",
      "\n",
      "For the training set:\n",
      "MAE: 1.8560 RMSE: 2.3155 R^2: 0.6181\n",
      "\n",
      "For the validation set:\n",
      "MAE: 1.9921 RMSE: 2.4773 R^2: 0.6659\n",
      "\n",
      "For the test set:\n",
      "MAE: 1.9311 RMSE: 2.4471 R^2: 0.5200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main.Main(data=sol_data, \n",
    "          data_name=data_name, \n",
    "          data_units='', \n",
    "          bayopt_bounds=bounds, \n",
    "          k_fold_number = 10, \n",
    "          augmentation = True, \n",
    "          outdir = \"./data/\", \n",
    "          bayopt_n_rounds = 25, \n",
    "          bayopt_on = True, \n",
    "          lstmunits_ref = 128, \n",
    "          denseunits_ref = 16, \n",
    "          embedding_ref = 32, \n",
    "          seed_ref = None, \n",
    "          n_gpus = 1,\n",
    "          gpus_list = None, \n",
    "          gpus_debug = False,\n",
    "          batchsize_pergpu = 64,  \n",
    "          patience = 25, \n",
    "          n_epochs = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***SMILES_X for inference starts...***\n",
      "\n",
      "\n",
      "***Checking the SMILES list for inference***\n",
      "\n",
      "***Data augmentation.***\n",
      "\n",
      "Enumerated SMILES: 5\n",
      "\n",
      "***Tokenization of SMILES.***\n",
      "\n",
      "Full vocabulary: ['pad', 'unk', 'Cl', '[N+]', '\\\\', ')', '2', '-', 'c', '1', 'P', 'n', '=', ' ', '[C@@]', 'S', '3', 'Br', '#', '/', '[O-]', '[C@@H]', '[C@H]', '[nH]', '5', '4', 'C', 's', '(', 'N', 'F', '[S+2]', 'I', '[C@]', 'O']\n",
      "Of size: 35\n",
      "\n",
      "Maximum length of tokenized SMILES: 51 tokens\n",
      "\n",
      "***Inference of SMILES property done.***\n"
     ]
    }
   ],
   "source": [
    "pred_from_ens = inference.Inference(data_name=data_name, \n",
    "                                    smiles_list = ['CC','CCC','C=O','ABC','DEF'], \n",
    "                                    data_units = '',\n",
    "                                    k_fold_number = 3,\n",
    "                                    augmentation = True, \n",
    "                                    outdir = \"./data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMILES</th>\n",
       "      <th>ens_pred_mean</th>\n",
       "      <th>ens_pred_sd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CC</td>\n",
       "      <td>0.406713</td>\n",
       "      <td>0.0213377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CCC</td>\n",
       "      <td>0.43053</td>\n",
       "      <td>0.020964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C=O</td>\n",
       "      <td>0.00962523</td>\n",
       "      <td>0.0223681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SMILES ens_pred_mean ens_pred_sd\n",
       "0     CC      0.406713   0.0213377\n",
       "1    CCC       0.43053    0.020964\n",
       "2    C=O    0.00962523   0.0223681"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_from_ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
