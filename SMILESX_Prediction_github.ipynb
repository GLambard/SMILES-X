{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (main.py, line 210)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/home/guillaume/miniconda3/envs/tf2_gpu/lib/python3.7/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3319\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-2aa8af042d80>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    from SMILESX import main, inference, utils\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"/home/guillaume/Documents/Projects/SMILES-X/SMILESX/main.py\"\u001b[0;36m, line \u001b[0;32m210\u001b[0m\n\u001b[0;31m    y_valid =\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from SMILESX import main, inference, utils\n",
    "%load_ext autoreload\n",
    "%aimport SMILESX\n",
    "%autoreload 1\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Read data file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data_dir = \"./validation_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "extension = '.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'FreeSolv' # FreeSolv, ESOL, Lipophilicity\n",
    "prop_tag = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_name == 'FreeSolv':\n",
    "    data_filename = 'FreeSolv_SAMPL'\n",
    "    prop_tag = 'expt'\n",
    "elif data_name == 'ESOL':\n",
    "    data_filename = 'ESOL_delaney-processed'\n",
    "    prop_tag = 'measured log solubility in mols per litre'\n",
    "elif data_name == 'Lipophilicity':\n",
    "    data_filename = 'Lipophilicity'\n",
    "    prop_tag = 'exp'\n",
    "else:\n",
    "    data_filename = data_name\n",
    "    prop_tag = prop_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol_data = pd.read_csv(validation_data_dir+data_filename+extension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>iupac</th>\n",
       "      <th>smiles</th>\n",
       "      <th>expt</th>\n",
       "      <th>calc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4-methoxy-N,N-dimethyl-benzamide</td>\n",
       "      <td>COc1ccc(C(=O)N(C)C)cc1</td>\n",
       "      <td>-11.01</td>\n",
       "      <td>-9.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>methanesulfonyl chloride</td>\n",
       "      <td>CS(=O)(=O)Cl</td>\n",
       "      <td>-4.87</td>\n",
       "      <td>-6.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3-methylbut-1-ene</td>\n",
       "      <td>C=CC(C)C</td>\n",
       "      <td>1.83</td>\n",
       "      <td>2.452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                             iupac                  smiles  \\\n",
       "0           0  4-methoxy-N,N-dimethyl-benzamide  COc1ccc(C(=O)N(C)C)cc1   \n",
       "1           1          methanesulfonyl chloride            CS(=O)(=O)Cl   \n",
       "2           2                 3-methylbut-1-ene                C=CC(C)C   \n",
       "\n",
       "    expt   calc  \n",
       "0 -11.01 -9.625  \n",
       "1  -4.87 -6.219  \n",
       "2   1.83  2.452  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Observation**\n",
    "* The column containing the SMILES must be named 'smiles' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Extract relevant data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol_data = sol_data[['smiles',prop_tag]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>expt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COc1ccc(C(=O)N(C)C)cc1</td>\n",
       "      <td>-11.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CS(=O)(=O)Cl</td>\n",
       "      <td>-4.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C=CC(C)C</td>\n",
       "      <td>1.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CCc1cnccn1</td>\n",
       "      <td>-5.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CCCCCCCO</td>\n",
       "      <td>-4.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   smiles   expt\n",
       "0  COc1ccc(C(=O)N(C)C)cc1 -11.01\n",
       "1            CS(=O)(=O)Cl  -4.87\n",
       "2                C=CC(C)C   1.83\n",
       "3              CCc1cnccn1  -5.45\n",
       "4                CCCCCCCO  -4.21"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(642, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **SMILES check from RDKit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol_data, bad_smiles_list = utils.check_smiles(sol_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(642, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(642,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sol_data.iloc[:,1].values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters optimization with GPyOpt (Bayesian optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dhyp_range = [int(2**itn) for itn in range(3,11)] # \n",
    "dalpha_range = [float(ialpha/10.) for ialpha in range(20,40,1)] # Adam's learning rate = 10^(-dalpha_range)\n",
    "\n",
    "if data_name != 'Lipophilicity':\n",
    "    bounds = [\n",
    "        {'name': 'lstmunits', 'type': 'discrete', 'domain': dhyp_range}, \n",
    "        {'name': 'denseunits', 'type': 'discrete', 'domain': dhyp_range}, \n",
    "        {'name': 'embedding', 'type': 'discrete', 'domain': dhyp_range}, \n",
    "        {'name': 'batchsize', 'type': 'discrete', 'domain': dhyp_range}, \n",
    "        {'name': 'lrate', 'type': 'discrete', 'domain': dalpha_range}\n",
    "    ]\n",
    "else:\n",
    "    bounds = [\n",
    "        {'name': 'lstmunits', 'type': 'discrete', 'domain': dhyp_range}, \n",
    "        {'name': 'denseunits', 'type': 'discrete', 'domain': dhyp_range}, \n",
    "        {'name': 'embedding', 'type': 'discrete', 'domain': dhyp_range}, \n",
    "        {'name': 'batchsize', 'type': 'discrete', 'domain': (1024, 1024)}, # fixed\n",
    "        {'name': 'lrate', 'type': 'discrete', 'domain': (3, 3)} # fixed\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***SMILES_X starts...***\n",
      "\n",
      "\n",
      "******\n",
      "***Fold #0 initiated...***\n",
      "******\n",
      "***Sampling and splitting of the dataset.***\n",
      "\n",
      "Scaler: RobustScaler(copy=True, quantile_range=(5.0, 95.0), with_centering=True,\n",
      "             with_scaling=True)\n",
      "Train/valid/test splits: 0.80/0.10/0.10\n",
      "\n",
      "\n",
      "***Data augmentation to True***\n",
      "\n",
      "Enumerated SMILES:\n",
      "\tTraining set: 4285\n",
      "\tValidation set: 501\n",
      "\tTest set: 569\n",
      "\n",
      "***Tokenization of SMILES.***\n",
      "\n",
      "Examples of tokenized SMILES from a training set:\n",
      "[[' ', 'C', 'Cl', ' '], [' ', 'Cl', 'C', ' '], [' ', 'C', 'C', 'c', '1', 'c', 'c', 'n', 'c', 'c', '1', ' '], [' ', 'C', '(', 'c', '1', 'c', 'c', 'n', 'c', 'c', '1', ')', 'C', ' '], [' ', 'c', '1', '(', 'C', 'C', ')', 'c', 'c', 'n', 'c', 'c', '1', ' ']]\n",
      "\n",
      "Number of tokens only present in a training set: 32\n",
      "\n",
      "Number of tokens only present in a validation set: 27\n",
      "Is the validation set a subset of the training set: True\n",
      "What are the tokens by which they differ: set()\n",
      "\n",
      "Number of tokens only present in a test set: 27\n",
      "Is the test set a subset of the training set: False\n",
      "What are the tokens by which they differ: {'5'}\n",
      "Is the test set a subset of the validation set: False\n",
      "What are the tokens by which they differ: {'[N+]', '[O-]', '4', '5'}\n",
      "\n",
      "Full vocabulary: {'Cl', '[N+]', '\\\\', ')', '2', '-', 'c', '1', 'P', 'n', '=', ' ', '[C@@]', 'S', '3', 'Br', '#', '/', '[O-]', '[C@@H]', '[C@H]', '[nH]', '5', '4', 'C', 's', '(', 'N', 'F', '[S+2]', 'I', '[C@]', 'O'}\n",
      "Of size: 33\n",
      "\n",
      "Maximum length of tokenized SMILES: 50 tokens (termination spaces included)\n",
      "\n",
      "***Bayesian Optimization of the SMILESX's architecture.***\n",
      "\n",
      "Random initialization:\n",
      "\n",
      "Model: [[ 128.    32.  1024.   256.     2.5]]\n",
      "WARNING:tensorflow:From /home/lambard/miniconda3/envs/my-py37-env/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/lambard/miniconda3/envs/my-py37-env/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Valid MAE: 0.2518, RMSE: 0.0933\n",
      "Optimization:\n",
      "\n",
      "Model: [[  8.   64.  256.   32.    2.6]]\n",
      "Valid MAE: 0.1557, RMSE: 0.0345\n",
      "\n",
      "The architecture for this datatset is:\n",
      "\tLSTM units: 8\n",
      "\tDense units: 64\n",
      "\tEmbedding dimensions 256\n",
      "\tBatch size: 32\n",
      "\tLearning rate: 10^-(2.6)\n",
      "\n",
      "***Training of the best model.***\n",
      "\n",
      "Best model summary:\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 51)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 51, 256)           8960      \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 51, 16)            17024     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 51, 64)            1088      \n",
      "_________________________________________________________________\n",
      "attention_m_1 (AttentionM)   (None, 64)                115       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 27,252\n",
      "Trainable params: 27,252\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      "Epoch 1/100\n",
      "134/134 [==============================] - 1s 9ms/step - loss: 0.0765 - mean_absolute_error: 0.2091 - mean_squared_error: 0.0765 - val_loss: 0.0425 - val_mean_absolute_error: 0.1642 - val_mean_squared_error: 0.0425\n",
      "Epoch 2/100\n",
      "134/134 [==============================] - 1s 6ms/step - loss: 0.0313 - mean_absolute_error: 0.1396 - mean_squared_error: 0.0313 - val_loss: 0.0183 - val_mean_absolute_error: 0.1083 - val_mean_squared_error: 0.0183\n",
      "Epoch 3/100\n",
      "134/134 [==============================] - 1s 6ms/step - loss: 0.0284 - mean_absolute_error: 0.1326 - mean_squared_error: 0.0284 - val_loss: 0.0208 - val_mean_absolute_error: 0.1152 - val_mean_squared_error: 0.0208\n",
      "Epoch 4/100\n",
      "134/134 [==============================] - 1s 6ms/step - loss: 0.0236 - mean_absolute_error: 0.1223 - mean_squared_error: 0.0236 - val_loss: 0.0143 - val_mean_absolute_error: 0.1006 - val_mean_squared_error: 0.0143\n",
      "Epoch 5/100\n",
      "134/134 [==============================] - 1s 5ms/step - loss: 0.0229 - mean_absolute_error: 0.1167 - mean_squared_error: 0.0229 - val_loss: 0.0125 - val_mean_absolute_error: 0.0937 - val_mean_squared_error: 0.0125\n",
      "Epoch 6/100\n",
      "134/134 [==============================] - 1s 6ms/step - loss: 0.0185 - mean_absolute_error: 0.1068 - mean_squared_error: 0.0185 - val_loss: 0.0143 - val_mean_absolute_error: 0.0990 - val_mean_squared_error: 0.0143\n",
      "Epoch 7/100\n",
      "134/134 [==============================] - 1s 6ms/step - loss: 0.0184 - mean_absolute_error: 0.1072 - mean_squared_error: 0.0184 - val_loss: 0.0103 - val_mean_absolute_error: 0.0848 - val_mean_squared_error: 0.0103\n",
      "Epoch 8/100\n",
      "134/134 [==============================] - 1s 5ms/step - loss: 0.0175 - mean_absolute_error: 0.1021 - mean_squared_error: 0.0175 - val_loss: 0.0132 - val_mean_absolute_error: 0.0928 - val_mean_squared_error: 0.0132\n",
      "Epoch 9/100\n",
      "134/134 [==============================] - 1s 6ms/step - loss: 0.0162 - mean_absolute_error: 0.1006 - mean_squared_error: 0.0162 - val_loss: 0.0210 - val_mean_absolute_error: 0.1156 - val_mean_squared_error: 0.0210\n",
      "Epoch 10/100\n",
      "134/134 [==============================] - 1s 6ms/step - loss: 0.0158 - mean_absolute_error: 0.0992 - mean_squared_error: 0.0158 - val_loss: 0.0116 - val_mean_absolute_error: 0.0879 - val_mean_squared_error: 0.0116\n",
      "Epoch 11/100\n",
      "134/134 [==============================] - 1s 6ms/step - loss: 0.0141 - mean_absolute_error: 0.0929 - mean_squared_error: 0.0141 - val_loss: 0.0111 - val_mean_absolute_error: 0.0872 - val_mean_squared_error: 0.0111\n",
      "Epoch 12/100\n",
      "134/134 [==============================] - 1s 5ms/step - loss: 0.0126 - mean_absolute_error: 0.0872 - mean_squared_error: 0.0126 - val_loss: 0.0111 - val_mean_absolute_error: 0.0853 - val_mean_squared_error: 0.0111\n",
      "Epoch 13/100\n",
      "134/134 [==============================] - 1s 6ms/step - loss: 0.0126 - mean_absolute_error: 0.0857 - mean_squared_error: 0.0126 - val_loss: 0.0109 - val_mean_absolute_error: 0.0829 - val_mean_squared_error: 0.0109\n",
      "Epoch 14/100\n",
      "134/134 [==============================] - 1s 6ms/step - loss: 0.0125 - mean_absolute_error: 0.0855 - mean_squared_error: 0.0125 - val_loss: 0.0112 - val_mean_absolute_error: 0.0873 - val_mean_squared_error: 0.0112\n",
      "Epoch 15/100\n",
      "134/134 [==============================] - 1s 6ms/step - loss: 0.0113 - mean_absolute_error: 0.0808 - mean_squared_error: 0.0113 - val_loss: 0.0107 - val_mean_absolute_error: 0.0826 - val_mean_squared_error: 0.0107\n",
      "Epoch 16/100\n",
      "134/134 [==============================] - 1s 8ms/step - loss: 0.0106 - mean_absolute_error: 0.0779 - mean_squared_error: 0.0106 - val_loss: 0.0093 - val_mean_absolute_error: 0.0745 - val_mean_squared_error: 0.0093\n",
      "Epoch 17/100\n",
      "134/134 [==============================] - 1s 7ms/step - loss: 0.0103 - mean_absolute_error: 0.0771 - mean_squared_error: 0.0103 - val_loss: 0.0110 - val_mean_absolute_error: 0.0839 - val_mean_squared_error: 0.0110\n",
      "Epoch 18/100\n",
      "134/134 [==============================] - 1s 6ms/step - loss: 0.0104 - mean_absolute_error: 0.0786 - mean_squared_error: 0.0104 - val_loss: 0.0093 - val_mean_absolute_error: 0.0757 - val_mean_squared_error: 0.0093\n",
      "Epoch 19/100\n",
      "134/134 [==============================] - 1s 5ms/step - loss: 0.0097 - mean_absolute_error: 0.0753 - mean_squared_error: 0.0097 - val_loss: 0.0091 - val_mean_absolute_error: 0.0694 - val_mean_squared_error: 0.0091\n",
      "Epoch 20/100\n",
      "134/134 [==============================] - 1s 6ms/step - loss: 0.0099 - mean_absolute_error: 0.0768 - mean_squared_error: 0.0099 - val_loss: 0.0128 - val_mean_absolute_error: 0.0856 - val_mean_squared_error: 0.0128\n",
      "Epoch 21/100\n",
      "134/134 [==============================] - 1s 9ms/step - loss: 0.0083 - mean_absolute_error: 0.0699 - mean_squared_error: 0.0083 - val_loss: 0.0110 - val_mean_absolute_error: 0.0795 - val_mean_squared_error: 0.0110\n",
      "Epoch 22/100\n",
      "134/134 [==============================] - 1s 7ms/step - loss: 0.0085 - mean_absolute_error: 0.0698 - mean_squared_error: 0.0085 - val_loss: 0.0090 - val_mean_absolute_error: 0.0713 - val_mean_squared_error: 0.0090\n",
      "Epoch 23/100\n",
      "134/134 [==============================] - 1s 6ms/step - loss: 0.0090 - mean_absolute_error: 0.0721 - mean_squared_error: 0.0090 - val_loss: 0.0090 - val_mean_absolute_error: 0.0734 - val_mean_squared_error: 0.0090\n",
      "Epoch 24/100\n",
      "134/134 [==============================] - 1s 7ms/step - loss: 0.0087 - mean_absolute_error: 0.0717 - mean_squared_error: 0.0087 - val_loss: 0.0089 - val_mean_absolute_error: 0.0699 - val_mean_squared_error: 0.0089\n",
      "Epoch 25/100\n",
      "134/134 [==============================] - 1s 7ms/step - loss: 0.0083 - mean_absolute_error: 0.0697 - mean_squared_error: 0.0083 - val_loss: 0.0093 - val_mean_absolute_error: 0.0740 - val_mean_squared_error: 0.0093\n",
      "Epoch 26/100\n",
      "134/134 [==============================] - 1s 8ms/step - loss: 0.0088 - mean_absolute_error: 0.0723 - mean_squared_error: 0.0088 - val_loss: 0.0091 - val_mean_absolute_error: 0.0718 - val_mean_squared_error: 0.0091\n",
      "Epoch 27/100\n",
      "134/134 [==============================] - 1s 8ms/step - loss: 0.0080 - mean_absolute_error: 0.0693 - mean_squared_error: 0.0080 - val_loss: 0.0110 - val_mean_absolute_error: 0.0778 - val_mean_squared_error: 0.0110\n",
      "Epoch 28/100\n",
      "134/134 [==============================] - 1s 9ms/step - loss: 0.0078 - mean_absolute_error: 0.0666 - mean_squared_error: 0.0078 - val_loss: 0.0122 - val_mean_absolute_error: 0.0885 - val_mean_squared_error: 0.0122\n",
      "Epoch 29/100\n",
      "134/134 [==============================] - 1s 7ms/step - loss: 0.0074 - mean_absolute_error: 0.0648 - mean_squared_error: 0.0074 - val_loss: 0.0107 - val_mean_absolute_error: 0.0792 - val_mean_squared_error: 0.0107\n",
      "Epoch 30/100\n",
      "134/134 [==============================] - 1s 7ms/step - loss: 0.0075 - mean_absolute_error: 0.0668 - mean_squared_error: 0.0075 - val_loss: 0.0092 - val_mean_absolute_error: 0.0743 - val_mean_squared_error: 0.0092\n",
      "Epoch 31/100\n",
      "134/134 [==============================] - 1s 7ms/step - loss: 0.0071 - mean_absolute_error: 0.0640 - mean_squared_error: 0.0071 - val_loss: 0.0098 - val_mean_absolute_error: 0.0781 - val_mean_squared_error: 0.0098\n",
      "Epoch 32/100\n",
      "134/134 [==============================] - 1s 7ms/step - loss: 0.0068 - mean_absolute_error: 0.0621 - mean_squared_error: 0.0068 - val_loss: 0.0089 - val_mean_absolute_error: 0.0718 - val_mean_squared_error: 0.0089\n",
      "Epoch 33/100\n",
      "134/134 [==============================] - 1s 6ms/step - loss: 0.0069 - mean_absolute_error: 0.0626 - mean_squared_error: 0.0069 - val_loss: 0.0123 - val_mean_absolute_error: 0.0842 - val_mean_squared_error: 0.0123\n",
      "Epoch 34/100\n",
      "134/134 [==============================] - 1s 8ms/step - loss: 0.0068 - mean_absolute_error: 0.0616 - mean_squared_error: 0.0068 - val_loss: 0.0095 - val_mean_absolute_error: 0.0748 - val_mean_squared_error: 0.0095\n",
      "Epoch 35/100\n",
      "134/134 [==============================] - 1s 8ms/step - loss: 0.0065 - mean_absolute_error: 0.0618 - mean_squared_error: 0.0065 - val_loss: 0.0099 - val_mean_absolute_error: 0.0772 - val_mean_squared_error: 0.0099\n",
      "Epoch 36/100\n",
      "134/134 [==============================] - 1s 7ms/step - loss: 0.0062 - mean_absolute_error: 0.0598 - mean_squared_error: 0.0062 - val_loss: 0.0082 - val_mean_absolute_error: 0.0709 - val_mean_squared_error: 0.0082\n",
      "Epoch 37/100\n",
      "134/134 [==============================] - 1s 8ms/step - loss: 0.0058 - mean_absolute_error: 0.0576 - mean_squared_error: 0.0058 - val_loss: 0.0102 - val_mean_absolute_error: 0.0779 - val_mean_squared_error: 0.0102\n",
      "Epoch 38/100\n",
      "134/134 [==============================] - 1s 8ms/step - loss: 0.0065 - mean_absolute_error: 0.0613 - mean_squared_error: 0.0065 - val_loss: 0.0107 - val_mean_absolute_error: 0.0754 - val_mean_squared_error: 0.0107\n",
      "Epoch 39/100\n",
      "134/134 [==============================] - 1s 9ms/step - loss: 0.0066 - mean_absolute_error: 0.0614 - mean_squared_error: 0.0066 - val_loss: 0.0089 - val_mean_absolute_error: 0.0722 - val_mean_squared_error: 0.0089\n",
      "Epoch 40/100\n",
      "134/134 [==============================] - 1s 6ms/step - loss: 0.0061 - mean_absolute_error: 0.0583 - mean_squared_error: 0.0061 - val_loss: 0.0088 - val_mean_absolute_error: 0.0726 - val_mean_squared_error: 0.0088\n",
      "Epoch 41/100\n",
      "134/134 [==============================] - 1s 6ms/step - loss: 0.0055 - mean_absolute_error: 0.0560 - mean_squared_error: 0.0055 - val_loss: 0.0088 - val_mean_absolute_error: 0.0707 - val_mean_squared_error: 0.0088\n",
      "Epoch 42/100\n",
      "134/134 [==============================] - 1s 6ms/step - loss: 0.0054 - mean_absolute_error: 0.0547 - mean_squared_error: 0.0054 - val_loss: 0.0072 - val_mean_absolute_error: 0.0668 - val_mean_squared_error: 0.0072\n",
      "Epoch 43/100\n",
      "134/134 [==============================] - 1s 7ms/step - loss: 0.0062 - mean_absolute_error: 0.0605 - mean_squared_error: 0.0062 - val_loss: 0.0096 - val_mean_absolute_error: 0.0744 - val_mean_squared_error: 0.0096\n",
      "Epoch 44/100\n",
      "134/134 [==============================] - 1s 7ms/step - loss: 0.0058 - mean_absolute_error: 0.0574 - mean_squared_error: 0.0058 - val_loss: 0.0115 - val_mean_absolute_error: 0.0831 - val_mean_squared_error: 0.0115\n",
      "Epoch 45/100\n",
      "134/134 [==============================] - 1s 7ms/step - loss: 0.0055 - mean_absolute_error: 0.0565 - mean_squared_error: 0.0055 - val_loss: 0.0077 - val_mean_absolute_error: 0.0645 - val_mean_squared_error: 0.0077\n",
      "Epoch 46/100\n",
      "134/134 [==============================] - 1s 7ms/step - loss: 0.0059 - mean_absolute_error: 0.0574 - mean_squared_error: 0.0059 - val_loss: 0.0086 - val_mean_absolute_error: 0.0704 - val_mean_squared_error: 0.0086\n",
      "Epoch 47/100\n",
      "134/134 [==============================] - 1s 6ms/step - loss: 0.0052 - mean_absolute_error: 0.0544 - mean_squared_error: 0.0052 - val_loss: 0.0095 - val_mean_absolute_error: 0.0704 - val_mean_squared_error: 0.0095\n",
      "Epoch 48/100\n",
      "134/134 [==============================] - 1s 8ms/step - loss: 0.0052 - mean_absolute_error: 0.0545 - mean_squared_error: 0.0052 - val_loss: 0.0102 - val_mean_absolute_error: 0.0763 - val_mean_squared_error: 0.0102\n",
      "Epoch 49/100\n",
      "134/134 [==============================] - 1s 5ms/step - loss: 0.0052 - mean_absolute_error: 0.0538 - mean_squared_error: 0.0052 - val_loss: 0.0091 - val_mean_absolute_error: 0.0740 - val_mean_squared_error: 0.0091\n",
      "Epoch 50/100\n",
      "134/134 [==============================] - 1s 6ms/step - loss: 0.0049 - mean_absolute_error: 0.0524 - mean_squared_error: 0.0049 - val_loss: 0.0119 - val_mean_absolute_error: 0.0756 - val_mean_squared_error: 0.0119\n",
      "Epoch 51/100\n",
      "134/134 [==============================] - 1s 6ms/step - loss: 0.0059 - mean_absolute_error: 0.0584 - mean_squared_error: 0.0059 - val_loss: 0.0089 - val_mean_absolute_error: 0.0715 - val_mean_squared_error: 0.0089\n",
      "Epoch 52/100\n",
      "134/134 [==============================] - 1s 6ms/step - loss: 0.0047 - mean_absolute_error: 0.0518 - mean_squared_error: 0.0047 - val_loss: 0.0086 - val_mean_absolute_error: 0.0691 - val_mean_squared_error: 0.0086\n",
      "Epoch 53/100\n",
      "134/134 [==============================] - 1s 6ms/step - loss: 0.0044 - mean_absolute_error: 0.0500 - mean_squared_error: 0.0044 - val_loss: 0.0124 - val_mean_absolute_error: 0.0815 - val_mean_squared_error: 0.0124\n",
      "Epoch 54/100\n",
      "134/134 [==============================] - 1s 5ms/step - loss: 0.0047 - mean_absolute_error: 0.0523 - mean_squared_error: 0.0047 - val_loss: 0.0097 - val_mean_absolute_error: 0.0710 - val_mean_squared_error: 0.0097\n",
      "Epoch 55/100\n",
      "134/134 [==============================] - 1s 7ms/step - loss: 0.0045 - mean_absolute_error: 0.0503 - mean_squared_error: 0.0045 - val_loss: 0.0098 - val_mean_absolute_error: 0.0752 - val_mean_squared_error: 0.0098\n",
      "Epoch 56/100\n",
      "134/134 [==============================] - 1s 5ms/step - loss: 0.0049 - mean_absolute_error: 0.0530 - mean_squared_error: 0.0049 - val_loss: 0.0116 - val_mean_absolute_error: 0.0755 - val_mean_squared_error: 0.0116\n",
      "Epoch 57/100\n",
      "134/134 [==============================] - 1s 8ms/step - loss: 0.0051 - mean_absolute_error: 0.0528 - mean_squared_error: 0.0051 - val_loss: 0.0100 - val_mean_absolute_error: 0.0734 - val_mean_squared_error: 0.0100\n",
      "Epoch 58/100\n",
      "134/134 [==============================] - 1s 9ms/step - loss: 0.0055 - mean_absolute_error: 0.0546 - mean_squared_error: 0.0055 - val_loss: 0.0082 - val_mean_absolute_error: 0.0681 - val_mean_squared_error: 0.0082\n",
      "Epoch 59/100\n",
      "134/134 [==============================] - 1s 7ms/step - loss: 0.0053 - mean_absolute_error: 0.0550 - mean_squared_error: 0.0053 - val_loss: 0.0102 - val_mean_absolute_error: 0.0726 - val_mean_squared_error: 0.0102\n",
      "Epoch 60/100\n",
      "134/134 [==============================] - 1s 7ms/step - loss: 0.0048 - mean_absolute_error: 0.0518 - mean_squared_error: 0.0048 - val_loss: 0.0086 - val_mean_absolute_error: 0.0656 - val_mean_squared_error: 0.0086\n",
      "Epoch 61/100\n",
      "134/134 [==============================] - 1s 8ms/step - loss: 0.0052 - mean_absolute_error: 0.0539 - mean_squared_error: 0.0052 - val_loss: 0.0088 - val_mean_absolute_error: 0.0725 - val_mean_squared_error: 0.0088\n",
      "Epoch 62/100\n",
      "134/134 [==============================] - 1s 7ms/step - loss: 0.0045 - mean_absolute_error: 0.0509 - mean_squared_error: 0.0045 - val_loss: 0.0080 - val_mean_absolute_error: 0.0658 - val_mean_squared_error: 0.0080\n",
      "Epoch 63/100\n",
      "134/134 [==============================] - 1s 8ms/step - loss: 0.0043 - mean_absolute_error: 0.0490 - mean_squared_error: 0.0043 - val_loss: 0.0080 - val_mean_absolute_error: 0.0624 - val_mean_squared_error: 0.0080\n",
      "Epoch 64/100\n",
      "134/134 [==============================] - 1s 7ms/step - loss: 0.0040 - mean_absolute_error: 0.0473 - mean_squared_error: 0.0040 - val_loss: 0.0091 - val_mean_absolute_error: 0.0730 - val_mean_squared_error: 0.0091\n",
      "Epoch 65/100\n",
      "134/134 [==============================] - 1s 7ms/step - loss: 0.0042 - mean_absolute_error: 0.0483 - mean_squared_error: 0.0042 - val_loss: 0.0093 - val_mean_absolute_error: 0.0715 - val_mean_squared_error: 0.0093\n",
      "Epoch 66/100\n",
      "134/134 [==============================] - 1s 8ms/step - loss: 0.0044 - mean_absolute_error: 0.0494 - mean_squared_error: 0.0044 - val_loss: 0.0081 - val_mean_absolute_error: 0.0661 - val_mean_squared_error: 0.0081\n",
      "Epoch 67/100\n",
      "134/134 [==============================] - 1s 7ms/step - loss: 0.0042 - mean_absolute_error: 0.0492 - mean_squared_error: 0.0042 - val_loss: 0.0086 - val_mean_absolute_error: 0.0657 - val_mean_squared_error: 0.0086\n",
      "Epoch 68/100\n",
      "134/134 [==============================] - 1s 7ms/step - loss: 0.0044 - mean_absolute_error: 0.0490 - mean_squared_error: 0.0044 - val_loss: 0.0086 - val_mean_absolute_error: 0.0656 - val_mean_squared_error: 0.0086\n",
      "Epoch 69/100\n",
      "134/134 [==============================] - 1s 7ms/step - loss: 0.0047 - mean_absolute_error: 0.0510 - mean_squared_error: 0.0047 - val_loss: 0.0081 - val_mean_absolute_error: 0.0624 - val_mean_squared_error: 0.0081\n",
      "Epoch 70/100\n",
      "134/134 [==============================] - 1s 7ms/step - loss: 0.0041 - mean_absolute_error: 0.0477 - mean_squared_error: 0.0041 - val_loss: 0.0090 - val_mean_absolute_error: 0.0706 - val_mean_squared_error: 0.0090\n",
      "Epoch 71/100\n",
      "134/134 [==============================] - 1s 7ms/step - loss: 0.0037 - mean_absolute_error: 0.0457 - mean_squared_error: 0.0037 - val_loss: 0.0075 - val_mean_absolute_error: 0.0633 - val_mean_squared_error: 0.0075\n",
      "Epoch 72/100\n",
      "134/134 [==============================] - 1s 7ms/step - loss: 0.0042 - mean_absolute_error: 0.0484 - mean_squared_error: 0.0042 - val_loss: 0.0079 - val_mean_absolute_error: 0.0640 - val_mean_squared_error: 0.0079\n",
      "Epoch 73/100\n",
      "134/134 [==============================] - 1s 8ms/step - loss: 0.0042 - mean_absolute_error: 0.0486 - mean_squared_error: 0.0042 - val_loss: 0.0084 - val_mean_absolute_error: 0.0665 - val_mean_squared_error: 0.0084\n",
      "Epoch 74/100\n",
      "134/134 [==============================] - 1s 7ms/step - loss: 0.0050 - mean_absolute_error: 0.0508 - mean_squared_error: 0.0050 - val_loss: 0.0074 - val_mean_absolute_error: 0.0619 - val_mean_squared_error: 0.0074\n",
      "Epoch 75/100\n",
      "134/134 [==============================] - 1s 6ms/step - loss: 0.0045 - mean_absolute_error: 0.0496 - mean_squared_error: 0.0045 - val_loss: 0.0081 - val_mean_absolute_error: 0.0653 - val_mean_squared_error: 0.0081\n",
      "Epoch 76/100\n",
      "134/134 [==============================] - 1s 7ms/step - loss: 0.0041 - mean_absolute_error: 0.0482 - mean_squared_error: 0.0041 - val_loss: 0.0091 - val_mean_absolute_error: 0.0720 - val_mean_squared_error: 0.0091\n",
      "Epoch 77/100\n",
      "134/134 [==============================] - 1s 7ms/step - loss: 0.0041 - mean_absolute_error: 0.0480 - mean_squared_error: 0.0041 - val_loss: 0.0094 - val_mean_absolute_error: 0.0703 - val_mean_squared_error: 0.0094\n",
      "Epoch 78/100\n",
      "134/134 [==============================] - 1s 7ms/step - loss: 0.0040 - mean_absolute_error: 0.0462 - mean_squared_error: 0.0040 - val_loss: 0.0090 - val_mean_absolute_error: 0.0699 - val_mean_squared_error: 0.0090\n",
      "Epoch 79/100\n",
      "134/134 [==============================] - 1s 6ms/step - loss: 0.0036 - mean_absolute_error: 0.0447 - mean_squared_error: 0.0036 - val_loss: 0.0082 - val_mean_absolute_error: 0.0664 - val_mean_squared_error: 0.0082\n",
      "Epoch 80/100\n",
      "134/134 [==============================] - 1s 6ms/step - loss: 0.0035 - mean_absolute_error: 0.0427 - mean_squared_error: 0.0035 - val_loss: 0.0078 - val_mean_absolute_error: 0.0651 - val_mean_squared_error: 0.0078\n",
      "Epoch 81/100\n",
      "134/134 [==============================] - 1s 8ms/step - loss: 0.0034 - mean_absolute_error: 0.0438 - mean_squared_error: 0.0034 - val_loss: 0.0069 - val_mean_absolute_error: 0.0618 - val_mean_squared_error: 0.0069\n",
      "Epoch 82/100\n",
      "134/134 [==============================] - 1s 5ms/step - loss: 0.0035 - mean_absolute_error: 0.0441 - mean_squared_error: 0.0035 - val_loss: 0.0076 - val_mean_absolute_error: 0.0680 - val_mean_squared_error: 0.0076\n",
      "Epoch 83/100\n",
      "134/134 [==============================] - 1s 7ms/step - loss: 0.0037 - mean_absolute_error: 0.0455 - mean_squared_error: 0.0037 - val_loss: 0.0093 - val_mean_absolute_error: 0.0720 - val_mean_squared_error: 0.0093\n",
      "Epoch 84/100\n",
      "134/134 [==============================] - 1s 6ms/step - loss: 0.0036 - mean_absolute_error: 0.0440 - mean_squared_error: 0.0036 - val_loss: 0.0068 - val_mean_absolute_error: 0.0605 - val_mean_squared_error: 0.0068\n",
      "Epoch 85/100\n",
      "134/134 [==============================] - 1s 7ms/step - loss: 0.0034 - mean_absolute_error: 0.0436 - mean_squared_error: 0.0034 - val_loss: 0.0081 - val_mean_absolute_error: 0.0659 - val_mean_squared_error: 0.0081\n",
      "Epoch 86/100\n",
      "134/134 [==============================] - 1s 7ms/step - loss: 0.0036 - mean_absolute_error: 0.0455 - mean_squared_error: 0.0036 - val_loss: 0.0079 - val_mean_absolute_error: 0.0643 - val_mean_squared_error: 0.0079\n",
      "Epoch 87/100\n",
      "134/134 [==============================] - 1s 9ms/step - loss: 0.0035 - mean_absolute_error: 0.0441 - mean_squared_error: 0.0035 - val_loss: 0.0103 - val_mean_absolute_error: 0.0725 - val_mean_squared_error: 0.0103\n",
      "Epoch 88/100\n",
      "134/134 [==============================] - 1s 8ms/step - loss: 0.0035 - mean_absolute_error: 0.0435 - mean_squared_error: 0.0035 - val_loss: 0.0080 - val_mean_absolute_error: 0.0650 - val_mean_squared_error: 0.0080\n",
      "Epoch 89/100\n",
      "134/134 [==============================] - 1s 6ms/step - loss: 0.0035 - mean_absolute_error: 0.0431 - mean_squared_error: 0.0035 - val_loss: 0.0063 - val_mean_absolute_error: 0.0593 - val_mean_squared_error: 0.0063\n",
      "Epoch 90/100\n",
      "134/134 [==============================] - 1s 6ms/step - loss: 0.0033 - mean_absolute_error: 0.0427 - mean_squared_error: 0.0033 - val_loss: 0.0082 - val_mean_absolute_error: 0.0668 - val_mean_squared_error: 0.0082\n",
      "Epoch 91/100\n",
      "134/134 [==============================] - 1s 7ms/step - loss: 0.0035 - mean_absolute_error: 0.0442 - mean_squared_error: 0.0035 - val_loss: 0.0092 - val_mean_absolute_error: 0.0676 - val_mean_squared_error: 0.0092\n",
      "Epoch 92/100\n",
      "134/134 [==============================] - 1s 7ms/step - loss: 0.0049 - mean_absolute_error: 0.0518 - mean_squared_error: 0.0049 - val_loss: 0.0085 - val_mean_absolute_error: 0.0648 - val_mean_squared_error: 0.0085\n",
      "Epoch 93/100\n",
      "134/134 [==============================] - 1s 8ms/step - loss: 0.0036 - mean_absolute_error: 0.0442 - mean_squared_error: 0.0036 - val_loss: 0.0080 - val_mean_absolute_error: 0.0636 - val_mean_squared_error: 0.0080\n",
      "Epoch 94/100\n",
      "134/134 [==============================] - 1s 9ms/step - loss: 0.0033 - mean_absolute_error: 0.0427 - mean_squared_error: 0.0033 - val_loss: 0.0079 - val_mean_absolute_error: 0.0636 - val_mean_squared_error: 0.0079\n",
      "Epoch 95/100\n",
      "134/134 [==============================] - 1s 6ms/step - loss: 0.0040 - mean_absolute_error: 0.0470 - mean_squared_error: 0.0040 - val_loss: 0.0080 - val_mean_absolute_error: 0.0643 - val_mean_squared_error: 0.0080\n",
      "Epoch 96/100\n",
      "134/134 [==============================] - 1s 9ms/step - loss: 0.0034 - mean_absolute_error: 0.0432 - mean_squared_error: 0.0034 - val_loss: 0.0075 - val_mean_absolute_error: 0.0619 - val_mean_squared_error: 0.0075\n",
      "Epoch 97/100\n",
      "134/134 [==============================] - 1s 8ms/step - loss: 0.0033 - mean_absolute_error: 0.0431 - mean_squared_error: 0.0033 - val_loss: 0.0066 - val_mean_absolute_error: 0.0570 - val_mean_squared_error: 0.0066\n",
      "Epoch 98/100\n",
      "134/134 [==============================] - 1s 8ms/step - loss: 0.0031 - mean_absolute_error: 0.0411 - mean_squared_error: 0.0031 - val_loss: 0.0100 - val_mean_absolute_error: 0.0758 - val_mean_squared_error: 0.0100\n",
      "Epoch 99/100\n",
      "134/134 [==============================] - 1s 7ms/step - loss: 0.0034 - mean_absolute_error: 0.0435 - mean_squared_error: 0.0034 - val_loss: 0.0077 - val_mean_absolute_error: 0.0648 - val_mean_squared_error: 0.0077\n",
      "Epoch 100/100\n",
      "134/134 [==============================] - 1s 7ms/step - loss: 0.0033 - mean_absolute_error: 0.0426 - mean_squared_error: 0.0033 - val_loss: 0.0064 - val_mean_absolute_error: 0.0587 - val_mean_squared_error: 0.0064\n",
      "Best val_loss @ Epoch #89\n",
      "\n",
      "***Predictions from the best model.***\n",
      "\n",
      "For the training set:\n",
      "MAE: 0.3762 RMSE: 0.5254 R^2: 0.9820\n",
      "\n",
      "For the validation set:\n",
      "MAE: 0.6141 RMSE: 0.8293 R^2: 0.9475\n",
      "\n",
      "For the test set:\n",
      "MAE: 0.6233 RMSE: 0.9714 R^2: 0.9106\n",
      "\n",
      "******\n",
      "***Fold #1 initiated...***\n",
      "******\n",
      "***Sampling and splitting of the dataset.***\n",
      "\n",
      "Scaler: RobustScaler(copy=True, quantile_range=(5.0, 95.0), with_centering=True,\n",
      "             with_scaling=True)\n",
      "Train/valid/test splits: 0.80/0.10/0.10\n",
      "\n",
      "\n",
      "***Data augmentation to True***\n",
      "\n",
      "Enumerated SMILES:\n",
      "\tTraining set: 4256\n",
      "\tValidation set: 538\n",
      "\tTest set: 561\n",
      "\n",
      "***Tokenization of SMILES.***\n",
      "\n",
      "Examples of tokenized SMILES from a training set:\n",
      "[[' ', 'O', '=', '[N+]', '(', '[O-]', ')', 'c', '1', 'c', '(', 'Cl', ')', 'c', '(', 'Cl', ')', 'c', '(', 'Cl', ')', 'c', '(', 'Cl', ')', 'c', '1', 'Cl', ' '], [' ', '[N+]', '(', '[O-]', ')', '(', 'c', '1', 'c', '(', 'Cl', ')', 'c', '(', 'Cl', ')', 'c', '(', 'Cl', ')', 'c', '(', 'Cl', ')', 'c', '1', 'Cl', ')', '=', 'O', ' '], [' ', '[O-]', '[N+]', '(', 'c', '1', 'c', '(', 'Cl', ')', 'c', '(', 'Cl', ')', 'c', '(', 'Cl', ')', 'c', '(', 'Cl', ')', 'c', '1', 'Cl', ')', '=', 'O', ' '], [' ', 'c', '1', '(', '[N+]', '(', '=', 'O', ')', '[O-]', ')', 'c', '(', 'Cl', ')', 'c', '(', 'Cl', ')', 'c', '(', 'Cl', ')', 'c', '(', 'Cl', ')', 'c', '1', 'Cl', ' '], [' ', 'c', '1', '(', 'Cl', ')', 'c', '(', 'Cl', ')', 'c', '(', 'Cl', ')', 'c', '(', 'Cl', ')', 'c', '(', 'Cl', ')', 'c', '1', '[N+]', '(', '=', 'O', ')', '[O-]', ' ']]\n",
      "\n",
      "Number of tokens only present in a training set: 33\n",
      "\n",
      "Number of tokens only present in a validation set: 26\n",
      "Is the validation set a subset of the training set: True\n",
      "What are the tokens by which they differ: set()\n",
      "\n",
      "Number of tokens only present in a test set: 25\n",
      "Is the test set a subset of the training set: True\n",
      "What are the tokens by which they differ: set()\n",
      "Is the test set a subset of the validation set: False\n",
      "What are the tokens by which they differ: {'-', '\\\\', '/'}\n",
      "\n",
      "Full vocabulary: {'Cl', '[N+]', '\\\\', ')', '2', '-', 'c', '1', 'P', 'n', '=', ' ', '[C@@]', 'S', '3', 'Br', '#', '/', '[C@@H]', '[O-]', '[C@H]', '[nH]', '5', '4', 'C', 's', '(', 'N', 'F', '[C@]', 'I', '[S+2]', 'O'}\n",
      "Of size: 33\n",
      "\n",
      "Maximum length of tokenized SMILES: 50 tokens (termination spaces included)\n",
      "\n",
      "***Bayesian Optimization of the SMILESX's architecture.***\n",
      "\n",
      "Random initialization:\n",
      "\n",
      "Model: [[  8.   16.   16.  512.    2.4]]\n",
      "Valid MAE: 0.2152, RMSE: 0.0887\n",
      "Optimization:\n",
      "\n",
      "Model: [[ 32.  128.   64.   64.    3.2]]\n",
      "Valid MAE: 0.2037, RMSE: 0.0643\n",
      "\n",
      "The architecture for this datatset is:\n",
      "\tLSTM units: 32\n",
      "\tDense units: 128\n",
      "\tEmbedding dimensions 64\n",
      "\tBatch size: 64\n",
      "\tLearning rate: 10^-(3.2)\n",
      "\n",
      "***Training of the best model.***\n",
      "\n",
      "Best model summary:\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 51)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 51, 64)            2240      \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 51, 64)            25088     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 51, 128)           8320      \n",
      "_________________________________________________________________\n",
      "attention_m_1 (AttentionM)   (None, 128)               179       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 35,956\n",
      "Trainable params: 35,956\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      "Epoch 1/100\n",
      "67/67 [==============================] - 1s 11ms/step - loss: 0.1075 - mean_absolute_error: 0.2374 - mean_squared_error: 0.1075 - val_loss: 0.0699 - val_mean_absolute_error: 0.2182 - val_mean_squared_error: 0.0699\n",
      "Epoch 2/100\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.0652 - mean_absolute_error: 0.1889 - mean_squared_error: 0.0652 - val_loss: 0.0534 - val_mean_absolute_error: 0.1887 - val_mean_squared_error: 0.0534\n",
      "Epoch 3/100\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0415 - mean_absolute_error: 0.1591 - mean_squared_error: 0.0415 - val_loss: 0.0614 - val_mean_absolute_error: 0.2127 - val_mean_squared_error: 0.0614\n",
      "Epoch 4/100\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0350 - mean_absolute_error: 0.1491 - mean_squared_error: 0.0350 - val_loss: 0.0596 - val_mean_absolute_error: 0.1940 - val_mean_squared_error: 0.0596\n",
      "Epoch 5/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0329 - mean_absolute_error: 0.1417 - mean_squared_error: 0.0329 - val_loss: 0.0283 - val_mean_absolute_error: 0.1389 - val_mean_squared_error: 0.0283\n",
      "Epoch 6/100\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 0.0288 - mean_absolute_error: 0.1342 - mean_squared_error: 0.0288 - val_loss: 0.0616 - val_mean_absolute_error: 0.1838 - val_mean_squared_error: 0.0616\n",
      "Epoch 7/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0309 - mean_absolute_error: 0.1397 - mean_squared_error: 0.0309 - val_loss: 0.0245 - val_mean_absolute_error: 0.1274 - val_mean_squared_error: 0.0245\n",
      "Epoch 8/100\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0265 - mean_absolute_error: 0.1311 - mean_squared_error: 0.0265 - val_loss: 0.0217 - val_mean_absolute_error: 0.1193 - val_mean_squared_error: 0.0217\n",
      "Epoch 9/100\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0286 - mean_absolute_error: 0.1343 - mean_squared_error: 0.0286 - val_loss: 0.0245 - val_mean_absolute_error: 0.1260 - val_mean_squared_error: 0.0245\n",
      "Epoch 10/100\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0259 - mean_absolute_error: 0.1296 - mean_squared_error: 0.0259 - val_loss: 0.0228 - val_mean_absolute_error: 0.1208 - val_mean_squared_error: 0.0228\n",
      "Epoch 11/100\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0254 - mean_absolute_error: 0.1276 - mean_squared_error: 0.0254 - val_loss: 0.0252 - val_mean_absolute_error: 0.1304 - val_mean_squared_error: 0.0252\n",
      "Epoch 12/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0269 - mean_absolute_error: 0.1310 - mean_squared_error: 0.0269 - val_loss: 0.0225 - val_mean_absolute_error: 0.1248 - val_mean_squared_error: 0.0225\n",
      "Epoch 13/100\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 0.0252 - mean_absolute_error: 0.1274 - mean_squared_error: 0.0252 - val_loss: 0.0363 - val_mean_absolute_error: 0.1531 - val_mean_squared_error: 0.0363\n",
      "Epoch 14/100\n",
      "67/67 [==============================] - 1s 10ms/step - loss: 0.0248 - mean_absolute_error: 0.1250 - mean_squared_error: 0.0248 - val_loss: 0.0273 - val_mean_absolute_error: 0.1339 - val_mean_squared_error: 0.0273\n",
      "Epoch 15/100\n",
      "67/67 [==============================] - 1s 9ms/step - loss: 0.0244 - mean_absolute_error: 0.1252 - mean_squared_error: 0.0244 - val_loss: 0.0305 - val_mean_absolute_error: 0.1373 - val_mean_squared_error: 0.0305\n",
      "Epoch 16/100\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 0.0245 - mean_absolute_error: 0.1266 - mean_squared_error: 0.0245 - val_loss: 0.0227 - val_mean_absolute_error: 0.1203 - val_mean_squared_error: 0.0227\n",
      "Epoch 17/100\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 0.0235 - mean_absolute_error: 0.1238 - mean_squared_error: 0.0235 - val_loss: 0.0258 - val_mean_absolute_error: 0.1320 - val_mean_squared_error: 0.0258\n",
      "Epoch 18/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0245 - mean_absolute_error: 0.1240 - mean_squared_error: 0.0245 - val_loss: 0.0299 - val_mean_absolute_error: 0.1400 - val_mean_squared_error: 0.0299\n",
      "Epoch 19/100\n",
      "67/67 [==============================] - 1s 9ms/step - loss: 0.0230 - mean_absolute_error: 0.1207 - mean_squared_error: 0.0230 - val_loss: 0.0214 - val_mean_absolute_error: 0.1188 - val_mean_squared_error: 0.0214\n",
      "Epoch 20/100\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0235 - mean_absolute_error: 0.1210 - mean_squared_error: 0.0235 - val_loss: 0.0348 - val_mean_absolute_error: 0.1486 - val_mean_squared_error: 0.0348\n",
      "Epoch 21/100\n",
      "67/67 [==============================] - 1s 9ms/step - loss: 0.0250 - mean_absolute_error: 0.1257 - mean_squared_error: 0.0250 - val_loss: 0.0240 - val_mean_absolute_error: 0.1247 - val_mean_squared_error: 0.0240\n",
      "Epoch 22/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0217 - mean_absolute_error: 0.1181 - mean_squared_error: 0.0217 - val_loss: 0.0211 - val_mean_absolute_error: 0.1154 - val_mean_squared_error: 0.0211\n",
      "Epoch 23/100\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0223 - mean_absolute_error: 0.1203 - mean_squared_error: 0.0223 - val_loss: 0.0249 - val_mean_absolute_error: 0.1280 - val_mean_squared_error: 0.0249\n",
      "Epoch 24/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0212 - mean_absolute_error: 0.1161 - mean_squared_error: 0.0212 - val_loss: 0.0218 - val_mean_absolute_error: 0.1182 - val_mean_squared_error: 0.0218\n",
      "Epoch 25/100\n",
      "67/67 [==============================] - 1s 9ms/step - loss: 0.0200 - mean_absolute_error: 0.1128 - mean_squared_error: 0.0200 - val_loss: 0.0220 - val_mean_absolute_error: 0.1207 - val_mean_squared_error: 0.0220\n",
      "Epoch 26/100\n",
      "67/67 [==============================] - 1s 9ms/step - loss: 0.0208 - mean_absolute_error: 0.1155 - mean_squared_error: 0.0208 - val_loss: 0.0216 - val_mean_absolute_error: 0.1138 - val_mean_squared_error: 0.0216\n",
      "Epoch 27/100\n",
      "67/67 [==============================] - 1s 10ms/step - loss: 0.0209 - mean_absolute_error: 0.1154 - mean_squared_error: 0.0209 - val_loss: 0.0237 - val_mean_absolute_error: 0.1223 - val_mean_squared_error: 0.0237\n",
      "Epoch 28/100\n",
      "67/67 [==============================] - 1s 9ms/step - loss: 0.0195 - mean_absolute_error: 0.1113 - mean_squared_error: 0.0195 - val_loss: 0.0209 - val_mean_absolute_error: 0.1172 - val_mean_squared_error: 0.0209\n",
      "Epoch 29/100\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0191 - mean_absolute_error: 0.1096 - mean_squared_error: 0.0191 - val_loss: 0.0307 - val_mean_absolute_error: 0.1466 - val_mean_squared_error: 0.0307\n",
      "Epoch 30/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0202 - mean_absolute_error: 0.1142 - mean_squared_error: 0.0202 - val_loss: 0.0228 - val_mean_absolute_error: 0.1238 - val_mean_squared_error: 0.0228\n",
      "Epoch 31/100\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.0177 - mean_absolute_error: 0.1058 - mean_squared_error: 0.0177 - val_loss: 0.0205 - val_mean_absolute_error: 0.1160 - val_mean_squared_error: 0.0205\n",
      "Epoch 32/100\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0176 - mean_absolute_error: 0.1078 - mean_squared_error: 0.0176 - val_loss: 0.0312 - val_mean_absolute_error: 0.1422 - val_mean_squared_error: 0.0312\n",
      "Epoch 33/100\n",
      "67/67 [==============================] - 1s 9ms/step - loss: 0.0169 - mean_absolute_error: 0.1039 - mean_squared_error: 0.0169 - val_loss: 0.0192 - val_mean_absolute_error: 0.1126 - val_mean_squared_error: 0.0192\n",
      "Epoch 34/100\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0166 - mean_absolute_error: 0.1028 - mean_squared_error: 0.0166 - val_loss: 0.0245 - val_mean_absolute_error: 0.1256 - val_mean_squared_error: 0.0245\n",
      "Epoch 35/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0157 - mean_absolute_error: 0.0987 - mean_squared_error: 0.0157 - val_loss: 0.0180 - val_mean_absolute_error: 0.1094 - val_mean_squared_error: 0.0180\n",
      "Epoch 36/100\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 0.0163 - mean_absolute_error: 0.1007 - mean_squared_error: 0.0163 - val_loss: 0.0224 - val_mean_absolute_error: 0.1223 - val_mean_squared_error: 0.0224\n",
      "Epoch 37/100\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 0.0160 - mean_absolute_error: 0.1009 - mean_squared_error: 0.0160 - val_loss: 0.0203 - val_mean_absolute_error: 0.1137 - val_mean_squared_error: 0.0203\n",
      "Epoch 38/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0146 - mean_absolute_error: 0.0972 - mean_squared_error: 0.0146 - val_loss: 0.0196 - val_mean_absolute_error: 0.1107 - val_mean_squared_error: 0.0196\n",
      "Epoch 39/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0152 - mean_absolute_error: 0.0968 - mean_squared_error: 0.0152 - val_loss: 0.0174 - val_mean_absolute_error: 0.1019 - val_mean_squared_error: 0.0174\n",
      "Epoch 40/100\n",
      "67/67 [==============================] - 0s 5ms/step - loss: 0.0137 - mean_absolute_error: 0.0916 - mean_squared_error: 0.0137 - val_loss: 0.0175 - val_mean_absolute_error: 0.1047 - val_mean_squared_error: 0.0175\n",
      "Epoch 41/100\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0142 - mean_absolute_error: 0.0942 - mean_squared_error: 0.0142 - val_loss: 0.0188 - val_mean_absolute_error: 0.1099 - val_mean_squared_error: 0.0188\n",
      "Epoch 42/100\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 0.0137 - mean_absolute_error: 0.0926 - mean_squared_error: 0.0137 - val_loss: 0.0217 - val_mean_absolute_error: 0.1175 - val_mean_squared_error: 0.0217\n",
      "Epoch 43/100\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 0.0128 - mean_absolute_error: 0.0892 - mean_squared_error: 0.0128 - val_loss: 0.0195 - val_mean_absolute_error: 0.1079 - val_mean_squared_error: 0.0195\n",
      "Epoch 44/100\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 0.0134 - mean_absolute_error: 0.0913 - mean_squared_error: 0.0134 - val_loss: 0.0234 - val_mean_absolute_error: 0.1236 - val_mean_squared_error: 0.0234\n",
      "Epoch 45/100\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0124 - mean_absolute_error: 0.0865 - mean_squared_error: 0.0124 - val_loss: 0.0295 - val_mean_absolute_error: 0.1332 - val_mean_squared_error: 0.0295\n",
      "Epoch 46/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0135 - mean_absolute_error: 0.0915 - mean_squared_error: 0.0135 - val_loss: 0.0172 - val_mean_absolute_error: 0.0993 - val_mean_squared_error: 0.0172\n",
      "Epoch 47/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0122 - mean_absolute_error: 0.0865 - mean_squared_error: 0.0122 - val_loss: 0.0161 - val_mean_absolute_error: 0.0951 - val_mean_squared_error: 0.0161\n",
      "Epoch 48/100\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 0.0117 - mean_absolute_error: 0.0838 - mean_squared_error: 0.0117 - val_loss: 0.0195 - val_mean_absolute_error: 0.1104 - val_mean_squared_error: 0.0195\n",
      "Epoch 49/100\n",
      "67/67 [==============================] - 1s 7ms/step - loss: 0.0124 - mean_absolute_error: 0.0874 - mean_squared_error: 0.0124 - val_loss: 0.0185 - val_mean_absolute_error: 0.1033 - val_mean_squared_error: 0.0185\n",
      "Epoch 50/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0122 - mean_absolute_error: 0.0870 - mean_squared_error: 0.0122 - val_loss: 0.0228 - val_mean_absolute_error: 0.1172 - val_mean_squared_error: 0.0228\n",
      "Epoch 51/100\n",
      "67/67 [==============================] - 1s 9ms/step - loss: 0.0125 - mean_absolute_error: 0.0865 - mean_squared_error: 0.0125 - val_loss: 0.0238 - val_mean_absolute_error: 0.1244 - val_mean_squared_error: 0.0238\n",
      "Epoch 52/100\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0117 - mean_absolute_error: 0.0855 - mean_squared_error: 0.0117 - val_loss: 0.0210 - val_mean_absolute_error: 0.1061 - val_mean_squared_error: 0.0210\n",
      "Epoch 53/100\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 0.0112 - mean_absolute_error: 0.0815 - mean_squared_error: 0.0112 - val_loss: 0.0185 - val_mean_absolute_error: 0.1010 - val_mean_squared_error: 0.0185\n",
      "Epoch 54/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0103 - mean_absolute_error: 0.0779 - mean_squared_error: 0.0103 - val_loss: 0.0175 - val_mean_absolute_error: 0.0988 - val_mean_squared_error: 0.0175\n",
      "Epoch 55/100\n",
      "67/67 [==============================] - 1s 9ms/step - loss: 0.0103 - mean_absolute_error: 0.0788 - mean_squared_error: 0.0103 - val_loss: 0.0207 - val_mean_absolute_error: 0.1040 - val_mean_squared_error: 0.0207\n",
      "Epoch 56/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0100 - mean_absolute_error: 0.0770 - mean_squared_error: 0.0100 - val_loss: 0.0197 - val_mean_absolute_error: 0.1013 - val_mean_squared_error: 0.0197\n",
      "Epoch 57/100\n",
      "67/67 [==============================] - 1s 9ms/step - loss: 0.0098 - mean_absolute_error: 0.0755 - mean_squared_error: 0.0098 - val_loss: 0.0198 - val_mean_absolute_error: 0.1070 - val_mean_squared_error: 0.0198\n",
      "Epoch 58/100\n",
      "67/67 [==============================] - 1s 9ms/step - loss: 0.0100 - mean_absolute_error: 0.0776 - mean_squared_error: 0.0100 - val_loss: 0.0177 - val_mean_absolute_error: 0.0955 - val_mean_squared_error: 0.0177\n",
      "Epoch 59/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0092 - mean_absolute_error: 0.0737 - mean_squared_error: 0.0092 - val_loss: 0.0168 - val_mean_absolute_error: 0.0996 - val_mean_squared_error: 0.0168\n",
      "Epoch 60/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0101 - mean_absolute_error: 0.0760 - mean_squared_error: 0.0101 - val_loss: 0.0202 - val_mean_absolute_error: 0.1042 - val_mean_squared_error: 0.0202\n",
      "Epoch 61/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0092 - mean_absolute_error: 0.0731 - mean_squared_error: 0.0092 - val_loss: 0.0192 - val_mean_absolute_error: 0.1006 - val_mean_squared_error: 0.0192\n",
      "Epoch 62/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0098 - mean_absolute_error: 0.0758 - mean_squared_error: 0.0098 - val_loss: 0.0234 - val_mean_absolute_error: 0.1109 - val_mean_squared_error: 0.0234\n",
      "Epoch 63/100\n",
      "67/67 [==============================] - 1s 7ms/step - loss: 0.0092 - mean_absolute_error: 0.0733 - mean_squared_error: 0.0092 - val_loss: 0.0201 - val_mean_absolute_error: 0.1064 - val_mean_squared_error: 0.0201\n",
      "Epoch 64/100\n",
      "67/67 [==============================] - 1s 9ms/step - loss: 0.0089 - mean_absolute_error: 0.0723 - mean_squared_error: 0.0089 - val_loss: 0.0216 - val_mean_absolute_error: 0.1030 - val_mean_squared_error: 0.0216\n",
      "Epoch 65/100\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 0.0085 - mean_absolute_error: 0.0704 - mean_squared_error: 0.0085 - val_loss: 0.0182 - val_mean_absolute_error: 0.1011 - val_mean_squared_error: 0.0182\n",
      "Epoch 66/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0083 - mean_absolute_error: 0.0696 - mean_squared_error: 0.0083 - val_loss: 0.0142 - val_mean_absolute_error: 0.0866 - val_mean_squared_error: 0.0142\n",
      "Epoch 67/100\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 0.0087 - mean_absolute_error: 0.0708 - mean_squared_error: 0.0087 - val_loss: 0.0173 - val_mean_absolute_error: 0.1008 - val_mean_squared_error: 0.0173\n",
      "Epoch 68/100\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 0.0088 - mean_absolute_error: 0.0709 - mean_squared_error: 0.0088 - val_loss: 0.0194 - val_mean_absolute_error: 0.0994 - val_mean_squared_error: 0.0194\n",
      "Epoch 69/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0088 - mean_absolute_error: 0.0720 - mean_squared_error: 0.0088 - val_loss: 0.0152 - val_mean_absolute_error: 0.0903 - val_mean_squared_error: 0.0152\n",
      "Epoch 70/100\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 0.0083 - mean_absolute_error: 0.0692 - mean_squared_error: 0.0083 - val_loss: 0.0208 - val_mean_absolute_error: 0.1084 - val_mean_squared_error: 0.0208\n",
      "Epoch 71/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0087 - mean_absolute_error: 0.0707 - mean_squared_error: 0.0087 - val_loss: 0.0175 - val_mean_absolute_error: 0.1001 - val_mean_squared_error: 0.0175\n",
      "Epoch 72/100\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 0.0077 - mean_absolute_error: 0.0669 - mean_squared_error: 0.0077 - val_loss: 0.0156 - val_mean_absolute_error: 0.0925 - val_mean_squared_error: 0.0156\n",
      "Epoch 73/100\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 0.0078 - mean_absolute_error: 0.0668 - mean_squared_error: 0.0078 - val_loss: 0.0174 - val_mean_absolute_error: 0.0969 - val_mean_squared_error: 0.0174\n",
      "Epoch 74/100\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0071 - mean_absolute_error: 0.0639 - mean_squared_error: 0.0071 - val_loss: 0.0144 - val_mean_absolute_error: 0.0887 - val_mean_squared_error: 0.0144\n",
      "Epoch 75/100\n",
      "67/67 [==============================] - 1s 7ms/step - loss: 0.0069 - mean_absolute_error: 0.0627 - mean_squared_error: 0.0069 - val_loss: 0.0154 - val_mean_absolute_error: 0.0912 - val_mean_squared_error: 0.0154\n",
      "Epoch 76/100\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0073 - mean_absolute_error: 0.0658 - mean_squared_error: 0.0073 - val_loss: 0.0160 - val_mean_absolute_error: 0.0906 - val_mean_squared_error: 0.0160\n",
      "Epoch 77/100\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0074 - mean_absolute_error: 0.0655 - mean_squared_error: 0.0074 - val_loss: 0.0166 - val_mean_absolute_error: 0.0956 - val_mean_squared_error: 0.0166\n",
      "Epoch 78/100\n",
      "67/67 [==============================] - 1s 9ms/step - loss: 0.0073 - mean_absolute_error: 0.0637 - mean_squared_error: 0.0073 - val_loss: 0.0144 - val_mean_absolute_error: 0.0843 - val_mean_squared_error: 0.0144\n",
      "Epoch 79/100\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 0.0067 - mean_absolute_error: 0.0625 - mean_squared_error: 0.0067 - val_loss: 0.0164 - val_mean_absolute_error: 0.0915 - val_mean_squared_error: 0.0164\n",
      "Epoch 80/100\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 0.0066 - mean_absolute_error: 0.0606 - mean_squared_error: 0.0066 - val_loss: 0.0136 - val_mean_absolute_error: 0.0877 - val_mean_squared_error: 0.0136\n",
      "Epoch 81/100\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0069 - mean_absolute_error: 0.0640 - mean_squared_error: 0.0069 - val_loss: 0.0177 - val_mean_absolute_error: 0.1025 - val_mean_squared_error: 0.0177\n",
      "Epoch 82/100\n",
      "67/67 [==============================] - 1s 9ms/step - loss: 0.0069 - mean_absolute_error: 0.0633 - mean_squared_error: 0.0069 - val_loss: 0.0182 - val_mean_absolute_error: 0.0995 - val_mean_squared_error: 0.0182\n",
      "Epoch 83/100\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0069 - mean_absolute_error: 0.0640 - mean_squared_error: 0.0069 - val_loss: 0.0149 - val_mean_absolute_error: 0.0885 - val_mean_squared_error: 0.0149\n",
      "Epoch 84/100\n",
      "67/67 [==============================] - 1s 9ms/step - loss: 0.0065 - mean_absolute_error: 0.0616 - mean_squared_error: 0.0065 - val_loss: 0.0142 - val_mean_absolute_error: 0.0836 - val_mean_squared_error: 0.0142\n",
      "Epoch 85/100\n",
      "67/67 [==============================] - 1s 10ms/step - loss: 0.0063 - mean_absolute_error: 0.0593 - mean_squared_error: 0.0063 - val_loss: 0.0138 - val_mean_absolute_error: 0.0842 - val_mean_squared_error: 0.0138\n",
      "Epoch 86/100\n",
      "67/67 [==============================] - 1s 10ms/step - loss: 0.0065 - mean_absolute_error: 0.0611 - mean_squared_error: 0.0065 - val_loss: 0.0138 - val_mean_absolute_error: 0.0833 - val_mean_squared_error: 0.0138\n",
      "Epoch 87/100\n",
      "67/67 [==============================] - 1s 9ms/step - loss: 0.0069 - mean_absolute_error: 0.0614 - mean_squared_error: 0.0069 - val_loss: 0.0160 - val_mean_absolute_error: 0.0872 - val_mean_squared_error: 0.0160\n",
      "Epoch 88/100\n",
      "67/67 [==============================] - 1s 9ms/step - loss: 0.0058 - mean_absolute_error: 0.0576 - mean_squared_error: 0.0058 - val_loss: 0.0160 - val_mean_absolute_error: 0.1000 - val_mean_squared_error: 0.0160\n",
      "Epoch 89/100\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 0.0067 - mean_absolute_error: 0.0625 - mean_squared_error: 0.0067 - val_loss: 0.0161 - val_mean_absolute_error: 0.0914 - val_mean_squared_error: 0.0161\n",
      "Epoch 90/100\n",
      "67/67 [==============================] - 1s 10ms/step - loss: 0.0067 - mean_absolute_error: 0.0628 - mean_squared_error: 0.0067 - val_loss: 0.0174 - val_mean_absolute_error: 0.0958 - val_mean_squared_error: 0.0174\n",
      "Epoch 91/100\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 0.0060 - mean_absolute_error: 0.0581 - mean_squared_error: 0.0060 - val_loss: 0.0196 - val_mean_absolute_error: 0.0969 - val_mean_squared_error: 0.0196\n",
      "Epoch 92/100\n",
      "67/67 [==============================] - 1s 9ms/step - loss: 0.0063 - mean_absolute_error: 0.0600 - mean_squared_error: 0.0063 - val_loss: 0.0139 - val_mean_absolute_error: 0.0873 - val_mean_squared_error: 0.0139\n",
      "Epoch 93/100\n",
      "67/67 [==============================] - 1s 9ms/step - loss: 0.0057 - mean_absolute_error: 0.0565 - mean_squared_error: 0.0057 - val_loss: 0.0136 - val_mean_absolute_error: 0.0821 - val_mean_squared_error: 0.0136\n",
      "Epoch 94/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0056 - mean_absolute_error: 0.0555 - mean_squared_error: 0.0056 - val_loss: 0.0140 - val_mean_absolute_error: 0.0817 - val_mean_squared_error: 0.0140\n",
      "Epoch 95/100\n",
      "67/67 [==============================] - 1s 9ms/step - loss: 0.0058 - mean_absolute_error: 0.0576 - mean_squared_error: 0.0058 - val_loss: 0.0186 - val_mean_absolute_error: 0.0960 - val_mean_squared_error: 0.0186\n",
      "Epoch 96/100\n",
      "67/67 [==============================] - 1s 9ms/step - loss: 0.0062 - mean_absolute_error: 0.0593 - mean_squared_error: 0.0062 - val_loss: 0.0148 - val_mean_absolute_error: 0.0847 - val_mean_squared_error: 0.0148\n",
      "Epoch 97/100\n",
      "67/67 [==============================] - 0s 7ms/step - loss: 0.0059 - mean_absolute_error: 0.0573 - mean_squared_error: 0.0059 - val_loss: 0.0146 - val_mean_absolute_error: 0.0837 - val_mean_squared_error: 0.0146\n",
      "Epoch 98/100\n",
      "67/67 [==============================] - 1s 8ms/step - loss: 0.0058 - mean_absolute_error: 0.0573 - mean_squared_error: 0.0058 - val_loss: 0.0142 - val_mean_absolute_error: 0.0848 - val_mean_squared_error: 0.0142\n",
      "Epoch 99/100\n",
      "67/67 [==============================] - 1s 9ms/step - loss: 0.0059 - mean_absolute_error: 0.0581 - mean_squared_error: 0.0059 - val_loss: 0.0130 - val_mean_absolute_error: 0.0799 - val_mean_squared_error: 0.0130\n",
      "Epoch 100/100\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 0.0057 - mean_absolute_error: 0.0559 - mean_squared_error: 0.0057 - val_loss: 0.0133 - val_mean_absolute_error: 0.0826 - val_mean_squared_error: 0.0133\n",
      "Best val_loss @ Epoch #99\n",
      "\n",
      "***Predictions from the best model.***\n",
      "\n",
      "For the training set:\n",
      "MAE: 0.5602 RMSE: 0.7686 R^2: 0.9603\n",
      "\n",
      "For the validation set:\n",
      "MAE: 0.8229 RMSE: 1.2152 R^2: 0.8978\n",
      "\n",
      "For the test set:\n",
      "MAE: 0.8161 RMSE: 1.0090 R^2: 0.9251\n",
      "\n",
      "******\n",
      "***Fold #2 initiated...***\n",
      "******\n",
      "***Sampling and splitting of the dataset.***\n",
      "\n",
      "Scaler: RobustScaler(copy=True, quantile_range=(5.0, 95.0), with_centering=True,\n",
      "             with_scaling=True)\n",
      "Train/valid/test splits: 0.80/0.10/0.10\n",
      "\n",
      "\n",
      "***Data augmentation to True***\n",
      "\n",
      "Enumerated SMILES:\n",
      "\tTraining set: 4362\n",
      "\tValidation set: 496\n",
      "\tTest set: 497\n",
      "\n",
      "***Tokenization of SMILES.***\n",
      "\n",
      "Examples of tokenized SMILES from a training set:\n",
      "[[' ', 'C', 'O', 'c', '1', 'c', 'c', 'c', 'c', 'c', '1', 'N', ' '], [' ', 'O', '(', 'c', '1', 'c', 'c', 'c', 'c', 'c', '1', 'N', ')', 'C', ' '], [' ', 'c', '1', '(', 'O', 'C', ')', 'c', 'c', 'c', 'c', 'c', '1', 'N', ' '], [' ', 'c', '1', 'c', 'c', 'c', 'c', '(', 'N', ')', 'c', '1', 'O', 'C', ' '], [' ', 'c', '1', 'c', 'c', 'c', '(', 'N', ')', 'c', '(', 'O', 'C', ')', 'c', '1', ' ']]\n",
      "\n",
      "Number of tokens only present in a training set: 33\n",
      "\n",
      "Number of tokens only present in a validation set: 27\n",
      "Is the validation set a subset of the training set: True\n",
      "What are the tokens by which they differ: set()\n",
      "\n",
      "Number of tokens only present in a test set: 29\n",
      "Is the test set a subset of the training set: True\n",
      "What are the tokens by which they differ: set()\n",
      "Is the test set a subset of the validation set: False\n",
      "What are the tokens by which they differ: {'[C@]', '[C@@]', 's'}\n",
      "\n",
      "Full vocabulary: {'Cl', '[N+]', '\\\\', ')', '2', '-', 'c', '1', 'P', 'n', '=', ' ', '[C@@]', 'S', '3', 'Br', '#', '/', '[C@@H]', '[O-]', '[C@H]', '[nH]', '5', '4', 'C', 's', '(', 'N', 'F', '[S+2]', '[C@]', 'I', 'O'}\n",
      "Of size: 33\n",
      "\n",
      "Maximum length of tokenized SMILES: 50 tokens (termination spaces included)\n",
      "\n",
      "***Bayesian Optimization of the SMILESX's architecture.***\n",
      "\n",
      "Random initialization:\n",
      "\n",
      "Model: [[32.  32.  64.  16.   2.7]]\n",
      "Valid MAE: 0.1402, RMSE: 0.0330\n",
      "Optimization:\n",
      "\n",
      "Model: [[1024.    32.  1024.    32.     3.3]]\n",
      "Valid MAE: 0.1867, RMSE: 0.0677\n",
      "\n",
      "The architecture for this datatset is:\n",
      "\tLSTM units: 32\n",
      "\tDense units: 32\n",
      "\tEmbedding dimensions 64\n",
      "\tBatch size: 16\n",
      "\tLearning rate: 10^-(2.7)\n",
      "\n",
      "***Training of the best model.***\n",
      "\n",
      "Best model summary:\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 51)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 51, 64)            2240      \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 51, 64)            25088     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 51, 32)            2080      \n",
      "_________________________________________________________________\n",
      "attention_m_1 (AttentionM)   (None, 32)                83        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 29,524\n",
      "Trainable params: 29,524\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      "Epoch 1/100\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0773 - mean_absolute_error: 0.2057 - mean_squared_error: 0.0773 - val_loss: 0.0408 - val_mean_absolute_error: 0.1638 - val_mean_squared_error: 0.0408\n",
      "Epoch 2/100\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.0440 - mean_absolute_error: 0.1644 - mean_squared_error: 0.0440 - val_loss: 0.0245 - val_mean_absolute_error: 0.1217 - val_mean_squared_error: 0.0245\n",
      "Epoch 3/100\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.0285 - mean_absolute_error: 0.1341 - mean_squared_error: 0.0285 - val_loss: 0.0230 - val_mean_absolute_error: 0.1188 - val_mean_squared_error: 0.0230\n",
      "Epoch 4/100\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.0262 - mean_absolute_error: 0.1273 - mean_squared_error: 0.0262 - val_loss: 0.0249 - val_mean_absolute_error: 0.1202 - val_mean_squared_error: 0.0249\n",
      "Epoch 5/100\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0234 - mean_absolute_error: 0.1215 - mean_squared_error: 0.0234 - val_loss: 0.0241 - val_mean_absolute_error: 0.1259 - val_mean_squared_error: 0.0241\n",
      "Epoch 6/100\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0198 - mean_absolute_error: 0.1107 - mean_squared_error: 0.0198 - val_loss: 0.0193 - val_mean_absolute_error: 0.1078 - val_mean_squared_error: 0.0193\n",
      "Epoch 7/100\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.0175 - mean_absolute_error: 0.1044 - mean_squared_error: 0.0175 - val_loss: 0.0201 - val_mean_absolute_error: 0.1016 - val_mean_squared_error: 0.0201\n",
      "Epoch 8/100\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0166 - mean_absolute_error: 0.0977 - mean_squared_error: 0.0166 - val_loss: 0.0157 - val_mean_absolute_error: 0.0958 - val_mean_squared_error: 0.0157\n",
      "Epoch 9/100\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0143 - mean_absolute_error: 0.0920 - mean_squared_error: 0.0143 - val_loss: 0.0165 - val_mean_absolute_error: 0.0966 - val_mean_squared_error: 0.0165\n",
      "Epoch 10/100\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0145 - mean_absolute_error: 0.0930 - mean_squared_error: 0.0145 - val_loss: 0.0192 - val_mean_absolute_error: 0.1088 - val_mean_squared_error: 0.0192\n",
      "Epoch 11/100\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0134 - mean_absolute_error: 0.0880 - mean_squared_error: 0.0134 - val_loss: 0.0135 - val_mean_absolute_error: 0.0839 - val_mean_squared_error: 0.0135\n",
      "Epoch 12/100\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0120 - mean_absolute_error: 0.0836 - mean_squared_error: 0.0120 - val_loss: 0.0152 - val_mean_absolute_error: 0.0919 - val_mean_squared_error: 0.0152\n",
      "Epoch 13/100\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0121 - mean_absolute_error: 0.0831 - mean_squared_error: 0.0121 - val_loss: 0.0140 - val_mean_absolute_error: 0.0855 - val_mean_squared_error: 0.0140\n",
      "Epoch 14/100\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0110 - mean_absolute_error: 0.0798 - mean_squared_error: 0.0110 - val_loss: 0.0142 - val_mean_absolute_error: 0.0839 - val_mean_squared_error: 0.0142\n",
      "Epoch 15/100\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0101 - mean_absolute_error: 0.0750 - mean_squared_error: 0.0101 - val_loss: 0.0154 - val_mean_absolute_error: 0.0949 - val_mean_squared_error: 0.0154\n",
      "Epoch 16/100\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0096 - mean_absolute_error: 0.0743 - mean_squared_error: 0.0096 - val_loss: 0.0120 - val_mean_absolute_error: 0.0764 - val_mean_squared_error: 0.0120\n",
      "Epoch 17/100\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0088 - mean_absolute_error: 0.0718 - mean_squared_error: 0.0088 - val_loss: 0.0118 - val_mean_absolute_error: 0.0742 - val_mean_squared_error: 0.0118\n",
      "Epoch 18/100\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0091 - mean_absolute_error: 0.0721 - mean_squared_error: 0.0091 - val_loss: 0.0134 - val_mean_absolute_error: 0.0770 - val_mean_squared_error: 0.0134\n",
      "Epoch 19/100\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0098 - mean_absolute_error: 0.0738 - mean_squared_error: 0.0098 - val_loss: 0.0194 - val_mean_absolute_error: 0.1017 - val_mean_squared_error: 0.0194\n",
      "Epoch 20/100\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0087 - mean_absolute_error: 0.0706 - mean_squared_error: 0.0087 - val_loss: 0.0184 - val_mean_absolute_error: 0.0962 - val_mean_squared_error: 0.0184\n",
      "Epoch 21/100\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0085 - mean_absolute_error: 0.0706 - mean_squared_error: 0.0085 - val_loss: 0.0127 - val_mean_absolute_error: 0.0753 - val_mean_squared_error: 0.0127\n",
      "Epoch 22/100\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0073 - mean_absolute_error: 0.0645 - mean_squared_error: 0.0073 - val_loss: 0.0116 - val_mean_absolute_error: 0.0748 - val_mean_squared_error: 0.0116\n",
      "Epoch 23/100\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0066 - mean_absolute_error: 0.0616 - mean_squared_error: 0.0066 - val_loss: 0.0105 - val_mean_absolute_error: 0.0684 - val_mean_squared_error: 0.0105\n",
      "Epoch 24/100\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.0060 - mean_absolute_error: 0.0586 - mean_squared_error: 0.0060 - val_loss: 0.0107 - val_mean_absolute_error: 0.0708 - val_mean_squared_error: 0.0107\n",
      "Epoch 25/100\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.0069 - mean_absolute_error: 0.0625 - mean_squared_error: 0.0069 - val_loss: 0.0116 - val_mean_absolute_error: 0.0742 - val_mean_squared_error: 0.0116\n",
      "Epoch 26/100\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0059 - mean_absolute_error: 0.0579 - mean_squared_error: 0.0059 - val_loss: 0.0095 - val_mean_absolute_error: 0.0676 - val_mean_squared_error: 0.0095\n",
      "Epoch 27/100\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0049 - mean_absolute_error: 0.0533 - mean_squared_error: 0.0049 - val_loss: 0.0126 - val_mean_absolute_error: 0.0782 - val_mean_squared_error: 0.0126\n",
      "Epoch 28/100\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0055 - mean_absolute_error: 0.0546 - mean_squared_error: 0.0055 - val_loss: 0.0096 - val_mean_absolute_error: 0.0633 - val_mean_squared_error: 0.0096\n",
      "Epoch 29/100\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.0059 - mean_absolute_error: 0.0573 - mean_squared_error: 0.0059 - val_loss: 0.0096 - val_mean_absolute_error: 0.0653 - val_mean_squared_error: 0.0096\n",
      "Epoch 30/100\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.0050 - mean_absolute_error: 0.0525 - mean_squared_error: 0.0050 - val_loss: 0.0132 - val_mean_absolute_error: 0.0771 - val_mean_squared_error: 0.0132\n",
      "Epoch 31/100\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.0046 - mean_absolute_error: 0.0504 - mean_squared_error: 0.0046 - val_loss: 0.0094 - val_mean_absolute_error: 0.0645 - val_mean_squared_error: 0.0094\n",
      "Epoch 32/100\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.0045 - mean_absolute_error: 0.0503 - mean_squared_error: 0.0045 - val_loss: 0.0125 - val_mean_absolute_error: 0.0743 - val_mean_squared_error: 0.0125\n",
      "Epoch 33/100\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.0044 - mean_absolute_error: 0.0495 - mean_squared_error: 0.0044 - val_loss: 0.0117 - val_mean_absolute_error: 0.0760 - val_mean_squared_error: 0.0117\n",
      "Epoch 34/100\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.0039 - mean_absolute_error: 0.0473 - mean_squared_error: 0.0039 - val_loss: 0.0100 - val_mean_absolute_error: 0.0630 - val_mean_squared_error: 0.0100\n",
      "Epoch 35/100\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.0038 - mean_absolute_error: 0.0467 - mean_squared_error: 0.0038 - val_loss: 0.0107 - val_mean_absolute_error: 0.0755 - val_mean_squared_error: 0.0107\n",
      "Epoch 36/100\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0035 - mean_absolute_error: 0.0450 - mean_squared_error: 0.0035 - val_loss: 0.0097 - val_mean_absolute_error: 0.0621 - val_mean_squared_error: 0.0097\n",
      "Epoch 37/100\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.0037 - mean_absolute_error: 0.0461 - mean_squared_error: 0.0037 - val_loss: 0.0080 - val_mean_absolute_error: 0.0602 - val_mean_squared_error: 0.0080\n",
      "Epoch 38/100\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.0044 - mean_absolute_error: 0.0500 - mean_squared_error: 0.0044 - val_loss: 0.0097 - val_mean_absolute_error: 0.0659 - val_mean_squared_error: 0.0097\n",
      "Epoch 39/100\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.0041 - mean_absolute_error: 0.0473 - mean_squared_error: 0.0041 - val_loss: 0.0124 - val_mean_absolute_error: 0.0793 - val_mean_squared_error: 0.0124\n",
      "Epoch 40/100\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.0038 - mean_absolute_error: 0.0461 - mean_squared_error: 0.0038 - val_loss: 0.0129 - val_mean_absolute_error: 0.0762 - val_mean_squared_error: 0.0129\n",
      "Epoch 41/100\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0032 - mean_absolute_error: 0.0432 - mean_squared_error: 0.0032 - val_loss: 0.0099 - val_mean_absolute_error: 0.0653 - val_mean_squared_error: 0.0099\n",
      "Epoch 42/100\n",
      "273/273 [==============================] - 3s 9ms/step - loss: 0.0030 - mean_absolute_error: 0.0415 - mean_squared_error: 0.0030 - val_loss: 0.0118 - val_mean_absolute_error: 0.0693 - val_mean_squared_error: 0.0118\n",
      "Epoch 43/100\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0035 - mean_absolute_error: 0.0444 - mean_squared_error: 0.0035 - val_loss: 0.0088 - val_mean_absolute_error: 0.0608 - val_mean_squared_error: 0.0088\n",
      "Epoch 44/100\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0029 - mean_absolute_error: 0.0409 - mean_squared_error: 0.0029 - val_loss: 0.0101 - val_mean_absolute_error: 0.0625 - val_mean_squared_error: 0.0101\n",
      "Epoch 45/100\n",
      "273/273 [==============================] - 2s 9ms/step - loss: 0.0028 - mean_absolute_error: 0.0396 - mean_squared_error: 0.0028 - val_loss: 0.0103 - val_mean_absolute_error: 0.0645 - val_mean_squared_error: 0.0103\n",
      "Epoch 46/100\n",
      "273/273 [==============================] - 3s 9ms/step - loss: 0.0025 - mean_absolute_error: 0.0382 - mean_squared_error: 0.0025 - val_loss: 0.0098 - val_mean_absolute_error: 0.0629 - val_mean_squared_error: 0.0098\n",
      "Epoch 47/100\n",
      "273/273 [==============================] - 2s 9ms/step - loss: 0.0028 - mean_absolute_error: 0.0392 - mean_squared_error: 0.0028 - val_loss: 0.0105 - val_mean_absolute_error: 0.0631 - val_mean_squared_error: 0.0105\n",
      "Epoch 48/100\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0030 - mean_absolute_error: 0.0399 - mean_squared_error: 0.0030 - val_loss: 0.0092 - val_mean_absolute_error: 0.0630 - val_mean_squared_error: 0.0092\n",
      "Epoch 49/100\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0024 - mean_absolute_error: 0.0368 - mean_squared_error: 0.0024 - val_loss: 0.0083 - val_mean_absolute_error: 0.0591 - val_mean_squared_error: 0.0083\n",
      "Epoch 50/100\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0022 - mean_absolute_error: 0.0354 - mean_squared_error: 0.0022 - val_loss: 0.0124 - val_mean_absolute_error: 0.0713 - val_mean_squared_error: 0.0124\n",
      "Epoch 51/100\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0023 - mean_absolute_error: 0.0362 - mean_squared_error: 0.0023 - val_loss: 0.0095 - val_mean_absolute_error: 0.0607 - val_mean_squared_error: 0.0095\n",
      "Epoch 52/100\n",
      "273/273 [==============================] - 2s 9ms/step - loss: 0.0026 - mean_absolute_error: 0.0385 - mean_squared_error: 0.0026 - val_loss: 0.0112 - val_mean_absolute_error: 0.0689 - val_mean_squared_error: 0.0112\n",
      "Epoch 53/100\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0022 - mean_absolute_error: 0.0355 - mean_squared_error: 0.0022 - val_loss: 0.0088 - val_mean_absolute_error: 0.0583 - val_mean_squared_error: 0.0088\n",
      "Epoch 54/100\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0020 - mean_absolute_error: 0.0333 - mean_squared_error: 0.0020 - val_loss: 0.0115 - val_mean_absolute_error: 0.0690 - val_mean_squared_error: 0.0115\n",
      "Epoch 55/100\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.0020 - mean_absolute_error: 0.0346 - mean_squared_error: 0.0020 - val_loss: 0.0103 - val_mean_absolute_error: 0.0668 - val_mean_squared_error: 0.0103\n",
      "Epoch 56/100\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.0021 - mean_absolute_error: 0.0348 - mean_squared_error: 0.0021 - val_loss: 0.0110 - val_mean_absolute_error: 0.0739 - val_mean_squared_error: 0.0110\n",
      "Epoch 57/100\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.0019 - mean_absolute_error: 0.0336 - mean_squared_error: 0.0019 - val_loss: 0.0085 - val_mean_absolute_error: 0.0601 - val_mean_squared_error: 0.0085\n",
      "Epoch 58/100\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.0019 - mean_absolute_error: 0.0336 - mean_squared_error: 0.0019 - val_loss: 0.0108 - val_mean_absolute_error: 0.0643 - val_mean_squared_error: 0.0108\n",
      "Epoch 59/100\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.0024 - mean_absolute_error: 0.0369 - mean_squared_error: 0.0024 - val_loss: 0.0083 - val_mean_absolute_error: 0.0553 - val_mean_squared_error: 0.0083\n",
      "Epoch 60/100\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.0020 - mean_absolute_error: 0.0335 - mean_squared_error: 0.0020 - val_loss: 0.0085 - val_mean_absolute_error: 0.0573 - val_mean_squared_error: 0.0085\n",
      "Epoch 61/100\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0019 - mean_absolute_error: 0.0323 - mean_squared_error: 0.0019 - val_loss: 0.0115 - val_mean_absolute_error: 0.0667 - val_mean_squared_error: 0.0115\n",
      "Epoch 62/100\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0018 - mean_absolute_error: 0.0318 - mean_squared_error: 0.0018 - val_loss: 0.0088 - val_mean_absolute_error: 0.0636 - val_mean_squared_error: 0.0088\n",
      "Epoch 63/100\n",
      "273/273 [==============================] - 2s 9ms/step - loss: 0.0016 - mean_absolute_error: 0.0309 - mean_squared_error: 0.0016 - val_loss: 0.0094 - val_mean_absolute_error: 0.0594 - val_mean_squared_error: 0.0094\n",
      "Epoch 64/100\n",
      "273/273 [==============================] - 3s 9ms/step - loss: 0.0020 - mean_absolute_error: 0.0341 - mean_squared_error: 0.0020 - val_loss: 0.0086 - val_mean_absolute_error: 0.0617 - val_mean_squared_error: 0.0086\n",
      "Epoch 65/100\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0016 - mean_absolute_error: 0.0303 - mean_squared_error: 0.0016 - val_loss: 0.0095 - val_mean_absolute_error: 0.0663 - val_mean_squared_error: 0.0095\n",
      "Epoch 66/100\n",
      "273/273 [==============================] - 3s 10ms/step - loss: 0.0016 - mean_absolute_error: 0.0302 - mean_squared_error: 0.0016 - val_loss: 0.0105 - val_mean_absolute_error: 0.0693 - val_mean_squared_error: 0.0105\n",
      "Epoch 67/100\n",
      "273/273 [==============================] - 2s 9ms/step - loss: 0.0019 - mean_absolute_error: 0.0334 - mean_squared_error: 0.0019 - val_loss: 0.0091 - val_mean_absolute_error: 0.0603 - val_mean_squared_error: 0.0091\n",
      "Epoch 68/100\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0017 - mean_absolute_error: 0.0319 - mean_squared_error: 0.0017 - val_loss: 0.0100 - val_mean_absolute_error: 0.0611 - val_mean_squared_error: 0.0100\n",
      "Epoch 69/100\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.0018 - mean_absolute_error: 0.0331 - mean_squared_error: 0.0018 - val_loss: 0.0108 - val_mean_absolute_error: 0.0629 - val_mean_squared_error: 0.0108\n",
      "Epoch 70/100\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.0016 - mean_absolute_error: 0.0300 - mean_squared_error: 0.0016 - val_loss: 0.0091 - val_mean_absolute_error: 0.0597 - val_mean_squared_error: 0.0091\n",
      "Epoch 71/100\n",
      "273/273 [==============================] - 1s 5ms/step - loss: 0.0019 - mean_absolute_error: 0.0326 - mean_squared_error: 0.0019 - val_loss: 0.0084 - val_mean_absolute_error: 0.0616 - val_mean_squared_error: 0.0084\n",
      "Epoch 72/100\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.0015 - mean_absolute_error: 0.0297 - mean_squared_error: 0.0015 - val_loss: 0.0103 - val_mean_absolute_error: 0.0630 - val_mean_squared_error: 0.0103\n",
      "Epoch 73/100\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.0016 - mean_absolute_error: 0.0300 - mean_squared_error: 0.0016 - val_loss: 0.0099 - val_mean_absolute_error: 0.0638 - val_mean_squared_error: 0.0099\n",
      "Epoch 74/100\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0013 - mean_absolute_error: 0.0283 - mean_squared_error: 0.0013 - val_loss: 0.0095 - val_mean_absolute_error: 0.0596 - val_mean_squared_error: 0.0095\n",
      "Epoch 75/100\n",
      "273/273 [==============================] - 2s 6ms/step - loss: 0.0014 - mean_absolute_error: 0.0286 - mean_squared_error: 0.0014 - val_loss: 0.0103 - val_mean_absolute_error: 0.0607 - val_mean_squared_error: 0.0103\n",
      "Epoch 76/100\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0015 - mean_absolute_error: 0.0292 - mean_squared_error: 0.0015 - val_loss: 0.0100 - val_mean_absolute_error: 0.0642 - val_mean_squared_error: 0.0100\n",
      "Epoch 77/100\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0014 - mean_absolute_error: 0.0282 - mean_squared_error: 0.0014 - val_loss: 0.0093 - val_mean_absolute_error: 0.0610 - val_mean_squared_error: 0.0093\n",
      "Epoch 78/100\n",
      "273/273 [==============================] - 2s 9ms/step - loss: 0.0015 - mean_absolute_error: 0.0288 - mean_squared_error: 0.0015 - val_loss: 0.0096 - val_mean_absolute_error: 0.0643 - val_mean_squared_error: 0.0096\n",
      "Epoch 79/100\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0014 - mean_absolute_error: 0.0290 - mean_squared_error: 0.0014 - val_loss: 0.0087 - val_mean_absolute_error: 0.0560 - val_mean_squared_error: 0.0087\n",
      "Epoch 80/100\n",
      "273/273 [==============================] - 3s 11ms/step - loss: 0.0019 - mean_absolute_error: 0.0320 - mean_squared_error: 0.0019 - val_loss: 0.0086 - val_mean_absolute_error: 0.0562 - val_mean_squared_error: 0.0086\n",
      "Epoch 81/100\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0017 - mean_absolute_error: 0.0313 - mean_squared_error: 0.0017 - val_loss: 0.0087 - val_mean_absolute_error: 0.0597 - val_mean_squared_error: 0.0087\n",
      "Epoch 82/100\n",
      "273/273 [==============================] - 2s 9ms/step - loss: 0.0012 - mean_absolute_error: 0.0266 - mean_squared_error: 0.0012 - val_loss: 0.0099 - val_mean_absolute_error: 0.0612 - val_mean_squared_error: 0.0099\n",
      "Epoch 83/100\n",
      "273/273 [==============================] - 2s 7ms/step - loss: 0.0011 - mean_absolute_error: 0.0249 - mean_squared_error: 0.0011 - val_loss: 0.0088 - val_mean_absolute_error: 0.0591 - val_mean_squared_error: 0.0088\n",
      "Epoch 84/100\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 9.0618e-04 - mean_absolute_error: 0.0232 - mean_squared_error: 9.0618e-04 - val_loss: 0.0094 - val_mean_absolute_error: 0.0649 - val_mean_squared_error: 0.0094\n",
      "Epoch 85/100\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 9.3682e-04 - mean_absolute_error: 0.0235 - mean_squared_error: 9.3682e-04 - val_loss: 0.0085 - val_mean_absolute_error: 0.0579 - val_mean_squared_error: 0.0085\n",
      "Epoch 86/100\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 9.6408e-04 - mean_absolute_error: 0.0239 - mean_squared_error: 9.6408e-04 - val_loss: 0.0083 - val_mean_absolute_error: 0.0592 - val_mean_squared_error: 0.0083\n",
      "Epoch 87/100\n",
      "273/273 [==============================] - 2s 8ms/step - loss: 0.0013 - mean_absolute_error: 0.0277 - mean_squared_error: 0.0013 - val_loss: 0.0101 - val_mean_absolute_error: 0.0625 - val_mean_squared_error: 0.0101\n",
      "Best val_loss @ Epoch #37\n",
      "\n",
      "***Predictions from the best model.***\n",
      "\n",
      "For the training set:\n",
      "MAE: 0.4164 RMSE: 0.5672 R^2: 0.9799\n",
      "\n",
      "For the validation set:\n",
      "MAE: 0.5921 RMSE: 0.8804 R^2: 0.9324\n",
      "\n",
      "For the test set:\n",
      "MAE: 0.4668 RMSE: 0.7007 R^2: 0.9350\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main.Main(data=sol_data, \n",
    "          data_name=data_name, \n",
    "          data_units='', \n",
    "          bayopt_bounds=bounds, \n",
    "          k_fold_number = 3, \n",
    "          augmentation = True, \n",
    "          outdir = \"./data/\", \n",
    "          bayopt_n_epochs = 1,\n",
    "          bayopt_n_rounds = 1, \n",
    "          bayopt_it_factor = 1, \n",
    "          bayopt_on = True, \n",
    "          lstmunits_ref = 128, \n",
    "          denseunits_ref = 16, \n",
    "          embedding_ref = 32, \n",
    "          n_gpus = 1, \n",
    "          bridge_type = 'NVLink', \n",
    "          batch_size_ref = 8,\n",
    "          alpha_ref = 22, \n",
    "          patience = 50, \n",
    "          n_epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***SMILES_X for inference starts...***\n",
      "\n",
      "\n",
      "***Checking the SMILES list for inference***\n",
      "\n",
      "***Data augmentation.***\n",
      "\n",
      "Enumerated SMILES: 5\n",
      "\n",
      "***Tokenization of SMILES.***\n",
      "\n",
      "Full vocabulary: ['pad', 'unk', 'Cl', '[N+]', '\\\\', ')', '2', '-', 'c', '1', 'P', 'n', '=', ' ', '[C@@]', 'S', '3', 'Br', '#', '/', '[O-]', '[C@@H]', '[C@H]', '[nH]', '5', '4', 'C', 's', '(', 'N', 'F', '[S+2]', 'I', '[C@]', 'O']\n",
      "Of size: 35\n",
      "\n",
      "Maximum length of tokenized SMILES: 51 tokens\n",
      "\n",
      "***Inference of SMILES property done.***\n"
     ]
    }
   ],
   "source": [
    "pred_from_ens = inference.Inference(data_name=data_name, \n",
    "                                    smiles_list = ['CC','CCC','C=O','ABC','DEF'], \n",
    "                                    data_units = '',\n",
    "                                    k_fold_number = 3,\n",
    "                                    augmentation = True, \n",
    "                                    outdir = \"./data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMILES</th>\n",
       "      <th>ens_pred_mean</th>\n",
       "      <th>ens_pred_sd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CC</td>\n",
       "      <td>0.406713</td>\n",
       "      <td>0.0213377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CCC</td>\n",
       "      <td>0.43053</td>\n",
       "      <td>0.020964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C=O</td>\n",
       "      <td>0.00962523</td>\n",
       "      <td>0.0223681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SMILES ens_pred_mean ens_pred_sd\n",
       "0     CC      0.406713   0.0213377\n",
       "1    CCC       0.43053    0.020964\n",
       "2    C=O    0.00962523   0.0223681"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_from_ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
